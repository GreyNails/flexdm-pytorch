{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA可用: False\n",
      "设备数量: 0\n",
      "✓ 导入完成（CPU模式）\n",
      "\n",
      "✓ 配置: device=cpu, batch_size=10\n",
      "\n",
      "================================================================================\n",
      "MFP PyTorch Demo - 修复版（对齐训练代码）\n",
      "================================================================================\n",
      "\n",
      "1. 加载数据集\n",
      "加载数据: /home/dell/Project-HCL/BaseLine/flexdm_pt/data/crello_json/test.json\n",
      "✓ 加载了 2248 个样本\n",
      "\n",
      "构建查找表...\n",
      "  Type词汇表: 5 个类型\n",
      "  Type映射: {'svgElement': 0, 'textElement': 1, 'imageElement': 2, 'coloredBackground': 3, 'maskElement': 4, '<UNKNOWN>': 0}\n",
      "  Canvas Width词汇表: 41 个尺寸\n",
      "  Canvas Height词汇表: 46 个尺寸\n",
      "  Font词汇表: 34 个字体 (OOV->0)\n",
      "✓ 数据集大小: 2248\n",
      "\n",
      "2. 加载映射\n",
      "✓ 字体映射: 34 个字体\n",
      "✓ Width映射: 42 个尺寸\n",
      "✓ Height映射: 47 个尺寸\n",
      "\n",
      "3. 创建DataLoader\n",
      "✓ 批次形状: torch.Size([10, 20, 1])\n",
      "\n",
      "4. 加载模型配置\n",
      "✓ 输入列数: 15\n",
      "✓ 任务列表: ['random', 'elem', 'type', 'pos', 'attr', 'img', 'txt']\n",
      "\n",
      "5. 加载模型\n",
      "加载模型: /home/dell/Project-HCL/BaseLine/flexdm_pt/checkpoints/retrain_v1/best.pth\n",
      "\n",
      "============================================================\n",
      "初始化MFP模型\n",
      "============================================================\n",
      "初始化Encoder:\n",
      "  type: Embedding(8, 256)\n",
      "  left: Embedding(66, 256)\n",
      "  top: Embedding(66, 256)\n",
      "  width: Embedding(66, 256)\n",
      "  height: Embedding(66, 256)\n",
      "  opacity: Embedding(10, 256)\n",
      "  color: Embedding(18, 256)\n",
      "  image_embedding: Linear(512, 256)\n",
      "  text_embedding: Linear(512, 256)\n",
      "  font_family: Embedding(36, 256)\n",
      "总计: 10 个特征\n",
      "\n",
      "初始化Transformer:\n",
      "  blocks=4, embed_dim=256, num_heads=8\n",
      "\n",
      "初始化Decoder:\n",
      "  type: Linear(256, 6) -> (1, 6)\n",
      "  left: Linear(256, 64) -> (1, 64)\n",
      "  top: Linear(256, 64) -> (1, 64)\n",
      "  width: Linear(256, 64) -> (1, 64)\n",
      "  height: Linear(256, 64) -> (1, 64)\n",
      "  opacity: Linear(256, 8) -> (1, 8)\n",
      "  color: Linear(256, 48) -> (3, 16)\n",
      "  image_embedding: Linear(256, 512)\n",
      "  text_embedding: Linear(256, 512)\n",
      "  font_family: Linear(256, 34) -> (1, 34)\n",
      "总计: 10 个输出头\n",
      "\n",
      "总参数数: 2,823,776\n",
      "============================================================\n",
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for MFP:\n\tsize mismatch for encoder.emb_layers.0.weight: copying a param with shape torch.Size([7, 256]) from checkpoint, the shape in current model is torch.Size([8, 256]).\n\tsize mismatch for decoder.head_layers.0.weight: copying a param with shape torch.Size([5, 256]) from checkpoint, the shape in current model is torch.Size([6, 256]).\n\tsize mismatch for decoder.head_layers.0.bias: copying a param with shape torch.Size([5]) from checkpoint, the shape in current model is torch.Size([6]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 438\u001b[0m\n\u001b[1;32m    436\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m5. 加载模型\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    437\u001b[0m checkpoint_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/home/dell/Project-HCL/BaseLine/flexdm_pt/checkpoints/retrain_v1/best.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 438\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcheckpoint_path\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_columns\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    440\u001b[0m \u001b[38;5;66;03m# 6. 构建检索数据库\u001b[39;00m\n\u001b[1;32m    441\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m6. 构建检索数据库\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[13], line 226\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(checkpoint_path, input_columns)\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    224\u001b[0m     state_dict \u001b[38;5;241m=\u001b[39m checkpoint\n\u001b[0;32m--> 226\u001b[0m missing, unexpected \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    228\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m missing:\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  警告: 缺失 \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(missing)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m 个键\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/home/dell/anaconda3/envs/ptfd311/lib/python3.11/site-packages/torch/nn/modules/module.py:2152\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[1;32m   2147\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[1;32m   2148\u001b[0m             \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2149\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)))\n\u001b[1;32m   2151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 2152\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2153\u001b[0m                        \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)))\n\u001b[1;32m   2154\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for MFP:\n\tsize mismatch for encoder.emb_layers.0.weight: copying a param with shape torch.Size([7, 256]) from checkpoint, the shape in current model is torch.Size([8, 256]).\n\tsize mismatch for decoder.head_layers.0.weight: copying a param with shape torch.Size([5, 256]) from checkpoint, the shape in current model is torch.Size([6, 256]).\n\tsize mismatch for decoder.head_layers.0.bias: copying a param with shape torch.Size([5]) from checkpoint, the shape in current model is torch.Size([6])."
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "MFP PyTorch Demo - 修复版\n",
    "严格对齐训练代码的Masking机制\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "os.chdir(\"/home/dell/Project-HCL/BaseLine/flexdm_pt/scripts\")\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = ''  # 强制CPU模式\n",
    "\n",
    "import json\n",
    "import logging\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Optional\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# ⭐ 导入训练代码中使用的masking模块\n",
    "from masking_pytorch import (\n",
    "    get_task_names,\n",
    "    preprocess_for_train,\n",
    "    get_seq_mask,\n",
    ")\n",
    "\n",
    "print(f\"CUDA可用: {torch.cuda.is_available()}\")\n",
    "print(f\"设备数量: {torch.cuda.device_count()}\")\n",
    "\n",
    "from models_pytorch import MFP\n",
    "from dataset import DesignLayoutDataset\n",
    "from svg_builder_pytorch import SVGBuilder\n",
    "from retriever_pytorch import ImageRetriever, TextRetriever\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "print(\"✓ 导入完成（CPU模式）\\n\")\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 配置\n",
    "# ============================================================\n",
    "class DemoConfig:\n",
    "    def __init__(self):\n",
    "        self.ckpt_dir = \"/home/dell/Project-HCL/BaseLine/flexdm_pt/chechpoints\"\n",
    "        self.dataset_name = \"crello_json\"\n",
    "        self.db_root = \"/home/dell/Project-HCL/BaseLine/flexdm_pt/data/crello_json\"\n",
    "        self.batch_size = 10\n",
    "        self.device = 'cpu'\n",
    "        self.target_task = \"pos\"\n",
    "        \n",
    "        self.column_names = {\n",
    "            \"txt\": [\"gt-layout\", \"gt-visual\", \"input\", \"pred\"],\n",
    "            \"img\": [\"gt-layout\", \"gt-visual\", \"input\", \"pred\"],\n",
    "            \"attr\": [\"gt-layout\", \"gt-visual\", \"input\", \"pred\"],\n",
    "            \"pos\": [\"gt-layout\", \"gt-visual\", \"pred-layout\", \"pred-visual\"],\n",
    "            \"elem\": [\"gt-layout\", \"gt-visual\", \"input-layout\", \"input-visual\", \n",
    "                     \"pred-layout\", \"pred-visual\"],\n",
    "        }\n",
    "        \n",
    "        # ⭐ 任务ID映射（与训练代码一致）\n",
    "        self.task_name_to_id = {\n",
    "            \"type\": 0,\n",
    "            \"pos\": 1,\n",
    "            \"attr\": 2,\n",
    "            \"img\": 3,\n",
    "            \"txt\": 4,\n",
    "            \"elem\": 5,\n",
    "        }\n",
    "\n",
    "config = DemoConfig()\n",
    "print(f\"✓ 配置: device={config.device}, batch_size={config.batch_size}\\n\")\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 类型映射\n",
    "# ============================================================\n",
    "# DEFAULT_TYPE_MAPPING = {\n",
    "#     0: '', 1: 'svgElement', 2: 'textElement', 3: 'imageElement',\n",
    "#     4: 'coloredBackground', 5: 'maskElement', 6: 'humanElement',\n",
    "# }\n",
    "\n",
    "DEFAULT_TYPE_MAPPING = {\n",
    "    0: 'svgElement', 1: 'textElement', 2: 'imageElement', 3: 'coloredBackground',\n",
    "    4: 'maskElement', 5: ''\n",
    "}\n",
    "\n",
    "\n",
    "def load_type_mapping_from_vocab(vocab_file: str):\n",
    "    return DEFAULT_TYPE_MAPPING\n",
    "\n",
    "def load_font_mapping_from_dataset(dataset):\n",
    "    return dataset.idx_to_font if hasattr(dataset, 'idx_to_font') else {}\n",
    "\n",
    "def load_canvas_mappings_from_dataset(dataset):\n",
    "    width_mapping = dataset.idx_to_width if hasattr(dataset, 'idx_to_width') else {}\n",
    "    height_mapping = dataset.idx_to_height if hasattr(dataset, 'idx_to_height') else {}\n",
    "    return width_mapping, height_mapping\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 数据处理工具\n",
    "# ============================================================\n",
    "def _extract_scalar(tensor):\n",
    "    if tensor.dim() == 0:\n",
    "        return tensor.item()\n",
    "    elif tensor.dim() == 1:\n",
    "        return tensor[0].item() if tensor.size(0) == 1 else tensor.argmax().item()\n",
    "    else:\n",
    "        return tensor.argmax(dim=-1)[0].item() if tensor.size(0) > 0 else 0\n",
    "\n",
    "\n",
    "def tensor_to_list(data, type_mapping, font_mapping=None, \n",
    "                   width_mapping=None, height_mapping=None, bins=64):\n",
    "    batch_size = data['length'].size(0)\n",
    "    items = []\n",
    "    scale = 1.0 / (bins - 1.0)\n",
    "    \n",
    "    for i in range(batch_size):\n",
    "        # Canvas尺寸\n",
    "        canvas_w = 800\n",
    "        canvas_h = 600\n",
    "        \n",
    "        if 'canvas_width' in data:\n",
    "            width_idx = data['canvas_width'][i].item()\n",
    "            if width_mapping and width_idx in width_mapping:\n",
    "                canvas_w = width_mapping[width_idx]\n",
    "        \n",
    "        if 'canvas_height' in data:\n",
    "            height_idx = data['canvas_height'][i].item()\n",
    "            if height_mapping and height_idx in height_mapping:\n",
    "                canvas_h = height_mapping[height_idx]\n",
    "        \n",
    "        item = {\n",
    "            'id': data['id'][i] if 'id' in data else f'sample_{i}',\n",
    "            'canvas_width': canvas_w,\n",
    "            'canvas_height': canvas_h,\n",
    "            'length': data['length'][i].item(),\n",
    "            'elements': []\n",
    "        }\n",
    "        \n",
    "        for j in range(item['length']):\n",
    "            element = {}\n",
    "            \n",
    "            for key, value in data.items():\n",
    "                if key in ['id', 'length', 'canvas_width', 'canvas_height']:\n",
    "                    continue\n",
    "                if not torch.is_tensor(value):\n",
    "                    continue\n",
    "                if value.dim() < 2 or value.size(1) <= j:\n",
    "                    continue\n",
    "                \n",
    "                elem_value = value[i, j]\n",
    "                \n",
    "                if key == 'type':\n",
    "                    element[key] = type_mapping.get(int(_extract_scalar(elem_value)), '')\n",
    "                elif key == 'font_family' and font_mapping:\n",
    "                    element[key] = font_mapping.get(int(_extract_scalar(elem_value)), 'Arial')\n",
    "                elif key in ['left', 'top', 'width', 'height']:\n",
    "                    discrete_idx = _extract_scalar(elem_value)\n",
    "                    element[key] = float(np.clip(scale * discrete_idx, 0.0, 1.0))\n",
    "                elif key == 'color':\n",
    "                    if elem_value.dim() == 2 and elem_value.size(0) == 3:\n",
    "                        discrete_indices = elem_value.argmax(dim=-1).cpu().numpy()\n",
    "                        rgb = [int(idx * 255 / 15) for idx in discrete_indices]\n",
    "                        element[key] = rgb\n",
    "                    elif elem_value.dim() == 1 and elem_value.size(0) == 3:\n",
    "                        rgb = [int(idx * 255 / 15) for idx in elem_value.cpu().numpy()]\n",
    "                        element[key] = rgb\n",
    "                    else:\n",
    "                        element[key] = [128, 128, 128]\n",
    "                elif key == 'opacity':\n",
    "                    discrete_idx = _extract_scalar(elem_value)\n",
    "                    element[key] = float(discrete_idx / 7.0)\n",
    "                elif 'embedding' in key:\n",
    "                    element[key] = elem_value.cpu().numpy()\n",
    "                elif key == 'uuid':\n",
    "                    element[key] = str(_extract_scalar(elem_value))\n",
    "                else:\n",
    "                    element[key] = _extract_scalar(elem_value)\n",
    "            \n",
    "            item['elements'].append(element)\n",
    "        \n",
    "        items.append(item)\n",
    "    \n",
    "    return items\n",
    "\n",
    "\n",
    "def set_visual_default(item):\n",
    "    item = item.copy()\n",
    "    for elem in item.get('elements', []):\n",
    "        elem.setdefault('color', [128, 128, 128])\n",
    "        elem.setdefault('opacity', 1.0)\n",
    "        elem.setdefault('font_family', 'Arial')\n",
    "    return item\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 模型相关（纯CPU版本）\n",
    "# ============================================================\n",
    "def load_model(checkpoint_path, input_columns):\n",
    "    \"\"\"加载模型 - 强制CPU\"\"\"\n",
    "    print(f\"加载模型: {checkpoint_path}\")\n",
    "    \n",
    "    model = MFP(\n",
    "        input_columns=input_columns,\n",
    "        embed_dim=256,\n",
    "        num_blocks=4,\n",
    "        num_heads=8,\n",
    "        dropout=0.1,\n",
    "    )\n",
    "    \n",
    "    checkpoint = torch.load(checkpoint_path, map_location='cpu')\n",
    "    \n",
    "    # ⭐ 处理不同的checkpoint格式\n",
    "    if 'model_state_dict' in checkpoint:\n",
    "        state_dict = checkpoint['model_state_dict']\n",
    "    elif 'state_dict' in checkpoint:\n",
    "        state_dict = checkpoint['state_dict']\n",
    "    else:\n",
    "        state_dict = checkpoint\n",
    "    \n",
    "    missing, unexpected = model.load_state_dict(state_dict, strict=False)\n",
    "    \n",
    "    if missing:\n",
    "        print(f\"  警告: 缺失 {len(missing)} 个键\")\n",
    "    if unexpected:\n",
    "        print(f\"  警告: 多余 {len(unexpected)} 个键\")\n",
    "    \n",
    "    model.eval()\n",
    "    print(\"✓ 模型加载完成（CPU）\\n\")\n",
    "    return model\n",
    "\n",
    "\n",
    "def model_inference_with_masking(model, inputs, input_columns, task_name):\n",
    "    \"\"\"\n",
    "    使用训练代码中相同的masking机制进行推理\n",
    "    \n",
    "    Args:\n",
    "        model: MFP模型\n",
    "        inputs: 输入数据字典\n",
    "        input_columns: 输入列配置\n",
    "        task_name: 任务名称 ('pos', 'elem', 'attr', 'txt', 'img')\n",
    "    \n",
    "    Returns:\n",
    "        outputs: 模型预测结果\n",
    "        modified_inputs: 应用mask后的输入\n",
    "        masks: mask字典\n",
    "    \"\"\"\n",
    "    # ⭐ 获取任务ID（与训练代码一致）\n",
    "    task_name_to_id = {\n",
    "        \"type\": 0, \"pos\": 1, \"attr\": 2, \n",
    "        \"img\": 3, \"txt\": 4, \"elem\": 5,\n",
    "    }\n",
    "    task_id = task_name_to_id.get(task_name, 1)\n",
    "    \n",
    "    # ⭐ 使用训练代码中的preprocess_for_train函数\n",
    "    targets, modified_inputs, masks = preprocess_for_train(\n",
    "        inputs,\n",
    "        input_columns,\n",
    "        task_id,\n",
    "        is_autoreg=False,  # demo使用非自回归模式\n",
    "    )\n",
    "    \n",
    "    # 确保所有数据在CPU上\n",
    "    for key in modified_inputs:\n",
    "        if torch.is_tensor(modified_inputs[key]):\n",
    "            modified_inputs[key] = modified_inputs[key].cpu()\n",
    "    \n",
    "    # 模型推理\n",
    "    with torch.no_grad():\n",
    "        outputs = model(modified_inputs)\n",
    "    \n",
    "    return outputs, modified_inputs, masks\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 可视化主函数（修复版）\n",
    "# ============================================================\n",
    "def visualize_reconstruction(model, example, builders, config, input_columns,\n",
    "                            type_mapping, font_mapping=None, width_mapping=None, \n",
    "                            height_mapping=None, bins=64):\n",
    "    \"\"\"\n",
    "    可视化重建结果 - 使用与训练代码一致的masking机制\n",
    "    \"\"\"\n",
    "    svgs = []\n",
    "    target_task = config.target_task\n",
    "    \n",
    "    # 确保数据在CPU\n",
    "    for key in example:\n",
    "        if torch.is_tensor(example[key]):\n",
    "            example[key] = example[key].cpu()\n",
    "    \n",
    "    items = tensor_to_list(example, type_mapping, font_mapping, \n",
    "                          width_mapping, height_mapping, bins)\n",
    "    \n",
    "    print(f\"渲染 {len(items)} 个样本...\")\n",
    "    \n",
    "    # GT\n",
    "    print(\"  - GT Layout\")\n",
    "    svgs.append([builders[\"layout\"](item) for item in items])\n",
    "    print(\"  - GT Visual\")\n",
    "    svgs.append([builders[\"visual\"](item) for item in items])\n",
    "    \n",
    "    # 输入视图（根据任务类型显示）\n",
    "    if target_task == \"txt\":\n",
    "        print(\"  - Input (无文本)\")\n",
    "        svgs.append([builders[\"visual_wo_text\"](item) for item in items])\n",
    "    elif target_task == \"img\":\n",
    "        print(\"  - Input (无图像)\")\n",
    "        svgs.append([builders[\"visual_wo_image\"](item) for item in items])\n",
    "    elif target_task == \"attr\":\n",
    "        print(\"  - Input (默认属性)\")\n",
    "        svgs.append([builders[\"visual\"](set_visual_default(item)) for item in items])\n",
    "    \n",
    "    # ⭐ 使用训练代码的masking机制进行推理\n",
    "    print(f\"  - 模型推理 (任务: {target_task})\")\n",
    "    outputs, modified_inputs, masks = model_inference_with_masking(\n",
    "        model, example, input_columns, target_task\n",
    "    )\n",
    "    \n",
    "    # 元素级任务的输入视图\n",
    "    if target_task == \"elem\":\n",
    "        # 显示去掉第一个元素后的输入\n",
    "        example_copy = {}\n",
    "        for key, value in modified_inputs.items():\n",
    "            if isinstance(value, torch.Tensor) and value.dim() >= 2:\n",
    "                if value.size(1) > 1:\n",
    "                    example_copy[key] = value[:, 1:]  # 去掉第一个元素\n",
    "                else:\n",
    "                    example_copy[key] = value\n",
    "            else:\n",
    "                example_copy[key] = value\n",
    "        \n",
    "        # 调整length\n",
    "        if 'length' in example:\n",
    "            example_copy['length'] = torch.clamp(example['length'] - 1, min=1)\n",
    "        \n",
    "        items_copy = tensor_to_list(example_copy, type_mapping, font_mapping,\n",
    "                                    width_mapping, height_mapping, bins)\n",
    "        print(\"  - Input Layout (去掉第一个元素)\")\n",
    "        svgs.append([builders[\"layout\"](item) for item in items_copy])\n",
    "        print(\"  - Input Visual (去掉第一个元素)\")\n",
    "        svgs.append([builders[\"visual\"](item) for item in items_copy])\n",
    "    \n",
    "    # ⭐ 合并预测结果和原始输入\n",
    "    pred = {}\n",
    "    for key in example:\n",
    "        if key in outputs:\n",
    "            pred[key] = outputs[key]\n",
    "        else:\n",
    "            pred[key] = example[key]\n",
    "    \n",
    "    # 对于categorical类型，需要从logits转换\n",
    "    for key, value in outputs.items():\n",
    "        column = input_columns.get(key, {})\n",
    "        if column.get('type') == 'categorical' and value.dim() >= 3:\n",
    "            # 如果是logits，取argmax\n",
    "            if value.size(-1) > 1:\n",
    "                pred[key] = value.argmax(dim=-1)\n",
    "    \n",
    "    pred_items = tensor_to_list(pred, type_mapping, font_mapping,\n",
    "                                width_mapping, height_mapping, bins)\n",
    "    \n",
    "    # 预测结果视图\n",
    "    if target_task in [\"pos\", \"elem\"]:\n",
    "        print(\"  - Pred Layout\")\n",
    "        svgs.append([builders[\"layout\"](item) for item in pred_items])\n",
    "    \n",
    "    print(\"  - Pred Visual\")\n",
    "    svgs.append([builders[\"visual\"](item) for item in pred_items])\n",
    "    \n",
    "    print(\"✓ 渲染完成\\n\")\n",
    "    return list(zip(*svgs))\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 主流程\n",
    "# ============================================================\n",
    "print(\"=\"*80)\n",
    "print(\"MFP PyTorch Demo - 修复版（对齐训练代码）\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# 1. 加载数据集\n",
    "print(\"\\n1. 加载数据集\")\n",
    "dataset = DesignLayoutDataset(config.db_root, split='test', max_length=20)\n",
    "print(f\"✓ 数据集大小: {len(dataset)}\\n\")\n",
    "\n",
    "# 2. 加载映射\n",
    "print(\"2. 加载映射\")\n",
    "vocab_file = Path(config.db_root).parent / \"vocabulary.json\"\n",
    "type_mapping = load_type_mapping_from_vocab(str(vocab_file))\n",
    "font_mapping = load_font_mapping_from_dataset(dataset)\n",
    "width_mapping, height_mapping = load_canvas_mappings_from_dataset(dataset)\n",
    "\n",
    "if font_mapping:\n",
    "    print(f\"✓ 字体映射: {len(font_mapping)} 个字体\")\n",
    "if width_mapping:\n",
    "    print(f\"✓ Width映射: {len(width_mapping)} 个尺寸\")\n",
    "if height_mapping:\n",
    "    print(f\"✓ Height映射: {len(height_mapping)} 个尺寸\")\n",
    "print()\n",
    "\n",
    "# 3. 创建DataLoader\n",
    "print(\"3. 创建DataLoader\")\n",
    "from torch.utils.data import DataLoader\n",
    "from dataset import collate_fn\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=config.batch_size, \n",
    "                       shuffle=False, collate_fn=collate_fn)\n",
    "example = next(iter(dataloader))\n",
    "\n",
    "# 强制转CPU\n",
    "for key in example:\n",
    "    if torch.is_tensor(example[key]):\n",
    "        example[key] = example[key].cpu()\n",
    "\n",
    "print(f\"✓ 批次形状: {example['left'].shape}\\n\")\n",
    "\n",
    "# 4. 加载配置\n",
    "print(\"4. 加载模型配置\")\n",
    "input_columns_file = './input_columns_dataset.json'\n",
    "\n",
    "with open(input_columns_file, 'r') as f:\n",
    "    input_columns = json.load(f)\n",
    "\n",
    "# ⭐ 打印任务信息（与训练代码一致）\n",
    "task_names = get_task_names(input_columns)\n",
    "print(f\"✓ 输入列数: {len(input_columns)}\")\n",
    "print(f\"✓ 任务列表: {task_names}\\n\")\n",
    "\n",
    "# 5. 加载模型\n",
    "print(\"5. 加载模型\")\n",
    "checkpoint_path = \"/home/dell/Project-HCL/BaseLine/flexdm_pt/checkpoints/retrain_v1/best.pth\"\n",
    "model = load_model(str(checkpoint_path), input_columns)\n",
    "\n",
    "# 6. 构建检索数据库\n",
    "print(\"6. 构建检索数据库\")\n",
    "db_root = Path(config.db_root).parent / config.dataset_name\n",
    "image_db = ImageRetriever(db_root, image_path=db_root / \"images\")\n",
    "image_db.build(\"test\")\n",
    "text_db = TextRetriever(db_root, text_path=db_root / \"texts\")\n",
    "text_db.build(\"test\")\n",
    "print()\n",
    "\n",
    "# 7. 创建SVG构建器\n",
    "print(\"7. 创建SVG构建器\")\n",
    "builders = {\n",
    "    \"layout\": SVGBuilder(key='type', max_width=128, max_height=192, opacity=0.8),\n",
    "    \"visual\": SVGBuilder(key='color', max_width=128, max_height=192, \n",
    "                        image_db=image_db, text_db=text_db, \n",
    "                        render_text=True, opacity=1.0),\n",
    "    \"visual_wo_text\": SVGBuilder(key='color', max_width=128, max_height=192,\n",
    "                                 image_db=image_db, text_db=None, \n",
    "                                 render_text=False, opacity=1.0),\n",
    "    \"visual_wo_image\": SVGBuilder(key='color', max_width=128, max_height=192,\n",
    "                                  image_db=None, text_db=text_db, \n",
    "                                  render_text=True, opacity=1.0),\n",
    "}\n",
    "print(\"✓ 构建器创建完成\\n\")\n",
    "\n",
    "# 8. 运行可视化\n",
    "print(\"=\"*80)\n",
    "print(f\"8. 开始可视化 - 任务: {config.target_task}\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "svgs = visualize_reconstruction(model, example, builders, config, input_columns,\n",
    "                                type_mapping, font_mapping, width_mapping, \n",
    "                                height_mapping, bins=64)\n",
    "\n",
    "print(f\"✓ 生成了 {len(svgs)} 个样本的可视化结果\")\n",
    "print(f\"列名: {config.column_names[config.target_task]}\\n\")\n",
    "\n",
    "# 9. 显示结果\n",
    "print(\"=\"*80)\n",
    "print(\"可视化结果:\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for i, row in enumerate(svgs[:10]):\n",
    "    print(f\"\\nSample {i}:\")\n",
    "    display(HTML(\"<div style='margin: 10px 0;'>%s</div>\" % \" \".join(row)))\n",
    "\n",
    "print(\"\\n✓ Demo完成!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ptfd311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
