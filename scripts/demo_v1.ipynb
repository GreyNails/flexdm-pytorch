{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ 导入完成\n",
      "✓ 配置完成\n",
      "  - 设备: cuda\n",
      "  - 任务: pos\n",
      "  - 批次大小: 20\n",
      "================================================================================\n",
      "MFP PyTorch Demo - Jupyter Notebook版本\n",
      "================================================================================\n",
      "\n",
      "1. 加载数据集\n",
      "加载数据: /home/dell/Project-HCL/BaseLine/flexdm_pt/data/crello_json/test.json\n",
      "✓ 加载了 2248 个样本\n",
      "\n",
      "构建查找表...\n",
      "  Type词汇表: 7 个类型\n",
      "  Canvas Width词汇表: 41 个尺寸\n",
      "    范围: 160 - 3000\n",
      "  Canvas Height词汇表: 46 个尺寸\n",
      "    范围: 90 - 2560\n",
      "  Font过滤: 290 -> 34 (频率>=500)\n",
      "  Font词汇表: 37 个token (含特殊token)\n",
      "✓ 数据集大小: 2248\n",
      "\n",
      "2. 加载类型映射\n",
      "\n",
      "3. 加载字体映射\n",
      "✓ 字体映射: 37 个字体\n",
      "\n",
      "4. 加载Canvas尺寸映射\n",
      "✓ Width映射: 42 个尺寸\n",
      "  范围: 160 - 3000\n",
      "✓ Height映射: 47 个尺寸\n",
      "  范围: 90 - 2560\n",
      "\n",
      "5. 创建DataLoader\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Building ImageRetriever index for test...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ 批次形状: torch.Size([20, 20, 1])\n",
      "\n",
      "6. 加载模型配置\n",
      "✓ 输入列数: 15\n",
      "\n",
      "7. 加载模型\n",
      "\n",
      "============================================================\n",
      "初始化MFP模型\n",
      "============================================================\n",
      "初始化Encoder:\n",
      "  type: Embedding(7, 256)\n",
      "  left: Embedding(66, 256)\n",
      "  top: Embedding(66, 256)\n",
      "  width: Embedding(66, 256)\n",
      "  height: Embedding(66, 256)\n",
      "  opacity: Embedding(10, 256)\n",
      "  color: Embedding(18, 256)\n",
      "  image_embedding: Linear(512, 256)\n",
      "  text_embedding: Linear(512, 256)\n",
      "  font_family: Embedding(36, 256)\n",
      "总计: 10 个特征\n",
      "\n",
      "初始化Transformer:\n",
      "  blocks=4, embed_dim=256, num_heads=8\n",
      "\n",
      "初始化Decoder:\n",
      "  type: Linear(256, 5) -> (1, 5)\n",
      "  left: Linear(256, 64) -> (1, 64)\n",
      "  top: Linear(256, 64) -> (1, 64)\n",
      "  width: Linear(256, 64) -> (1, 64)\n",
      "  height: Linear(256, 64) -> (1, 64)\n",
      "  opacity: Linear(256, 8) -> (1, 8)\n",
      "  color: Linear(256, 48) -> (3, 16)\n",
      "  image_embedding: Linear(256, 512)\n",
      "  text_embedding: Linear(256, 512)\n",
      "  font_family: Linear(256, 34) -> (1, 34)\n",
      "总计: 10 个输出头\n",
      "\n",
      "总参数数: 2,823,263\n",
      "============================================================\n",
      "\n",
      "  警告: 缺失 97 个键\n",
      "  警告: 多余 84 个键\n",
      "✓ 模型加载成功\n",
      "\n",
      "8. 构建检索数据库\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Embeddings shape: (11306, 512), dtype: float32, C-contiguous: True\n",
      "INFO: ✓ Built index with 11306 items\n",
      "INFO: Building TextRetriever index for test...\n",
      "INFO: Embeddings shape: (6973, 512), dtype: float32, C-contiguous: True\n",
      "INFO: ✓ Built index with 6973 items\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "9. 创建SVG构建器\n",
      "✓ 构建器创建完成\n",
      "\n",
      "================================================================================\n",
      "10. 开始可视化 - 任务: pos\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "MFP PyTorch Demo - Jupyter Notebook版本（完整版）\n",
    "直接在notebook中显示SVG可视化结果\n",
    "支持canvas_width和canvas_height的Lookup方法\n",
    "\"\"\"\n",
    "\n",
    "# ============================================================\n",
    "# Cell 1: 导入依赖\n",
    "# ============================================================\n",
    "import json\n",
    "import itertools\n",
    "import logging\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Optional\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from IPython.display import display, HTML\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 导入自定义模块\n",
    "from models_pytorch import MFP\n",
    "from dataset import DesignLayoutDataset\n",
    "from svg_builder_pytorch import SVGBuilder\n",
    "from retriever_pytorch import ImageRetriever, TextRetriever\n",
    "\n",
    "# 配置日志\n",
    "logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# 设置随机种子\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "print(\"✓ 导入完成\")\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Cell 2: 配置参数\n",
    "# ============================================================\n",
    "class DemoConfig:\n",
    "    \"\"\"演示配置\"\"\"\n",
    "    def __init__(self):\n",
    "        self.ckpt_dir = \"/home/dell/Project-HCL/BaseLine/flexdm_pt/chechpoints\"\n",
    "        self.dataset_name = \"crello_json\"\n",
    "        self.db_root = \"/home/dell/Project-HCL/BaseLine/flexdm_pt/data/crello_json\"\n",
    "        self.batch_size = 20\n",
    "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        \n",
    "        # 任务类型: elem, pos, attr, txt, img\n",
    "        self.target_task = \"pos\"\n",
    "        \n",
    "        # 列名配置\n",
    "        self.column_names = {\n",
    "            \"txt\": [\"gt-layout\", \"gt-visual\", \"input\", \"pred\"],\n",
    "            \"img\": [\"gt-layout\", \"gt-visual\", \"input\", \"pred\"],\n",
    "            \"attr\": [\"gt-layout\", \"gt-visual\", \"input\", \"pred\"],\n",
    "            \"pos\": [\"gt-layout\", \"gt-visual\", \"pred-layout\", \"pred-visual\"],\n",
    "            \"elem\": [\"gt-layout\", \"gt-visual\", \"input-layout\", \"input-visual\", \"pred-layout\", \"pred-visual\"],\n",
    "        }\n",
    "        \n",
    "        # 属性分组\n",
    "        self.attribute_groups = {\n",
    "            \"type\": [\"type\"],\n",
    "            \"pos\": [\"left\", \"top\", \"width\", \"height\"],\n",
    "            \"attr\": [\"opacity\", \"color\", \"font_family\"],\n",
    "            \"img\": [\"image_embedding\"],\n",
    "            \"txt\": [\"text_embedding\"],\n",
    "        }\n",
    "\n",
    "config = DemoConfig()\n",
    "print(f\"✓ 配置完成\")\n",
    "print(f\"  - 设备: {config.device}\")\n",
    "print(f\"  - 任务: {config.target_task}\")\n",
    "print(f\"  - 批次大小: {config.batch_size}\")\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Cell 3: 类型映射工具\n",
    "# ============================================================\n",
    "DEFAULT_TYPE_MAPPING = {\n",
    "    0: '',\n",
    "    1: 'svgElement',\n",
    "    2: 'textElement',\n",
    "    3: 'imageElement',\n",
    "    4: 'coloredBackground',\n",
    "    5: 'maskElement',\n",
    "    6: 'humanElement',\n",
    "}\n",
    "\n",
    "def load_type_mapping_from_vocab(vocab_file: str) -> Dict[int, str]:\n",
    "    \"\"\"从vocabulary.json加载类型映射\"\"\"\n",
    "    return DEFAULT_TYPE_MAPPING\n",
    "\n",
    "    # try:\n",
    "    #     with open(vocab_file, 'r') as f:\n",
    "    #         vocab = json.load(f)\n",
    "        \n",
    "    #     type_vocab = vocab.get('type', {})\n",
    "        \n",
    "    #     if isinstance(type_vocab, dict):\n",
    "    #         type_list = sorted(type_vocab.keys())\n",
    "    #     elif isinstance(type_vocab, list):\n",
    "    #         type_list = type_vocab\n",
    "    #     else:\n",
    "    #         return DEFAULT_TYPE_MAPPING\n",
    "        \n",
    "    #     id_to_name = {0: ''}\n",
    "    #     for i, name in enumerate(type_list):\n",
    "    #         id_to_name[i + 1] = name\n",
    "        \n",
    "    #     print(\"✓ 类型映射:\")\n",
    "    #     for idx, name in sorted(id_to_name.items()):\n",
    "    #         if name:\n",
    "    #             print(f\"    {idx}: {name}\")\n",
    "        \n",
    "    #     return id_to_name\n",
    "        \n",
    "    # except Exception as e:\n",
    "    #     print(f\"警告: 加载类型映射失败 ({e})，使用默认映射\")\n",
    "    #     return DEFAULT_TYPE_MAPPING\n",
    "\n",
    "\n",
    "def load_font_mapping_from_dataset(dataset) -> Dict[int, str]:\n",
    "    \"\"\"从数据集加载字体映射\"\"\"\n",
    "    if hasattr(dataset, 'idx_to_font'):\n",
    "        return dataset.idx_to_font\n",
    "    return {}\n",
    "\n",
    "\n",
    "def load_canvas_mappings_from_dataset(dataset) -> tuple:\n",
    "    \"\"\"从数据集加载canvas尺寸映射\"\"\"\n",
    "    width_mapping = {}\n",
    "    height_mapping = {}\n",
    "    \n",
    "    if hasattr(dataset, 'idx_to_width'):\n",
    "        width_mapping = dataset.idx_to_width\n",
    "    \n",
    "    if hasattr(dataset, 'idx_to_height'):\n",
    "        height_mapping = dataset.idx_to_height\n",
    "    \n",
    "    return width_mapping, height_mapping\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Cell 4: 数据处理工具\n",
    "# ============================================================\n",
    "def _extract_scalar(tensor):\n",
    "    \"\"\"从张量中提取标量值\"\"\"\n",
    "    if tensor.dim() == 0:\n",
    "        return tensor.item()\n",
    "    elif tensor.dim() == 1:\n",
    "        if tensor.size(0) == 1:\n",
    "            return tensor[0].item()\n",
    "        else:\n",
    "            return tensor.argmax().item()\n",
    "    else:\n",
    "        return tensor.argmax(dim=-1)[0].item() if tensor.size(0) > 0 else 0\n",
    "\n",
    "\n",
    "def tensor_to_list(\n",
    "    data: Dict,\n",
    "    type_mapping: Dict[int, str],\n",
    "    font_mapping: Optional[Dict[int, str]] = None,\n",
    "    width_mapping: Optional[Dict[int, int]] = None,\n",
    "    height_mapping: Optional[Dict[int, int]] = None,\n",
    "    bins: int = 64  # 离散化的bins数量\n",
    ") -> List[Dict]:\n",
    "    \"\"\"将批次张量转换为样本列表（支持canvas Lookup）\"\"\"\n",
    "    batch_size = data['length'].size(0)\n",
    "    items = []\n",
    "    \n",
    "    # 位置字段的去离散化参数\n",
    "    position_spec = {\n",
    "        'min': 0.0,\n",
    "        'max': 1.0,\n",
    "        'bins': bins\n",
    "    }\n",
    "    scale = (position_spec['max'] - position_spec['min']) / (position_spec['bins'] - 1.0)\n",
    "    \n",
    "    for i in range(batch_size):\n",
    "        # Canvas尺寸 - 从索引转换回实际值\n",
    "        if 'canvas_width' in data:\n",
    "            width_idx = data['canvas_width'][i].item()\n",
    "            if width_mapping and width_idx in width_mapping:\n",
    "                canvas_w = width_mapping[width_idx]\n",
    "            else:\n",
    "                canvas_w = 800\n",
    "        else:\n",
    "            canvas_w = 800\n",
    "        \n",
    "        if 'canvas_height' in data:\n",
    "            height_idx = data['canvas_height'][i].item()\n",
    "            if height_mapping and height_idx in height_mapping:\n",
    "                canvas_h = height_mapping[height_idx]\n",
    "            else:\n",
    "                canvas_h = 600\n",
    "        else:\n",
    "            canvas_h = 600\n",
    "        \n",
    "        item = {\n",
    "            'id': data['id'][i] if 'id' in data else f'sample_{i}',\n",
    "            'canvas_width': canvas_w,\n",
    "            'canvas_height': canvas_h,\n",
    "            'length': data['length'][i].item(),\n",
    "            'elements': []\n",
    "        }\n",
    "        \n",
    "        num_elements = item['length']\n",
    "        \n",
    "        for j in range(num_elements):\n",
    "            element = {}\n",
    "            \n",
    "            for key, value in data.items():\n",
    "                if key in ['id', 'length', 'canvas_width', 'canvas_height']:\n",
    "                    continue\n",
    "                \n",
    "                if not torch.is_tensor(value):\n",
    "                    continue\n",
    "                \n",
    "                if value.dim() >= 2 and value.size(1) > j:\n",
    "                    elem_value = value[i, j]\n",
    "                    \n",
    "                    if key == 'type':\n",
    "                        type_id = _extract_scalar(elem_value)\n",
    "                        element[key] = type_mapping.get(int(type_id), '')\n",
    "                        continue\n",
    "                    \n",
    "                    if key == 'font_family' and font_mapping:\n",
    "                        font_id = _extract_scalar(elem_value)\n",
    "                        element[key] = font_mapping.get(int(font_id), 'Arial')\n",
    "                        continue\n",
    "                    \n",
    "                    # 位置和尺寸：离散化索引 -> 归一化值 (0-1)\n",
    "                    if key in ['left', 'top', 'width', 'height']:\n",
    "                        discrete_idx = _extract_scalar(elem_value)\n",
    "                        # 去离散化：index -> normalized value\n",
    "                        normalized_val = scale * discrete_idx + position_spec['min']\n",
    "                        element[key] = float(np.clip(normalized_val, 0.0, 1.0))\n",
    "                        continue\n",
    "                    \n",
    "                    if key == 'color':\n",
    "                        if elem_value.dim() >= 1 and elem_value.size(-1) >= 3:\n",
    "                            element[key] = elem_value[:3].cpu().numpy().tolist()\n",
    "                        else:\n",
    "                            element[key] = [128, 128, 128]\n",
    "                        continue\n",
    "                    \n",
    "                    if key in ['opacity']:\n",
    "                        element[key] = _extract_scalar(elem_value)\n",
    "                        continue\n",
    "                    \n",
    "                    if 'embedding' in key:\n",
    "                        element[key] = elem_value.cpu().numpy()\n",
    "                        continue\n",
    "                    \n",
    "                    if key == 'uuid':\n",
    "                        element[key] = str(_extract_scalar(elem_value))\n",
    "                        continue\n",
    "                    \n",
    "                    element[key] = _extract_scalar(elem_value)\n",
    "            \n",
    "            item['elements'].append(element)\n",
    "        \n",
    "        items.append(item)\n",
    "    \n",
    "    return items\n",
    "\n",
    "def get_seq_mask(lengths: torch.Tensor, max_len: int = None) -> torch.Tensor:\n",
    "    \"\"\"生成序列掩码\"\"\"\n",
    "    if lengths.dim() == 2:\n",
    "        lengths = lengths.squeeze(-1)\n",
    "    \n",
    "    if max_len is None:\n",
    "        max_len = lengths.max().item()\n",
    "    \n",
    "    mask = torch.arange(max_len, device=lengths.device).unsqueeze(0) < lengths.unsqueeze(1)\n",
    "    return mask\n",
    "\n",
    "\n",
    "def get_initial_masks(input_columns: Dict, seq_mask: torch.Tensor) -> Dict[str, torch.Tensor]:\n",
    "    \"\"\"初始化掩码字典\"\"\"\n",
    "    masks = {}\n",
    "    batch_size, seq_len = seq_mask.shape\n",
    "    \n",
    "    for key, column in input_columns.items():\n",
    "        if column.get('is_sequence', False):\n",
    "            masks[key] = torch.zeros_like(seq_mask, dtype=torch.bool)\n",
    "        else:\n",
    "            masks[key] = torch.ones(batch_size, dtype=torch.bool)\n",
    "    \n",
    "    return masks\n",
    "\n",
    "\n",
    "def set_visual_default(item: Dict) -> Dict:\n",
    "    \"\"\"设置可视化默认值\"\"\"\n",
    "    item = item.copy()\n",
    "    for elem in item.get('elements', []):\n",
    "        if 'color' not in elem or elem['color'] is None:\n",
    "            elem['color'] = [128, 128, 128]\n",
    "        if 'opacity' not in elem or elem['opacity'] is None:\n",
    "            elem['opacity'] = 1.0\n",
    "        if 'font_family' not in elem or elem['font_family'] is None:\n",
    "            elem['font_family'] = 'Arial'\n",
    "    return item\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Cell 5: 模型相关\n",
    "# ============================================================\n",
    "def load_model(checkpoint_path: str, input_columns: Dict, device: str = 'cuda'):\n",
    "    \"\"\"加载PyTorch模型\"\"\"\n",
    "    model = MFP(\n",
    "        input_columns=input_columns,\n",
    "        embed_dim=256,\n",
    "        num_blocks=4,\n",
    "        num_heads=8,\n",
    "        dropout=0.1,\n",
    "    )\n",
    "    \n",
    "    checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "    state_dict = checkpoint.get('state_dict', checkpoint)\n",
    "    \n",
    "    missing, unexpected = model.load_state_dict(state_dict, strict=False)\n",
    "    \n",
    "    if missing:\n",
    "        print(f\"  警告: 缺失 {len(missing)} 个键\")\n",
    "    if unexpected:\n",
    "        print(f\"  警告: 多余 {len(unexpected)} 个键\")\n",
    "    \n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    print(f\"✓ 模型加载成功\")\n",
    "    return model\n",
    "\n",
    "\n",
    "def apply_task_masks(\n",
    "    example: Dict,\n",
    "    input_columns: Dict,\n",
    "    target_task: str,\n",
    "    attribute_groups: Dict,\n",
    "    device: str\n",
    ") -> Dict[str, torch.Tensor]:\n",
    "    \"\"\"应用任务特定的掩码\"\"\"\n",
    "    seq_mask = get_seq_mask(example['length'], example['left'].size(1))\n",
    "    mfp_masks = get_initial_masks(input_columns, seq_mask)\n",
    "    \n",
    "    for key in mfp_masks.keys():\n",
    "        if not input_columns[key].get('is_sequence', False):\n",
    "            continue\n",
    "        \n",
    "        mask = mfp_masks[key].clone()\n",
    "        \n",
    "        if target_task == \"elem\":\n",
    "            mask[:, 0] = True\n",
    "        else:\n",
    "            if key == \"type\":\n",
    "                continue\n",
    "            \n",
    "            if target_task in attribute_groups:\n",
    "                attr_keys = attribute_groups[target_task]\n",
    "                if key in attr_keys:\n",
    "                    mask = seq_mask.clone()\n",
    "        \n",
    "        mfp_masks[key] = mask.to(device)\n",
    "    \n",
    "    return mfp_masks\n",
    "\n",
    "\n",
    "def model_inference_with_masks(model, inputs, masks):\n",
    "    \"\"\"使用掩码进行模型推理\"\"\"\n",
    "    masked_inputs = {}\n",
    "    for key, value in inputs.items():\n",
    "        if key in masks and torch.is_tensor(value):\n",
    "            mask = masks[key]\n",
    "            if mask.any():\n",
    "                masked_value = value.clone()\n",
    "                if value.dim() == 3:\n",
    "                    masked_value[mask] = 0\n",
    "                masked_inputs[key] = masked_value\n",
    "            else:\n",
    "                masked_inputs[key] = value\n",
    "        else:\n",
    "            masked_inputs[key] = value\n",
    "    \n",
    "    outputs = model(masked_inputs)\n",
    "    return outputs\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Cell 6: 可视化主函数\n",
    "# ============================================================\n",
    "def visualize_reconstruction(\n",
    "    model: torch.nn.Module,\n",
    "    example: Dict,\n",
    "    builders: Dict,\n",
    "    config: DemoConfig,\n",
    "    input_columns: Dict,\n",
    "    type_mapping: Dict[int, str],\n",
    "    font_mapping: Optional[Dict[int, str]] = None,\n",
    "    width_mapping: Optional[Dict[int, int]] = None,\n",
    "    height_mapping: Optional[Dict[int, int]] = None,\n",
    "    bins: int = 64  # 添加bins参数\n",
    "):\n",
    "    \"\"\"可视化重建结果\"\"\"\n",
    "    svgs = []\n",
    "    target_task = config.target_task\n",
    "    \n",
    "    # 转换为列表（传入bins参数）\n",
    "    items = tensor_to_list(\n",
    "        example, type_mapping, font_mapping, \n",
    "        width_mapping, height_mapping, bins\n",
    "    )\n",
    "    \n",
    "    print(f\"渲染 {len(items)} 个样本...\")\n",
    "    \n",
    "    # GT Layout\n",
    "    print(\"  - GT Layout\")\n",
    "    svgs.append([builders[\"layout\"](item) for item in items])\n",
    "    \n",
    "    # GT Visual\n",
    "    print(\"  - GT Visual\")\n",
    "    svgs.append([builders[\"visual\"](item) for item in items])\n",
    "    \n",
    "    # 输入视图\n",
    "    if target_task == \"txt\":\n",
    "        print(\"  - Input (无文本)\")\n",
    "        svgs.append([builders[\"visual_wo_text\"](item) for item in items])\n",
    "    elif target_task == \"img\":\n",
    "        print(\"  - Input (无图像)\")\n",
    "        svgs.append([builders[\"visual_wo_image\"](item) for item in items])\n",
    "    elif target_task == \"attr\":\n",
    "        print(\"  - Input (默认属性)\")\n",
    "        svgs.append([builders[\"visual\"](set_visual_default(item)) for item in items])\n",
    "    \n",
    "    # 应用掩码\n",
    "    mfp_masks = apply_task_masks(\n",
    "        example, input_columns, target_task,\n",
    "        config.attribute_groups, config.device\n",
    "    )\n",
    "    \n",
    "    # 元素级任务\n",
    "    if target_task == \"elem\":\n",
    "        example_copy = {}\n",
    "        for key, value in example.items():\n",
    "            if isinstance(value, torch.Tensor) and value.dim() >= 2 and value.size(1) > 1:\n",
    "                indices = torch.where(~mfp_masks[key][0, :])[0]\n",
    "                example_copy[key] = torch.index_select(value, 1, indices)\n",
    "            else:\n",
    "                example_copy[key] = value\n",
    "        \n",
    "        example_copy['length'] = example['length'] - 1\n",
    "        \n",
    "        # 转换时传入bins\n",
    "        items_copy = tensor_to_list(\n",
    "            example_copy, type_mapping, font_mapping,\n",
    "            width_mapping, height_mapping, bins\n",
    "        )\n",
    "        svgs.append([builders[\"layout\"](item) for item in items_copy])\n",
    "        svgs.append([builders[\"visual\"](item) for item in items_copy])\n",
    "    \n",
    "    # 模型预测\n",
    "    print(\"  - 模型推理\")\n",
    "    with torch.no_grad():\n",
    "        pred = model_inference_with_masks(model, example, mfp_masks)\n",
    "    \n",
    "    for key in example:\n",
    "        if key not in pred:\n",
    "            pred[key] = example[key]\n",
    "    \n",
    "    # 转换预测结果（传入bins）\n",
    "    pred_items = tensor_to_list(\n",
    "        pred, type_mapping, font_mapping,\n",
    "        width_mapping, height_mapping, bins\n",
    "    )\n",
    "    \n",
    "    if target_task in [\"pos\", \"elem\"]:\n",
    "        print(\"  - Pred Layout\")\n",
    "        svgs.append([builders[\"layout\"](item) for item in pred_items])\n",
    "    \n",
    "    print(\"  - Pred Visual\")\n",
    "    svgs.append([builders[\"visual\"](item) for item in pred_items])\n",
    "    \n",
    "    print(\"✓ 渲染完成\")\n",
    "    \n",
    "    return list(zip(*svgs))\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Cell 7: 加载数据和模型\n",
    "# ============================================================\n",
    "print(\"=\"*80)\n",
    "print(\"MFP PyTorch Demo - Jupyter Notebook版本\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# 加载数据集\n",
    "print(\"\\n1. 加载数据集\")\n",
    "dataset = DesignLayoutDataset(\n",
    "    config.db_root,\n",
    "    split='test',\n",
    "    max_length=20\n",
    ")\n",
    "print(f\"✓ 数据集大小: {len(dataset)}\")\n",
    "\n",
    "# 加载类型映射\n",
    "print(\"\\n2. 加载类型映射\")\n",
    "vocab_file = Path(config.db_root).parent / \"vocabulary.json\"\n",
    "type_mapping = load_type_mapping_from_vocab(str(vocab_file))\n",
    "\n",
    "# 加载字体映射\n",
    "print(\"\\n3. 加载字体映射\")\n",
    "font_mapping = load_font_mapping_from_dataset(dataset)\n",
    "if font_mapping:\n",
    "    print(f\"✓ 字体映射: {len(font_mapping)} 个字体\")\n",
    "else:\n",
    "    print(\"  未找到字体映射\")\n",
    "\n",
    "# 加载Canvas尺寸映射\n",
    "print(\"\\n4. 加载Canvas尺寸映射\")\n",
    "width_mapping, height_mapping = load_canvas_mappings_from_dataset(dataset)\n",
    "if width_mapping:\n",
    "    print(f\"✓ Width映射: {len(width_mapping)} 个尺寸\")\n",
    "    print(f\"  范围: {min(width_mapping.values())} - {max(width_mapping.values())}\")\n",
    "else:\n",
    "    print(\"  未找到width映射，使用默认值\")\n",
    "\n",
    "if height_mapping:\n",
    "    print(f\"✓ Height映射: {len(height_mapping)} 个尺寸\")\n",
    "    print(f\"  范围: {min(height_mapping.values())} - {max(height_mapping.values())}\")\n",
    "else:\n",
    "    print(\"  未找到height映射，使用默认值\")\n",
    "\n",
    "# 创建DataLoader\n",
    "print(\"\\n5. 创建DataLoader\")\n",
    "from torch.utils.data import DataLoader\n",
    "from dataset import collate_fn\n",
    "\n",
    "dataloader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=config.batch_size,\n",
    "    shuffle=False,\n",
    "    collate_fn=collate_fn\n",
    ")\n",
    "\n",
    "example = next(iter(dataloader))\n",
    "\n",
    "for key in example:\n",
    "    if torch.is_tensor(example[key]):\n",
    "        example[key] = example[key].to(config.device)\n",
    "\n",
    "print(f\"✓ 批次形状: {example['left'].shape}\")\n",
    "\n",
    "# 加载模型配置\n",
    "print(\"\\n6. 加载模型配置\")\n",
    "input_columns_file = './input_columns_fixed.json'\n",
    "with open(input_columns_file, 'r') as f:\n",
    "    input_columns = json.load(f)\n",
    "print(f\"✓ 输入列数: {len(input_columns)}\")\n",
    "\n",
    "# 加载模型\n",
    "print(\"\\n7. 加载模型\")\n",
    "checkpoint_path = Path(config.ckpt_dir) / \"best_pytorch.pth\"\n",
    "model = load_model(str(checkpoint_path), input_columns, config.device)\n",
    "\n",
    "# 构建检索数据库\n",
    "print(\"\\n8. 构建检索数据库\")\n",
    "db_root = Path(config.db_root).parent / config.dataset_name\n",
    "\n",
    "image_db = ImageRetriever(db_root, image_path=db_root / \"images\")\n",
    "image_db.build(\"test\")\n",
    "\n",
    "text_db = TextRetriever(db_root, text_path=db_root / \"texts\")\n",
    "text_db.build(\"test\")\n",
    "\n",
    "# 创建SVG构建器\n",
    "print(\"\\n9. 创建SVG构建器\")\n",
    "builders = {}\n",
    "\n",
    "builders[\"layout\"] = SVGBuilder(\n",
    "    key='type',\n",
    "    max_width=128,\n",
    "    max_height=192,\n",
    "    opacity=0.8,\n",
    ")\n",
    "\n",
    "patterns = [\n",
    "    (\"visual\", image_db, text_db),\n",
    "    (\"visual_wo_text\", image_db, None),\n",
    "    (\"visual_wo_image\", None, text_db),\n",
    "]\n",
    "\n",
    "for (name, idb, tdb) in patterns:\n",
    "    builders[name] = SVGBuilder(\n",
    "        key='color',\n",
    "        max_width=128,\n",
    "        max_height=192,\n",
    "        image_db=idb,\n",
    "        text_db=tdb,\n",
    "        render_text=(tdb is not None),\n",
    "        opacity=1.0,\n",
    "    )\n",
    "\n",
    "print(\"✓ 构建器创建完成\")\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Cell 8: 运行可视化\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(f\"10. 开始可视化 - 任务: {config.target_task}\")\n",
    "print(\"=\"*80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "渲染 20 个样本...\n",
      "  - GT Layout\n",
      "  - GT Visual\n",
      "  - 模型推理\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m svgs \u001b[38;5;241m=\u001b[39m \u001b[43mvisualize_reconstruction\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuilders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_columns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtype_mapping\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfont_mapping\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwidth_mapping\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheight_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbins\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# 与dataset.py中的bins保持一致\u001b[39;49;00m\n\u001b[1;32m      5\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m✓ 生成了 \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(svgs)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m 个样本的可视化结果\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m列名: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39mcolumn_names[config\u001b[38;5;241m.\u001b[39mtarget_task]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[1], line 466\u001b[0m, in \u001b[0;36mvisualize_reconstruction\u001b[0;34m(model, example, builders, config, input_columns, type_mapping, font_mapping, width_mapping, height_mapping, bins)\u001b[0m\n\u001b[1;32m    464\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  - 模型推理\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    465\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 466\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_inference_with_masks\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmfp_masks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    468\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m example:\n\u001b[1;32m    469\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pred:\n",
      "Cell \u001b[0;32mIn[1], line 387\u001b[0m, in \u001b[0;36mmodel_inference_with_masks\u001b[0;34m(model, inputs, masks)\u001b[0m\n\u001b[1;32m    384\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    385\u001b[0m         masked_inputs[key] \u001b[38;5;241m=\u001b[39m value\n\u001b[0;32m--> 387\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmasked_inputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    388\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[0;32m/home/dell/anaconda3/envs/ptfd311/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/dell/anaconda3/envs/ptfd311/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/home/dell/Project-HCL/BaseLine/flexdm_pt/scripts/models_pytorch.py:334\u001b[0m, in \u001b[0;36mMFP.forward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    333\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs: Dict[\u001b[38;5;28mstr\u001b[39m, torch\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Dict[\u001b[38;5;28mstr\u001b[39m, torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[0;32m--> 334\u001b[0m     x, mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    335\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransformer(x, mask)\n\u001b[1;32m    336\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder(x)\n",
      "File \u001b[0;32m/home/dell/anaconda3/envs/ptfd311/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/dell/anaconda3/envs/ptfd311/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/home/dell/Project-HCL/BaseLine/flexdm_pt/scripts/models_pytorch.py:213\u001b[0m, in \u001b[0;36mEncoder.forward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfloat:\n\u001b[1;32m    211\u001b[0m         x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[0;32m--> 213\u001b[0m emb \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;66;03m# 处理多维特征(如RGB) - sum across feature dimension\u001b[39;00m\n\u001b[1;32m    216\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(emb\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m4\u001b[39m:  \u001b[38;5;66;03m# (B, S, 3, D)\u001b[39;00m\n",
      "File \u001b[0;32m/home/dell/anaconda3/envs/ptfd311/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/dell/anaconda3/envs/ptfd311/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/home/dell/anaconda3/envs/ptfd311/lib/python3.11/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`"
     ]
    }
   ],
   "source": [
    "\n",
    "svgs = visualize_reconstruction(\n",
    "    model, example, builders, config, input_columns,\n",
    "    type_mapping, font_mapping, width_mapping, height_mapping,\n",
    "    bins=64  # 与dataset.py中的bins保持一致\n",
    ")\n",
    "\n",
    "print(f\"\\n✓ 生成了 {len(svgs)} 个样本的可视化结果\")\n",
    "print(f\"列名: {config.column_names[config.target_task]}\")\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Cell 9: 显示结果（基础版）\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"可视化结果:\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for i, row in enumerate(svgs[:5]):  # 只显示前5个样本\n",
    "    print(f\"\\nSample {i}:\")\n",
    "    display(HTML(\"<div style='margin: 10px 0;'>%s</div>\" % \" \".join(row)))\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"✓ Demo完成!\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Cell 10 (可选): 单独显示某个样本\n",
    "# ============================================================\n",
    "\"\"\"\n",
    "# 如果想单独查看某个样本，运行这个cell\n",
    "sample_idx = 0  # 修改这个索引查看不同样本\n",
    "\n",
    "print(f\"Sample {sample_idx} - 详细视图\")\n",
    "print(f\"列名: {config.column_names[config.target_task]}\")\n",
    "\n",
    "row = svgs[sample_idx]\n",
    "for col_idx, col_name in enumerate(config.column_names[config.target_task]):\n",
    "    if col_idx < len(row):\n",
    "        print(f\"\\n{col_name}:\")\n",
    "        display(HTML(f\"<div>{row[col_idx]}</div>\"))\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Cell 11 (可选): 并排对比显示\n",
    "# ============================================================\n",
    "# def display_comparison(svgs, sample_indices, column_names):\n",
    "#     \"\"\"并排显示多个样本\"\"\"\n",
    "#     html_parts = ['<table style=\"border-collapse: collapse; width: 100%;\">']\n",
    "    \n",
    "#     # 表头\n",
    "#     html_parts.append('<tr style=\"background-color: #f0f0f0;\">')\n",
    "#     html_parts.append('<th style=\"padding: 10px; border: 1px solid #ddd;\">Sample</th>')\n",
    "#     for col_name in column_names:\n",
    "#         html_parts.append(f'<th style=\"padding: 10px; border: 1px solid #ddd;\">{col_name}</th>')\n",
    "#     html_parts.append('</tr>')\n",
    "    \n",
    "#     # 每一行\n",
    "#     for idx in sample_indices:\n",
    "#         if idx >= len(svgs):\n",
    "#             continue\n",
    "        \n",
    "#         html_parts.append('<tr>')\n",
    "#         html_parts.append(f'<td style=\"padding: 10px; border: 1px solid #ddd; text-align: center;\"><b>#{idx}</b></td>')\n",
    "        \n",
    "#         row = svgs[idx]\n",
    "#         for item in row:\n",
    "#             html_parts.append(f'<td style=\"padding: 10px; border: 1px solid #ddd;\">{item}</td>')\n",
    "        \n",
    "#         html_parts.append('</tr>')\n",
    "    \n",
    "#     html_parts.append('</table>')\n",
    "    \n",
    "#     display(HTML(''.join(html_parts)))\n",
    "\n",
    "\n",
    "# # 显示前4个样本的对比\n",
    "# print(\"\\n\" + \"=\"*80)\n",
    "# print(\"前4个样本对比:\")\n",
    "# print(\"=\"*80)\n",
    "# display_comparison(svgs, [0, 1, 2, 3], config.column_names[config.target_task])\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Cell 12 (可选): 调试信息\n",
    "# ============================================================\n",
    "\"\"\"\n",
    "# 显示canvas尺寸的解码情况\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Canvas尺寸调试信息:\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for i in range(min(5, len(svgs))):\n",
    "    canvas_w_idx = example['canvas_width'][i].item()\n",
    "    canvas_h_idx = example['canvas_height'][i].item()\n",
    "    \n",
    "    canvas_w = width_mapping.get(canvas_w_idx, 800) if width_mapping else 800\n",
    "    canvas_h = height_mapping.get(canvas_h_idx, 600) if height_mapping else 600\n",
    "    \n",
    "    print(f\"\\nSample {i}:\")\n",
    "    print(f\"  Width:  idx={canvas_w_idx:3d} -> value={canvas_w}\")\n",
    "    print(f\"  Height: idx={canvas_h_idx:3d} -> value={canvas_h}\")\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Cell 13 (可选): 切换任务类型\n",
    "# ============================================================\n",
    "\"\"\"\n",
    "# 切换到不同的任务类型\n",
    "config.target_task = \"attr\"  # 可选: elem, pos, attr, txt, img\n",
    "\n",
    "print(f\"\\n切换任务类型为: {config.target_task}\")\n",
    "\n",
    "# 重新运行可视化\n",
    "svgs = visualize_reconstruction(\n",
    "    model, example, builders, config, input_columns,\n",
    "    type_mapping, font_mapping, width_mapping, height_mapping\n",
    ")\n",
    "\n",
    "# 显示结果\n",
    "print(f\"\\n任务 {config.target_task} 的结果:\")\n",
    "display_comparison(svgs, [0, 1, 2, 3], config.column_names[config.target_task])\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
