"""
æµ‹è¯•è®­ç»ƒç¯å¢ƒè®¾ç½®
è¿è¡Œæ­¤è„šæœ¬ä»¥éªŒè¯ä¸€åˆ‡é…ç½®æ­£ç¡®
"""

import os
import sys
import json
from pathlib import Path

def check_dependencies():
    """æ£€æŸ¥ä¾èµ–åŒ…"""
    print("="*60)
    print("æ£€æŸ¥ä¾èµ–åŒ…...")
    print("="*60)
    
    packages = {
        'torch': 'PyTorch',
        'numpy': 'NumPy',
        'tqdm': 'tqdm',
        'tensorboard': 'TensorBoard',
    }
    
    missing = []
    for package, name in packages.items():
        try:
            __import__(package)
            print(f"âœ“ {name:20s} å·²å®‰è£…")
        except ImportError:
            print(f"âœ— {name:20s} æœªå®‰è£…")
            missing.append(package)
    
    if missing:
        print(f"\nç¼ºå°‘ä¾èµ–: {', '.join(missing)}")
        print(f"è¯·è¿è¡Œ: pip install {' '.join(missing)}")
        return False
    
    # æ£€æŸ¥CUDA
    import torch
    if torch.cuda.is_available():
        print(f"\nâœ“ CUDA å¯ç”¨")
        print(f"  è®¾å¤‡æ•°: {torch.cuda.device_count()}")
        print(f"  å½“å‰è®¾å¤‡: {torch.cuda.current_device()}")
        print(f"  è®¾å¤‡åç§°: {torch.cuda.get_device_name(0)}")
    else:
        print(f"\nâš  CUDA ä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨CPUè®­ç»ƒ")
    
    return True


def check_data(data_dir):
    """æ£€æŸ¥æ•°æ®æ–‡ä»¶"""
    print("\n" + "="*60)
    print("æ£€æŸ¥æ•°æ®æ–‡ä»¶...")
    print("="*60)
    
    data_dir = Path(data_dir)
    
    required_files = {
        'train.json': 'è®­ç»ƒæ•°æ®',
        'val.json': 'éªŒè¯æ•°æ®',
        'test.json': 'æµ‹è¯•æ•°æ®',
        'vocabulary.json': 'è¯æ±‡è¡¨',
    }
    
    all_exist = True
    for filename, desc in required_files.items():
        filepath = data_dir / filename
        if filepath.exists():
            size = filepath.stat().st_size / (1024**2)  # MB
            print(f"âœ“ {desc:15s} å­˜åœ¨ ({size:.2f} MB)")
            
            # æ£€æŸ¥JSONæ ¼å¼
            try:
                with open(filepath, 'r') as f:
                    data = json.load(f)
                if isinstance(data, list):
                    print(f"  â””â”€ åŒ…å« {len(data)} ä¸ªæ ·æœ¬")
            except Exception as e:
                print(f"  â””â”€ è­¦å‘Š: æ— æ³•è¯»å– ({e})")
        else:
            print(f"âœ— {desc:15s} ä¸å­˜åœ¨")
            all_exist = False
    
    return all_exist


def test_data_loading(data_dir):
    """æµ‹è¯•æ•°æ®åŠ è½½"""
    print("\n" + "="*60)
    print("æµ‹è¯•æ•°æ®åŠ è½½...")
    print("="*60)
    
    try:
        from dataset import DesignLayoutDataset, create_dataloader
        
        # åˆ›å»ºæ•°æ®é›†
        dataset = DesignLayoutDataset(data_dir, split='train', max_length=20)
        print(f"âœ“ æ•°æ®é›†åˆ›å»ºæˆåŠŸ")
        print(f"  æ ·æœ¬æ•°: {len(dataset)}")
        
        # æµ‹è¯•å•ä¸ªæ ·æœ¬
        sample = dataset[0]
        print(f"\næ ·æœ¬ç»“æ„:")
        for key, value in sample.items():
            if hasattr(value, 'shape'):
                print(f"  {key:20s}: shape={list(value.shape)}, dtype={value.dtype}")
            else:
                print(f"  {key:20s}: {type(value)}")
        
        # æµ‹è¯•dataloader
        loader = create_dataloader(data_dir, 'train', batch_size=4, shuffle=False, num_workers=0)
        batch = next(iter(loader))
        print(f"\nâœ“ DataLoaderæµ‹è¯•æˆåŠŸ")
        print(f"  æ‰¹æ¬¡å¤§å°: {batch['left'].shape[0]}")
        
        # ç”Ÿæˆinput_columns
        input_columns = dataset.get_input_columns()
        print(f"\nâœ“ Input columnsç”ŸæˆæˆåŠŸ")
        print(f"  ç‰¹å¾æ•°: {len(input_columns)}")
        
        return True
        
    except Exception as e:
        print(f"\nâœ— æ•°æ®åŠ è½½å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_model_creation():
    """æµ‹è¯•æ¨¡å‹åˆ›å»º"""
    print("\n" + "="*60)
    print("æµ‹è¯•æ¨¡å‹åˆ›å»º...")
    print("="*60)
    
    try:
        from models_pytorch import MFP
        import torch
        
        # ç®€å•é…ç½®
        input_columns = {
            'type': {'is_sequence': True, 'type': 'categorical', 'input_dim': 6, 'shape': [1]},
            'left': {'is_sequence': True, 'type': 'categorical', 'input_dim': 64, 'shape': [1]},
            'top': {'is_sequence': True, 'type': 'categorical', 'input_dim': 64, 'shape': [1]},
            'width': {'is_sequence': True, 'type': 'categorical', 'input_dim': 64, 'shape': [1]},
            'height': {'is_sequence': True, 'type': 'categorical', 'input_dim': 64, 'shape': [1]},
        }
        
        model = MFP(input_columns, embed_dim=128, num_blocks=2, num_heads=4)
        print(f"âœ“ æ¨¡å‹åˆ›å»ºæˆåŠŸ")
        
        total_params = sum(p.numel() for p in model.parameters())
        print(f"  æ€»å‚æ•°: {total_params:,}")
        
        # æµ‹è¯•å‰å‘ä¼ æ’­
        batch_size = 2
        seq_len = 10
        test_input = {
            'length': torch.tensor([[5], [7]], dtype=torch.long),
            'type': torch.randint(0, 6, (batch_size, seq_len, 1)),
            'left': torch.randint(0, 64, (batch_size, seq_len, 1)),
            'top': torch.randint(0, 64, (batch_size, seq_len, 1)),
            'width': torch.randint(0, 64, (batch_size, seq_len, 1)),
            'height': torch.randint(0, 64, (batch_size, seq_len, 1)),
        }
        
        with torch.no_grad():
            outputs = model(test_input)
        
        print(f"âœ“ å‰å‘ä¼ æ’­æµ‹è¯•æˆåŠŸ")
        print(f"  è¾“å‡ºæ•°: {len(outputs)}")
        
        return True
        
    except Exception as e:
        print(f"\nâœ— æ¨¡å‹åˆ›å»ºå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def check_directories(save_dir, log_dir):
    """æ£€æŸ¥å¹¶åˆ›å»ºå¿…è¦ç›®å½•"""
    print("\n" + "="*60)
    print("æ£€æŸ¥ç›®å½•ç»“æ„...")
    print("="*60)
    
    directories = {
        save_dir: 'Checkpointsç›®å½•',
        log_dir: 'Logsç›®å½•',
    }
    
    for dir_path, desc in directories.items():
        dir_path = Path(dir_path)
        if dir_path.exists():
            print(f"âœ“ {desc:20s} å­˜åœ¨: {dir_path}")
        else:
            dir_path.mkdir(parents=True, exist_ok=True)
            print(f"âœ“ {desc:20s} å·²åˆ›å»º: {dir_path}")


def main():
    print("\n" + "="*80)
    print("MFP è®­ç»ƒç¯å¢ƒæ£€æŸ¥")
    print("="*80 + "\n")
    
    # é…ç½®è·¯å¾„
    project_root = Path(__file__).parent.parent
    data_dir = project_root / "data" / "crello_json"
    save_dir = project_root / "checkpoints"
    log_dir = project_root / "logs"
    
    # è¿è¡Œæ£€æŸ¥
    checks = [
        ("ä¾èµ–åŒ…", lambda: check_dependencies()),
        ("æ•°æ®æ–‡ä»¶", lambda: check_data(data_dir)),
        ("ç›®å½•ç»“æ„", lambda: check_directories(save_dir, log_dir) or True),
        ("æ•°æ®åŠ è½½", lambda: test_data_loading(data_dir)),
        ("æ¨¡å‹åˆ›å»º", lambda: test_model_creation()),
    ]
    
    results = []
    for name, check_func in checks:
        try:
            result = check_func()
            results.append((name, result))
        except Exception as e:
            print(f"\nâœ— {name} æ£€æŸ¥å‡ºé”™: {e}")
            results.append((name, False))
    
    # æ€»ç»“
    print("\n" + "="*80)
    print("æ£€æŸ¥æ€»ç»“")
    print("="*80)
    
    all_passed = True
    for name, result in results:
        status = "âœ“ é€šè¿‡" if result else "âœ— å¤±è´¥"
        print(f"{name:20s}: {status}")
        if not result:
            all_passed = False
    
    print("="*80)
    
    if all_passed:
        print("\nğŸ‰ æ‰€æœ‰æ£€æŸ¥é€šè¿‡ï¼å¯ä»¥å¼€å§‹è®­ç»ƒäº†ï¼")
        print("\nå¿«é€Ÿå¼€å§‹:")
        print("  cd scripts")
        print("  ./train.sh")
        print("\næˆ–è€…:")
        print("  python train_pytorch_improved.py --data_dir ../data/crello_json --config config/train_config.json")
    else:
        print("\nâš  éƒ¨åˆ†æ£€æŸ¥å¤±è´¥ï¼Œè¯·è§£å†³é—®é¢˜åå†å¼€å§‹è®­ç»ƒ")
        return 1
    
    return 0


if __name__ == "__main__":
    sys.exit(main())
    