"""
å®Œæ•´çš„MFPè®­ç»ƒä»£ç  - ä¸¥æ ¼å¯¹é½TensorFlowç‰ˆæœ¬
åŒ…å«æ­£ç¡®çš„Maskingæœºåˆ¶å’ŒLossæ›²çº¿ç»˜åˆ¶
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torch.utils.data import DataLoader
from torch.utils.tensorboard import SummaryWriter
from pathlib import Path
import argparse
import json
from tqdm import tqdm
import time
from typing import Dict, List
import numpy as np
import matplotlib.pyplot as plt
import matplotlib
matplotlib.use('Agg')  # ä½¿ç”¨éäº¤äº’å¼åç«¯
import seaborn as sns
sns.set_style('darkgrid')

from dataset import create_dataloader
from models_pytorch import MFP
from masking_pytorch import (
    get_task_names,
    preprocess_for_train,
    get_seq_mask,
)


class MFPTrainer:
    """MFPæ¨¡å‹è®­ç»ƒå™¨ï¼ˆåŒ…å«Maskingå’ŒLossæ›²çº¿ç»˜åˆ¶ï¼‰"""
    
    def __init__(
        self,
        model: nn.Module,
        train_loader: DataLoader,
        val_loader: DataLoader,
        config: Dict,
        device: str = 'cuda',
        save_dir: str = './checkpoints',
        log_dir: str = './logs',
        resume_path: str = None,
    ):
        self.model = model.to(device)
        self.train_loader = train_loader
        self.val_loader = val_loader
        self.config = config
        self.device = device
        self.input_columns = model.input_columns
        
        # è®­ç»ƒé…ç½®
        train_cfg = config.get('training', {})
        self.num_epochs = train_cfg.get('num_epochs', 100)
        self.gradient_clip = train_cfg.get('gradient_clip', 1.0)
        self.accumulation_steps = train_cfg.get('accumulation_steps', 1)
        
        # ä»»åŠ¡é‡‡æ ·
        self.task_names = get_task_names(self.input_columns)
        self.num_tasks = len(self.task_names)
        print(f"\nä»»åŠ¡åˆ—è¡¨: {self.task_names}")
        
        # æŸå¤±æƒé‡
        self.loss_weights = config.get('loss_weights', {})
        
        # ä¼˜åŒ–å™¨
        self.optimizer = optim.AdamW(
            model.parameters(),
            lr=train_cfg.get('learning_rate', 1e-4),
            betas=(0.9, 0.999),
            weight_decay=train_cfg.get('weight_decay', 0.01),
        )
        
        # å­¦ä¹ ç‡è°ƒåº¦å™¨
        self.scheduler = optim.lr_scheduler.ReduceLROnPlateau(
            self.optimizer,
            mode='min',
            factor=0.5,
            patience=5,
            min_lr=1e-6,
            verbose=True,
        )
        
        # ç›®å½•è®¾ç½®
        self.save_dir = Path(save_dir)
        self.save_dir.mkdir(parents=True, exist_ok=True)
        self.plot_dir = self.save_dir / 'plots'
        self.plot_dir.mkdir(exist_ok=True)
        
        # TensorBoard
        self.writer = SummaryWriter(log_dir)
        
        # è®­ç»ƒçŠ¶æ€
        self.start_epoch = 0
        self.best_val_loss = float('inf')
        self.global_step = 0
        
        # ğŸ¨ Losså†å²è®°å½• - ç”¨äºç»˜å›¾
        self.loss_history = {
            'epochs': [],
            'train_loss': [],
            'val_loss': [],
            'train_losses_detailed': {},  # æ¯ä¸ªä»»åŠ¡çš„è®­ç»ƒæŸå¤±
            'val_losses_detailed': {},    # æ¯ä¸ªä»»åŠ¡çš„éªŒè¯æŸå¤±
            'learning_rates': [],
        }
        
        # æ¢å¤è®­ç»ƒ
        if resume_path and Path(resume_path).exists():
            self.load_checkpoint(resume_path)
        
        print(f"âœ“ è®­ç»ƒå™¨åˆå§‹åŒ–å®Œæˆ (è®¾å¤‡: {device})")
    
    def compute_loss(
        self,
        predictions: Dict[str, torch.Tensor],
        targets: Dict[str, torch.Tensor],
        masks: Dict[str, torch.Tensor],
        seq_mask: torch.Tensor,
    ) -> Dict[str, torch.Tensor]:
        """
        è®¡ç®—å¤šä»»åŠ¡æŸå¤±ï¼ˆåªåœ¨maskedä½ç½®è®¡ç®—ï¼‰
        
        Args:
            predictions: æ¨¡å‹é¢„æµ‹
            targets: çœŸå®æ ‡ç­¾
            masks: maskå­—å…¸ï¼ˆTrueè¡¨ç¤ºéœ€è¦é¢„æµ‹çš„ä½ç½®ï¼‰
            seq_mask: (B, S) æœ‰æ•ˆä½ç½®mask
        
        Returns:
            æŸå¤±å­—å…¸
        """
        losses = {}
        total_loss = 0.0
        
        for key in predictions.keys():
            if key not in targets or key not in masks:
                continue
            
            pred = predictions[key]
            target = targets[key]
            mfp_mask = masks[key]
            
            column = self.input_columns.get(key, {})
            weight = self.loss_weights.get(key, 1.0)
            
            if column.get('type') == 'categorical':
                # â­ å…³é”®ä¿®å¤ï¼šè¿‡æ»¤æ‰ç‰¹æ®Štoken
                input_dim = column['input_dim']
                
                if pred.dim() == 4:  # (B, S, num_feat, C)
                    B, S, num_feat, C = pred.shape
                    
                    # å±•å¹³
                    pred_flat = pred.reshape(B * S * num_feat, C)
                    target_flat = target.reshape(B * S * num_feat).long()
                    
                    # è®¡ç®—æŸå¤±
                    loss = F.cross_entropy(pred_flat, target_flat, reduction='none')
                    loss = loss.reshape(B, S, num_feat)
                    
                    # åº”ç”¨mask
                    mask_expanded = mfp_mask.unsqueeze(-1) & seq_mask.unsqueeze(-1)
                    loss = (loss * mask_expanded.float()).sum() / (mask_expanded.sum() + 1e-8)
                
                elif pred.dim() == 3:  # (B, S, C)
                    B, S, C = pred.shape
                    
                    # å±•å¹³
                    pred_flat = pred.reshape(B * S, C)
                    target_flat = target.reshape(B * S).long()
                    
                    # è®¡ç®—æŸå¤±
                    loss = F.cross_entropy(pred_flat, target_flat, reduction='none')
                    loss = loss.reshape(B, S)
                    
                    # åº”ç”¨mask
                    mask_combined = mfp_mask & seq_mask
                    loss = (loss * mask_combined.float()).sum() / (mask_combined.sum() + 1e-8)
                else:
                    continue
            
            elif column.get('type') == 'numerical':
                # å›å½’æŸå¤±
                loss = F.mse_loss(pred, target.float(), reduction='none')
                
                # åº”ç”¨mask
                mask_expanded = mfp_mask.unsqueeze(-1) & seq_mask.unsqueeze(-1)
                mask_expanded = mask_expanded.expand_as(loss)
                loss = (loss * mask_expanded.float()).sum() / (mask_expanded.sum() + 1e-8)
            else:
                continue
            
            # åº”ç”¨æƒé‡
            weighted_loss = loss * weight
            losses[f'{key}_loss'] = loss.detach()
            total_loss += weighted_loss
        
        losses['total_loss'] = total_loss
        return losses
    
    def plot_loss_curves(self, save_path: str = None):
        """
        ç»˜åˆ¶æŸå¤±æ›²çº¿
        
        Args:
            save_path: ä¿å­˜è·¯å¾„ï¼Œå¦‚æœä¸ºNoneåˆ™ä¿å­˜åˆ°é»˜è®¤ä½ç½®
        """
        if len(self.loss_history['epochs']) == 0:
            return
        
        # åˆ›å»ºå­å›¾
        fig, axes = plt.subplots(2, 2, figsize=(15, 10))
        fig.suptitle('Training Progress', fontsize=16, fontweight='bold')
        
        # 1. ä¸»è¦æŸå¤±æ›²çº¿ï¼ˆè®­ç»ƒvséªŒè¯ï¼‰
        ax1 = axes[0, 0]
        ax1.plot(self.loss_history['epochs'], self.loss_history['train_loss'], 
                'b-', label='Train Loss', linewidth=2)
        ax1.plot(self.loss_history['epochs'], self.loss_history['val_loss'], 
                'r-', label='Val Loss', linewidth=2)
        ax1.fill_between(self.loss_history['epochs'], 
                        self.loss_history['train_loss'], 
                        self.loss_history['val_loss'], 
                        alpha=0.2)
        ax1.set_xlabel('Epoch')
        ax1.set_ylabel('Loss')
        ax1.set_title('Training vs Validation Loss')
        ax1.legend()
        ax1.grid(True, alpha=0.3)
        
        # æ ‡è®°æœ€ä½³éªŒè¯æŸå¤±
        if self.loss_history['val_loss']:
            best_epoch = np.argmin(self.loss_history['val_loss'])
            best_val_loss = self.loss_history['val_loss'][best_epoch]
            ax1.plot(self.loss_history['epochs'][best_epoch], best_val_loss, 
                    'g*', markersize=15, label=f'Best Val Loss: {best_val_loss:.4f}')
            ax1.legend()
        
        # 2. å­¦ä¹ ç‡æ›²çº¿
        ax2 = axes[0, 1]
        ax2.plot(self.loss_history['epochs'], self.loss_history['learning_rates'], 
                'g-', linewidth=2)
        ax2.set_xlabel('Epoch')
        ax2.set_ylabel('Learning Rate')
        ax2.set_title('Learning Rate Schedule')
        ax2.grid(True, alpha=0.3)
        ax2.set_yscale('log')
        
        # 3. æ¯ä¸ªä»»åŠ¡çš„è®­ç»ƒæŸå¤±
        ax3 = axes[1, 0]
        for key in self.loss_history['train_losses_detailed'].keys():
            if key != 'total_loss' and len(self.loss_history['train_losses_detailed'][key]) > 0:
                ax3.plot(self.loss_history['epochs'], 
                        self.loss_history['train_losses_detailed'][key], 
                        label=key.replace('_loss', ''), linewidth=1.5, alpha=0.8)
        ax3.set_xlabel('Epoch')
        ax3.set_ylabel('Loss')
        ax3.set_title('Training Loss by Task')
        ax3.legend(loc='upper right', fontsize=8)
        ax3.grid(True, alpha=0.3)
        
        # 4. æ¯ä¸ªä»»åŠ¡çš„éªŒè¯æŸå¤±
        ax4 = axes[1, 1]
        for key in self.loss_history['val_losses_detailed'].keys():
            if key != 'total_loss' and len(self.loss_history['val_losses_detailed'][key]) > 0:
                ax4.plot(self.loss_history['epochs'], 
                        self.loss_history['val_losses_detailed'][key], 
                        label=key.replace('_loss', ''), linewidth=1.5, alpha=0.8)
        ax4.set_xlabel('Epoch')
        ax4.set_ylabel('Loss')
        ax4.set_title('Validation Loss by Task')
        ax4.legend(loc='upper right', fontsize=8)
        ax4.grid(True, alpha=0.3)
        
        plt.tight_layout()
        
        # ä¿å­˜å›¾ç‰‡
        if save_path is None:
            save_path = self.plot_dir / f'loss_curves_epoch_{len(self.loss_history["epochs"])}.png'
        plt.savefig(save_path, dpi=100, bbox_inches='tight')
        plt.close()
        
        print(f"ğŸ“Š Lossæ›²çº¿å·²ä¿å­˜è‡³: {save_path}")
    
    def plot_loss_comparison(self):
        """ç»˜åˆ¶è®­ç»ƒå’ŒéªŒè¯æŸå¤±çš„å¯¹æ¯”å›¾ï¼ˆç®€åŒ–ç‰ˆï¼‰"""
        if len(self.loss_history['epochs']) == 0:
            return
        
        plt.figure(figsize=(10, 6))
        
        # ç»˜åˆ¶æŸå¤±æ›²çº¿
        plt.plot(self.loss_history['epochs'], self.loss_history['train_loss'], 
                'b-', label='Train Loss', linewidth=2, alpha=0.8)
        plt.plot(self.loss_history['epochs'], self.loss_history['val_loss'], 
                'r-', label='Val Loss', linewidth=2, alpha=0.8)
        
        # æ·»åŠ æœ€ä½³ç‚¹æ ‡è®°
        if self.loss_history['val_loss']:
            best_epoch = np.argmin(self.loss_history['val_loss'])
            best_val_loss = self.loss_history['val_loss'][best_epoch]
            plt.scatter(self.loss_history['epochs'][best_epoch], best_val_loss, 
                       color='green', s=100, zorder=5, 
                       label=f'Best: {best_val_loss:.4f}')
        
        plt.xlabel('Epoch', fontsize=12)
        plt.ylabel('Loss', fontsize=12)
        plt.title('Training Progress', fontsize=14, fontweight='bold')
        plt.legend(loc='upper right')
        plt.grid(True, alpha=0.3)
        
        # ä¿å­˜ç®€åŒ–ç‰ˆå›¾ç‰‡
        save_path = self.plot_dir / 'loss_curve_simple.png'
        plt.savefig(save_path, dpi=100, bbox_inches='tight')
        plt.close()
    
    def update_loss_history(self, epoch: int, train_losses: Dict, val_losses: Dict):
        """æ›´æ–°æŸå¤±å†å²è®°å½•"""
        self.loss_history['epochs'].append(epoch)
        self.loss_history['train_loss'].append(train_losses['total_loss'])
        self.loss_history['val_loss'].append(val_losses['total_loss'])
        self.loss_history['learning_rates'].append(self.optimizer.param_groups[0]['lr'])
        
        # æ›´æ–°è¯¦ç»†æŸå¤±
        for key, value in train_losses.items():
            if key not in self.loss_history['train_losses_detailed']:
                self.loss_history['train_losses_detailed'][key] = []
            self.loss_history['train_losses_detailed'][key].append(value)
        
        for key, value in val_losses.items():
            if key not in self.loss_history['val_losses_detailed']:
                self.loss_history['val_losses_detailed'][key] = []
            self.loss_history['val_losses_detailed'][key].append(value)
    
    def train_epoch(self, epoch: int):
        """è®­ç»ƒä¸€ä¸ªepochï¼ˆåŒ…å«Maskingï¼‰"""
        self.model.train()
        epoch_losses = {}
        
        pbar = tqdm(self.train_loader, desc=f'Epoch {epoch}/{self.num_epochs}')
        self.optimizer.zero_grad()
        
        for batch_idx, batch in enumerate(pbar):
            # ç§»åŠ¨åˆ°è®¾å¤‡
            inputs = {k: v.to(self.device) if torch.is_tensor(v) else v 
                     for k, v in batch.items()}
            
            # éšæœºé€‰æ‹©ä»»åŠ¡
            batch_size = inputs['length'].size(0)
            task_ids = torch.randint(0, self.num_tasks, (batch_size,))
            
            # é¢„å¤„ç†ï¼ˆåº”ç”¨Maskingï¼‰
            targets, modified_inputs, masks = preprocess_for_train(
                inputs,
                self.input_columns,
                task_ids[0].item(),  # ç®€åŒ–ï¼šæ•´ä¸ªbatchä½¿ç”¨åŒä¸€ä»»åŠ¡
                is_autoreg=False,
            )
            
            # å‰å‘ä¼ æ’­
            outputs = self.model(modified_inputs)
            
            # ç”Ÿæˆåºåˆ—mask
            seq_mask = get_seq_mask(inputs['length'], max_len=inputs['left'].size(1))
            
            # è®¡ç®—æŸå¤±
            losses = self.compute_loss(outputs, targets, masks, seq_mask)
            loss = losses['total_loss'] / self.accumulation_steps
            
            # åå‘ä¼ æ’­
            loss.backward()
            
            # æ¢¯åº¦ç´¯ç§¯
            if (batch_idx + 1) % self.accumulation_steps == 0:
                torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.gradient_clip)
                self.optimizer.step()
                self.optimizer.zero_grad()
            
            # è®°å½•æŸå¤±
            for key, value in losses.items():
                if key not in epoch_losses:
                    epoch_losses[key] = []
                epoch_losses[key].append(value.item() if torch.is_tensor(value) else value)
            
            # æ›´æ–°è¿›åº¦æ¡
            pbar.set_postfix({
                'loss': f"{losses['total_loss'].item():.4f}",
                'lr': f"{self.optimizer.param_groups[0]['lr']:.6f}"
            })
            
            # TensorBoardè®°å½•
            if self.global_step % 100 == 0:
                for key, value in losses.items():
                    self.writer.add_scalar(
                        f'train/{key}', 
                        value.item() if torch.is_tensor(value) else value, 
                        self.global_step
                    )
                self.writer.add_scalar('train/lr', self.optimizer.param_groups[0]['lr'], self.global_step)
            
            self.global_step += 1
        
        # è®¡ç®—å¹³å‡æŸå¤±
        avg_losses = {k: sum(v) / len(v) for k, v in epoch_losses.items()}
        return avg_losses
    
    @torch.no_grad()
    def validate(self, epoch: int):
        """éªŒè¯"""
        self.model.eval()
        epoch_losses = {}
        
        for batch in tqdm(self.val_loader, desc='Validation'):
            # ç§»åŠ¨åˆ°è®¾å¤‡
            inputs = {k: v.to(self.device) if torch.is_tensor(v) else v 
                     for k, v in batch.items()}
            
            # éšæœºé€‰æ‹©ä»»åŠ¡
            batch_size = inputs['length'].size(0)
            task_ids = torch.randint(0, self.num_tasks, (batch_size,))
            
            # é¢„å¤„ç†
            targets, modified_inputs, masks = preprocess_for_train(
                inputs,
                self.input_columns,
                task_ids[0].item(),
                is_autoreg=False,
            )
            
            # å‰å‘ä¼ æ’­
            outputs = self.model(modified_inputs)
            
            # ç”Ÿæˆåºåˆ—mask
            seq_mask = get_seq_mask(inputs['length'], max_len=inputs['left'].size(1))
            
            # è®¡ç®—æŸå¤±
            losses = self.compute_loss(outputs, targets, masks, seq_mask)
            
            # è®°å½•æŸå¤±
            for key, value in losses.items():
                if key not in epoch_losses:
                    epoch_losses[key] = []
                epoch_losses[key].append(value.item() if torch.is_tensor(value) else value)
        
        # è®¡ç®—å¹³å‡æŸå¤±
        avg_losses = {k: sum(v) / len(v) for k, v in epoch_losses.items()}
        
        # TensorBoardè®°å½•
        for key, value in avg_losses.items():
            self.writer.add_scalar(f'val/{key}', value, epoch)
        
        return avg_losses
    
    def save_checkpoint(self, epoch: int, val_loss: float, is_best: bool = False):
        """ä¿å­˜checkpointï¼ˆåŒ…å«losså†å²ï¼‰"""
        checkpoint = {
            'epoch': epoch,
            'global_step': self.global_step,
            'model_state_dict': self.model.state_dict(),
            'optimizer_state_dict': self.optimizer.state_dict(),
            'scheduler_state_dict': self.scheduler.state_dict(),
            'best_val_loss': self.best_val_loss,
            'val_loss': val_loss,
            'config': self.config,
            'loss_history': self.loss_history,  # ğŸ¨ ä¿å­˜æŸå¤±å†å²
        }
        
        # ä¿å­˜æœ€æ–°æ¨¡å‹
        torch.save(checkpoint, self.save_dir / 'latest.pth')
        
        # ä¿å­˜æœ€ä½³æ¨¡å‹
        if is_best:
            torch.save(checkpoint, self.save_dir / 'best.pth')
            print(f"âœ“ ä¿å­˜æœ€ä½³æ¨¡å‹ (epoch {epoch}, val_loss: {val_loss:.4f})")
        
        # ğŸ¨ ä¿å­˜æŸå¤±å†å²åˆ°JSONï¼ˆæ–¹ä¾¿å¤–éƒ¨åˆ†æï¼‰
        with open(self.save_dir / 'loss_history.json', 'w') as f:
            json.dump(self.loss_history, f, indent=2)
    
    def load_checkpoint(self, checkpoint_path: str):
        """åŠ è½½checkpointï¼ˆåŒ…å«losså†å²ï¼‰"""
        print(f"åŠ è½½checkpoint: {checkpoint_path}")
        checkpoint = torch.load(checkpoint_path, map_location=self.device)
        
        self.model.load_state_dict(checkpoint['model_state_dict'])
        self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
        self.scheduler.load_state_dict(checkpoint['scheduler_state_dict'])
        
        self.start_epoch = checkpoint.get('epoch', 0) + 1
        self.global_step = checkpoint.get('global_step', 0)
        self.best_val_loss = checkpoint.get('best_val_loss', float('inf'))
        
        # ğŸ¨ æ¢å¤æŸå¤±å†å²
        if 'loss_history' in checkpoint:
            self.loss_history = checkpoint['loss_history']
            print(f"âœ“ æ¢å¤æŸå¤±å†å² ({len(self.loss_history['epochs'])} epochs)")
        
        print(f"âœ“ æ¢å¤è®­ç»ƒä» epoch {self.start_epoch}")
    
    def train(self):
        """å®Œæ•´è®­ç»ƒæµç¨‹ï¼ˆåŒ…å«lossæ›²çº¿ç»˜åˆ¶ï¼‰"""
        print("\n" + "="*60)
        print("å¼€å§‹è®­ç»ƒï¼ˆåŒ…å«Maskingæœºåˆ¶å’ŒLossæ›²çº¿ç»˜åˆ¶ï¼‰")
        print("="*60)
        
        for epoch in range(self.start_epoch, self.num_epochs):
            start_time = time.time()
            
            # è®­ç»ƒ
            train_losses = self.train_epoch(epoch)
            
            # éªŒè¯
            if epoch % 1 == 0:
                val_losses = self.validate(epoch)
            else:
                val_losses = {'total_loss': float('inf')}
            
            # ğŸ¨ æ›´æ–°æŸå¤±å†å²
            self.update_loss_history(epoch, train_losses, val_losses)
            
            # å­¦ä¹ ç‡è°ƒåº¦
            self.scheduler.step(val_losses['total_loss'])
            
            # æ‰“å°ä¿¡æ¯
            epoch_time = time.time() - start_time
            print(f"\n{'='*60}")
            print(f"Epoch {epoch}/{self.num_epochs - 1} ({epoch_time:.1f}s)")
            print(f"{'='*60}")
            print(f"Train Loss: {train_losses['total_loss']:.4f}")
            if 'total_loss' in val_losses and val_losses['total_loss'] != float('inf'):
                print(f"Val Loss:   {val_losses['total_loss']:.4f}")
            print(f"LR:         {self.optimizer.param_groups[0]['lr']:.6f}")
            print(f"Best Val:   {self.best_val_loss:.4f}")
            
            # ä¿å­˜checkpoint
            is_best = val_losses['total_loss'] < self.best_val_loss
            if is_best:
                self.best_val_loss = val_losses['total_loss']
            
            self.save_checkpoint(epoch, val_losses['total_loss'], is_best)
            
            # ğŸ¨ å®šæœŸç»˜åˆ¶æŸå¤±æ›²çº¿
            if epoch % 5 == 0 or epoch == self.num_epochs - 1 or is_best:
                self.plot_loss_curves()
                self.plot_loss_comparison()
        
        # ğŸ¨ è®­ç»ƒç»“æŸï¼Œç»˜åˆ¶æœ€ç»ˆæŸå¤±æ›²çº¿
        print("\nğŸ“Š ç»˜åˆ¶æœ€ç»ˆæŸå¤±æ›²çº¿...")
        self.plot_loss_curves(self.plot_dir / 'final_loss_curves.png')
        self.plot_loss_comparison()
        
        print("\n" + "="*60)
        print("è®­ç»ƒå®Œæˆ!")
        print(f"æœ€ä½³éªŒè¯æŸå¤±: {self.best_val_loss:.4f}")
        print(f"æŸå¤±æ›²çº¿å·²ä¿å­˜è‡³: {self.plot_dir}")
        print("="*60)
        self.writer.close()


def visualize_training_summary(checkpoint_path: str):
    """ä»checkpointå¯è§†åŒ–è®­ç»ƒæ€»ç»“"""
    print("\nğŸ“Š ç”Ÿæˆè®­ç»ƒæ€»ç»“...")
    
    # åŠ è½½checkpoint
    checkpoint = torch.load(checkpoint_path, map_location='cpu')
    loss_history = checkpoint.get('loss_history', {})
    
    if not loss_history or not loss_history.get('epochs'):
        print("âŒ æ²¡æœ‰æ‰¾åˆ°æŸå¤±å†å²æ•°æ®")
        return
    
    # åˆ›å»ºæ€»ç»“å›¾
    fig, axes = plt.subplots(2, 3, figsize=(18, 10))
    fig.suptitle('Training Summary', fontsize=16, fontweight='bold')
    
    # 1. æŸå¤±æ›²çº¿
    ax = axes[0, 0]
    ax.plot(loss_history['epochs'], loss_history['train_loss'], 'b-', label='Train', linewidth=2)
    ax.plot(loss_history['epochs'], loss_history['val_loss'], 'r-', label='Val', linewidth=2)
    ax.set_xlabel('Epoch')
    ax.set_ylabel('Loss')
    ax.set_title('Loss Curves')
    ax.legend()
    ax.grid(True, alpha=0.3)
    
    # 2. æŸå¤±å·®è·
    ax = axes[0, 1]
    gap = np.array(loss_history['val_loss']) - np.array(loss_history['train_loss'])
    ax.plot(loss_history['epochs'], gap, 'g-', linewidth=2)
    ax.axhline(y=0, color='k', linestyle='--', alpha=0.3)
    ax.set_xlabel('Epoch')
    ax.set_ylabel('Gap (Val - Train)')
    ax.set_title('Generalization Gap')
    ax.grid(True, alpha=0.3)
    
    # 3. å­¦ä¹ ç‡
    ax = axes[0, 2]
    ax.plot(loss_history['epochs'], loss_history['learning_rates'], 'orange', linewidth=2)
    ax.set_xlabel('Epoch')
    ax.set_ylabel('Learning Rate')
    ax.set_title('Learning Rate Schedule')
    ax.set_yscale('log')
    ax.grid(True, alpha=0.3)
    
    # 4. æŸå¤±åˆ†å¸ƒï¼ˆç®±çº¿å›¾ï¼‰
    ax = axes[1, 0]
    data_to_plot = [loss_history['train_loss'][-20:], loss_history['val_loss'][-20:]]
    bp = ax.boxplot(data_to_plot, labels=['Train', 'Val'])
    ax.set_ylabel('Loss')
    ax.set_title('Loss Distribution (Last 20 Epochs)')
    ax.grid(True, alpha=0.3)
    
    # 5. æ”¶æ•›é€Ÿåº¦
    ax = axes[1, 1]
    if len(loss_history['val_loss']) > 1:
        convergence_rate = np.diff(loss_history['val_loss'])
        ax.plot(loss_history['epochs'][1:], convergence_rate, 'purple', linewidth=1.5)
        ax.axhline(y=0, color='k', linestyle='--', alpha=0.3)
        ax.set_xlabel('Epoch')
        ax.set_ylabel('Loss Change')
        ax.set_title('Convergence Rate (Val Loss)')
        ax.grid(True, alpha=0.3)
    
    # 6. æœ€ä½³æ¨¡å‹ä¿¡æ¯
    ax = axes[1, 2]
    ax.axis('off')
    best_epoch = np.argmin(loss_history['val_loss'])
    best_val_loss = loss_history['val_loss'][best_epoch]
    best_train_loss = loss_history['train_loss'][best_epoch]
    
    info_text = f"""
    Best Model Information:
    ----------------------
    Epoch: {loss_history['epochs'][best_epoch]}
    Val Loss: {best_val_loss:.4f}
    Train Loss: {best_train_loss:.4f}
    Gap: {best_val_loss - best_train_loss:.4f}
    
    Final Model:
    -----------
    Epoch: {loss_history['epochs'][-1]}
    Val Loss: {loss_history['val_loss'][-1]:.4f}
    Train Loss: {loss_history['train_loss'][-1]:.4f}
    """
    ax.text(0.1, 0.5, info_text, fontsize=11, family='monospace', 
            verticalalignment='center')
    
    plt.tight_layout()
    
    # ä¿å­˜
    save_path = Path(checkpoint_path).parent / 'training_summary.png'
    plt.savefig(save_path, dpi=100, bbox_inches='tight')
    plt.close()
    
    print(f"âœ“ è®­ç»ƒæ€»ç»“å·²ä¿å­˜è‡³: {save_path}")


def main():
    parser = argparse.ArgumentParser(description='Train MFP Model with Masking and Loss Visualization')
    
    parser.add_argument('--data_dir', type=str, required=True)
    parser.add_argument('--config', type=str, default='config/train_config.json')
    parser.add_argument('--batch_size', type=int, default=None)
    parser.add_argument('--num_epochs', type=int, default=None)
    parser.add_argument('--learning_rate', type=float, default=None)
    parser.add_argument('--device', type=str, default='cuda')
    parser.add_argument('--save_dir', type=str, default='./checkpoints')
    parser.add_argument('--log_dir', type=str, default='./logs')
    parser.add_argument('--resume', type=str, default=None)
    parser.add_argument('--visualize_only', type=str, default=None, 
                       help='ä»…å¯è§†åŒ–å·²æœ‰çš„checkpoint')
    
    args = parser.parse_args()
    
    # å¦‚æœåªæ˜¯å¯è§†åŒ–
    if args.visualize_only:
        visualize_training_summary(args.visualize_only)
        return
    
    # åŠ è½½é…ç½®
    with open(args.config, 'r') as f:
        config = json.load(f)
    
    # å‘½ä»¤è¡Œå‚æ•°è¦†ç›–
    if args.batch_size is not None:
        config['training']['batch_size'] = args.batch_size
    if args.num_epochs is not None:
        config['training']['num_epochs'] = args.num_epochs
    if args.learning_rate is not None:
        config['training']['learning_rate'] = args.learning_rate
    
    # åˆ›å»ºæ•°æ®åŠ è½½å™¨
    print("\nåŠ è½½æ•°æ®...")
    train_loader = create_dataloader(
        args.data_dir, 'train',
        batch_size=config['training']['batch_size'],
        shuffle=True,
        num_workers=config['data'].get('num_workers', 4),
        max_length=config['data'].get('max_length', 20),
    )
    
    val_loader = create_dataloader(
        args.data_dir, 'val',
        batch_size=config['training']['batch_size'],
        shuffle=False,
        num_workers=config['data'].get('num_workers', 4),
        max_length=config['data'].get('max_length', 20),
    )
    
    # è·å–input_columns
    dataset = train_loader.dataset
    input_columns = dataset.get_input_columns()
    
    # åˆ›å»ºæ¨¡å‹
    print("\nåˆ›å»ºæ¨¡å‹...")
    model = MFP(
        input_columns=input_columns,
        embed_dim=config['model']['embed_dim'],
        num_blocks=config['model']['num_blocks'],
        num_heads=config['model']['num_heads'],
        dropout=config['model']['dropout'],
        max_length=config['model']['max_length'],
    )
    
    # åˆ›å»ºè®­ç»ƒå™¨
    trainer = MFPTrainer(
        model=model,
        train_loader=train_loader,
        val_loader=val_loader,
        config=config,
        device=args.device,
        save_dir=args.save_dir,
        log_dir=args.log_dir,
        resume_path=args.resume,
    )
    
    # å¼€å§‹è®­ç»ƒ
    trainer.train()
    
    # ç”Ÿæˆæœ€ç»ˆçš„è®­ç»ƒæ€»ç»“
    final_checkpoint = Path(args.save_dir) / 'best.pth'
    if final_checkpoint.exists():
        visualize_training_summary(str(final_checkpoint))


if __name__ == "__main__":
    main()