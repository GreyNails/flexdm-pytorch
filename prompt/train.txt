===== models_pytorch.py =====
"""
PyTorch模型架构 - 完全修复版本
严格对齐TensorFlow原始实现
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
from typing import Dict, Optional
import math


# ==================== Transformer Components ====================

class MultiHeadSelfAttention(nn.Module):
    """多头自注意力机制"""
    
    def __init__(
        self,
        embed_dim: int,
        num_heads: int = 8,
        dropout: float = 0.1,
        lookahead: bool = True,
    ):
        super().__init__()
        assert embed_dim % num_heads == 0
        
        self.embed_dim = embed_dim
        self.num_heads = num_heads
        self.head_dim = embed_dim // num_heads
        self.lookahead = lookahead
        
        self.q_proj = nn.Linear(embed_dim, embed_dim)
        self.k_proj = nn.Linear(embed_dim, embed_dim)
        self.v_proj = nn.Linear(embed_dim, embed_dim)
        self.out_proj = nn.Linear(embed_dim, embed_dim)
        
        self.dropout = nn.Dropout(dropout)
        
    def forward(self, x: torch.Tensor, mask: Optional[torch.Tensor] = None):
        B, S, D = x.shape
        
        q = self.q_proj(x).view(B, S, self.num_heads, self.head_dim).transpose(1, 2)
        k = self.k_proj(x).view(B, S, self.num_heads, self.head_dim).transpose(1, 2)
        v = self.v_proj(x).view(B, S, self.num_heads, self.head_dim).transpose(1, 2)
        
        scores = torch.matmul(q, k.transpose(-2, -1)) / math.sqrt(self.head_dim)
        
        if mask is not None:
            mask = mask.unsqueeze(1).unsqueeze(2)
            scores = scores.masked_fill(~mask, float('-inf'))
            
            if not self.lookahead:
                causal_mask = torch.triu(
                    torch.ones(S, S, device=x.device, dtype=torch.bool),
                    diagonal=1
                )
                scores = scores.masked_fill(causal_mask, float('-inf'))
        
        attn_weights = F.softmax(scores, dim=-1)
        attn_weights = self.dropout(attn_weights)
        
        out = torch.matmul(attn_weights, v)
        out = out.transpose(1, 2).contiguous().view(B, S, D)
        out = self.out_proj(out)
        return out


class TransformerBlock(nn.Module):
    """Transformer块(DeepSVG风格)"""
    
    def __init__(
        self,
        embed_dim: int = 128,
        num_heads: int = 8,
        ff_dim: Optional[int] = None,
        dropout: float = 0.1,
        lookahead: bool = True,
    ):
        super().__init__()
        ff_dim = ff_dim or (2 * embed_dim)
        
        self.norm1 = nn.LayerNorm(embed_dim)
        self.attn = MultiHeadSelfAttention(
            embed_dim, num_heads, dropout, lookahead
        )
        self.dropout1 = nn.Dropout(dropout)
        
        self.norm2 = nn.LayerNorm(embed_dim)
        self.ffn = nn.Sequential(
            nn.Linear(embed_dim, ff_dim),
            nn.ReLU(),
            nn.Linear(ff_dim, embed_dim),
        )
        self.dropout2 = nn.Dropout(dropout)
    
    def forward(self, x: torch.Tensor, mask: Optional[torch.Tensor] = None):
        residual = x
        x = self.norm1(x)
        x = self.attn(x, mask)
        x = self.dropout1(x)
        x = residual + x
        
        residual = x
        x = self.norm2(x)
        x = self.ffn(x)
        x = self.dropout2(x)
        x = residual + x
        
        return x


class TransformerBlocks(nn.Module):
    """堆叠的Transformer块"""
    
    def __init__(
        self,
        num_blocks: int = 4,
        embed_dim: int = 128,
        num_heads: int = 8,
        dropout: float = 0.1,
        lookahead: bool = True,
    ):
        super().__init__()
        self.blocks = nn.ModuleList([
            TransformerBlock(embed_dim, num_heads, dropout=dropout, lookahead=lookahead)
            for _ in range(num_blocks)
        ])
    
    def forward(self, x: torch.Tensor, mask: Optional[torch.Tensor] = None):
        for block in self.blocks:
            x = block(x, mask)
        return x


# ==================== Encoder(修复版本)====================

class Encoder(nn.Module):
    """编码器 - 严格对齐TF版本"""
    
    def __init__(
        self,
        input_columns: Dict,
        embed_dim: int = 128,
        dropout: float = 0.1,
        max_length: int = 50,
    ):
        super().__init__()
        self.input_columns = input_columns
        self.embed_dim = embed_dim
        
        # 使用列表存储层
        self.emb_layers = nn.ModuleList()
        self.emb_keys = []
        
        print("初始化Encoder:")
        for key, column in input_columns.items():
            # 跳过非序列字段和demo_only字段
            if not column.get('is_sequence', False):
                continue
            if column.get('demo_only', False):
                continue
            
            self.emb_keys.append(key)
            
            if column['type'] == 'categorical':
                # +2 用于<MASK>和<UNUSED>标记
                vocab_size = column['input_dim'] + 2
                self.emb_layers.append(nn.Embedding(vocab_size, embed_dim))
                print(f"  {key}: Embedding({vocab_size}, {embed_dim})")
            elif column['type'] == 'numerical':
                # 数值类型需要额外的特殊标记嵌入
                input_size = column['shape'][-1] if 'shape' in column else 1
                self.emb_layers.append(nn.Linear(input_size, embed_dim))
                print(f"  {key}: Linear({input_size}, {embed_dim})")
        
        print(f"总计: {len(self.emb_keys)} 个特征")
        
        self.pos_embedding = nn.Embedding(max_length + 1, embed_dim)
        self.dropout = nn.Dropout(dropout)
    
    def forward(self, inputs: Dict[str, torch.Tensor]) -> tuple:
        """前向传播"""
        batch_size = inputs['length'].size(0)
        
        # 找到序列长度
        seq_len = None
        for key in self.emb_keys:
            if key in inputs:
                seq_len = inputs[key].size(1)
                break
        
        if seq_len is None:
            raise ValueError("未找到序列特征")
        
        # 编码每个特征
        seq_embs = []
        for idx, key in enumerate(self.emb_keys):
            if key not in inputs:
                continue
            
            x = inputs[key]
            layer = self.emb_layers[idx]
            
            # 根据层类型自动转换输入数据类型
            if isinstance(layer, nn.Embedding):
                if x.dtype != torch.long:
                    x = x.long()
            elif isinstance(layer, nn.Linear):
                if x.dtype != torch.float:
                    x = x.float()
            
            emb = layer(x)
            
            # 处理多维特征(如RGB) - sum across feature dimension
            if len(emb.shape) == 4:  # (B, S, 3, D)
                emb = emb.sum(dim=2)  # -> (B, S, D)
            
            seq_embs.append(emb)
        
        # 融合特征 - element-wise addition
        seq = torch.stack(seq_embs).sum(dim=0)
        
        # 位置编码
        positions = torch.arange(seq_len, device=seq.device).unsqueeze(0).expand(batch_size, -1)
        seq = seq + self.pos_embedding(positions)
        seq = self.dropout(seq)
        
        # 生成掩码
        lengths = inputs['length'].squeeze(-1)
        mask = torch.arange(seq_len, device=seq.device).unsqueeze(0) < lengths.unsqueeze(1)
        
        return seq, mask


# ==================== Decoder(修复版本)====================

class Decoder(nn.Module):
    """解码器 - 严格对齐TF版本"""
    
    def __init__(self, input_columns: Dict, embed_dim: int = 128):
        super().__init__()
        self.input_columns = input_columns
        
        # 使用列表存储层
        self.head_layers = nn.ModuleList()
        self.head_keys = []
        self.head_configs = []
        
        print("初始化Decoder:")
        for key, column in input_columns.items():
            # 跳过非序列字段和demo_only字段
            if not column.get('is_sequence', False):
                continue
            if column.get('demo_only', False):
                continue
            
            self.head_keys.append(key)
            self.head_configs.append(column)
            
            if column['type'] == 'categorical':
                shape = column.get('shape', [1])
                # 关键修复：输出维度 = shape[-1] * input_dim
                output_dim = shape[-1] * column['input_dim']
                self.head_layers.append(nn.Linear(embed_dim, output_dim))
                print(f"  {key}: Linear({embed_dim}, {output_dim}) -> ({shape[-1]}, {column['input_dim']})")
            else:
                shape = column.get('shape', [1])
                output_dim = shape[-1]
                self.head_layers.append(nn.Linear(embed_dim, output_dim))
                print(f"  {key}: Linear({embed_dim}, {output_dim})")
        
        print(f"总计: {len(self.head_keys)} 个输出头")
    
    def forward(self, x: torch.Tensor) -> Dict[str, torch.Tensor]:
        outputs = {}
        batch_size, seq_len, _ = x.shape
        
        for idx, key in enumerate(self.head_keys):
            column = self.head_configs[idx]
            pred = self.head_layers[idx](x)
            
            if column['type'] == 'categorical':
                shape = column.get('shape', [1])
                num_features = shape[-1]
                vocab_size = column['input_dim']
                # Reshape: (B, S, num_features*vocab_size) -> (B, S, num_features, vocab_size)
                pred = pred.view(batch_size, seq_len, num_features, vocab_size)
            
            outputs[key] = pred
        
        return outputs


# ==================== MFP Model ====================

class MFP(nn.Module):
    """Masked Field Prediction模型"""
    
    def __init__(
        self,
        input_columns: Dict,
        embed_dim: int = 128,
        num_blocks: int = 4,
        num_heads: int = 8,
        dropout: float = 0.1,
        max_length: int = 50,
    ):
        super().__init__()
        self.input_columns = input_columns
        
        print("\n" + "="*60)
        print("初始化MFP模型")
        print("="*60)
        
        self.encoder = Encoder(
            input_columns, embed_dim, dropout, max_length
        )
        
        print("\n初始化Transformer:")
        print(f"  blocks={num_blocks}, embed_dim={embed_dim}, num_heads={num_heads}")
        self.transformer = TransformerBlocks(
            num_blocks, embed_dim, num_heads, dropout, lookahead=True
        )
        
        print("")
        self.decoder = Decoder(input_columns, embed_dim)
        
        total_params = sum(p.numel() for p in self.parameters())
        print(f"\n总参数数: {total_params:,}")
        print("="*60 + "\n")
    
    def forward(self, inputs: Dict[str, torch.Tensor]) -> Dict[str, torch.Tensor]:
        x, mask = self.encoder(inputs) #torch.Size([20, 20, 256])
        x = self.transformer(x, mask) #torch.Size([20, 20, 256])
        outputs = self.decoder(x)
        return outputs
    
    def load_converted_weights(self, checkpoint_path: str):
        """加载转换后的权重"""
        checkpoint = torch.load(checkpoint_path, map_location='cpu')
        state_dict = checkpoint['state_dict']
        
        missing_keys, unexpected_keys = self.load_state_dict(state_dict, strict=False)
        
        if missing_keys:
            print(f"警告: 缺失 {len(missing_keys)} 个键")
            for key in missing_keys[:5]:
                print(f"  - {key}")
        if unexpected_keys:
            print(f"警告: 多余 {len(unexpected_keys)} 个键")
            for key in unexpected_keys[:5]:
                print(f"  - {key}")
        
        print("✓ 权重加载完成")


# ==================== 测试代码 ====================

if __name__ == "__main__":
    print("测试MFP模型(修复版本)\n")
    
    # 使用原始TF格式的input_columns
    input_columns = {
        'type': {
            'is_sequence': True, 
            'type': 'categorical', 
            'input_dim': 6, 
            'shape': [1]
        },
        'left': {
            'is_sequence': True, 
            'type': 'categorical', 
            'input_dim': 64, 
            'shape': [1]
        },
        'top': {
            'is_sequence': True, 
            'type': 'categorical', 
            'input_dim': 64, 
            'shape': [1]
        },
        'width': {
            'is_sequence': True, 
            'type': 'categorical', 
            'input_dim': 64, 
            'shape': [1]
        },
        'height': {
            'is_sequence': True, 
            'type': 'categorical', 
            'input_dim': 64, 
            'shape': [1]
        },
        'opacity': {
            'is_sequence': True, 
            'type': 'categorical', 
            'input_dim': 8, 
            'shape': [1]
        },
        'color': {
            'is_sequence': True, 
            'type': 'categorical', 
            'input_dim': 16, 
            'shape': [3]
        },
        'image_embedding': {
            'is_sequence': True, 
            'type': 'numerical', 
            'shape': [512]
        },
        'text_embedding': {
            'is_sequence': True, 
            'type': 'numerical', 
            'shape': [512]
        },
        'font_family': {
            'is_sequence': True, 
            'type': 'categorical', 
            'input_dim': 35, 
            'shape': [1]
        },
        'uuid': {
            'is_sequence': True, 
            'demo_only': True,
            'type': 'categorical', 
            'input_dim': 1215, 
            'shape': [1]
        },
    }
    
    model = MFP(input_columns, embed_dim=256, num_blocks=4)
    
    # 测试前向传播
    batch_size = 2
    seq_len = 10
    
    test_input = {
        'length': torch.tensor([[5], [7]], dtype=torch.long),
        'type': torch.randint(0, 6, (batch_size, seq_len, 1)),
        'left': torch.randint(0, 64, (batch_size, seq_len, 1)),
        'top': torch.randint(0, 64, (batch_size, seq_len, 1)),
        'width': torch.randint(0, 64, (batch_size, seq_len, 1)),
        'height': torch.randint(0, 64, (batch_size, seq_len, 1)),
        'opacity': torch.randint(0, 8, (batch_size, seq_len, 1)),
        'color': torch.randint(0, 16, (batch_size, seq_len, 3)),
        'image_embedding': torch.randn(batch_size, seq_len, 512),
        'text_embedding': torch.randn(batch_size, seq_len, 512),
        'font_family': torch.randint(0, 35, (batch_size, seq_len, 1)),
    }
    
    print("测试前向传播...")
    with torch.no_grad():
        outputs = model(test_input)
    
    print("\n✓ 前向传播成功!")
    print("\n输出形状:")
    for key, value in outputs.items():
        print(f"  {key:20s}: {list(value.shape)}")
    
    print("\n预期形状对比:")
    print("  type:  [2, 10, 1, 6]")
    print("  color: [2, 10, 3, 16]")
    print("  opacity: [2, 10, 1, 8]")

===== retriever_pytorch.py =====
"""
PyTorch版本的检索器
用于图像和文本的最近邻检索
"""

import json
import logging
from pathlib import Path
from typing import Any, Dict, List
from base64 import b64encode

import torch
import numpy as np

# 使用faiss进行快速检索
try:
    import faiss
    FAISS_AVAILABLE = True
except ImportError:
    FAISS_AVAILABLE = False
    logging.warning("Faiss not available, using brute force search")

logger = logging.getLogger(__name__)


class BaseRetriever:
    """基础检索器"""
    
    def __init__(
        self,
        data_path: Path,
        key: str,
        value: str,
        condition: Dict[str, Any] = None,
        dim: int = 512,
    ):
        """
        Args:
            data_path: 数据路径
            key: 查询键
            value: 检索值
            condition: 条件过滤
            dim: 嵌入维度
        """
        self.data_path = Path(data_path)
        self.key = key
        self.value = value
        self.condition = condition
        self.dim = dim
        
        self.labels = None
        self.db = None
    
    def build(self, split: str = 'train'):
        """
        构建检索索引
        
        Args:
            split: 数据集划分
        """
        logger.info(f"Building {self.__class__.__name__} index for {split}...")
        
        # 加载数据
        json_file = self.data_path / f"{split}.json"
        if not json_file.exists():
            logger.warning(f"Data file not found: {json_file}")
            return
        
        with open(json_file, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        # 提取嵌入和标签
        embeddings = []
        labels = []
        
        for item in data:
            length = item['length']
            
            for i in range(length):
                # 检查条件
                if self.condition:
                    cond_key = self.condition['key']
                    cond_values = self.condition['values']
                    if item[cond_key][i] not in cond_values:
                        continue
                
                # 提取嵌入和标签
                if self.key in item and self.value in item:
                    key_val = item[self.key][i]
                    value_val = item[self.value][i]
                    
                    if isinstance(value_val, list) and len(value_val) == self.dim:
                        embeddings.append(value_val)
                        labels.append(key_val)
        
        if not embeddings:
            logger.warning(f"No embeddings found for {split}")
            return
        
        # 去重
        unique_data = {}
        for label, emb in zip(labels, embeddings):
            if label not in unique_data:
                unique_data[label] = emb
        
        self.labels = np.array(list(unique_data.keys()))
        embeddings_list = list(unique_data.values())
        
        # 确保正确转换为连续的2D numpy数组
        if embeddings_list:
            # 先转换为 numpy 数组
            embeddings = np.array(embeddings_list, dtype=np.float32)
            
            # 确保是 C-contiguous 内存布局
            if not embeddings.flags['C_CONTIGUOUS']:
                embeddings = np.ascontiguousarray(embeddings)
            
            # 验证形状和类型
            assert embeddings.ndim == 2, f"Expected 2D array, got {embeddings.ndim}D"
            assert embeddings.shape[1] == self.dim, f"Expected dim={self.dim}, got {embeddings.shape[1]}"
            assert embeddings.dtype == np.float32, f"Expected float32, got {embeddings.dtype}"
            
            logger.info(f"Embeddings shape: {embeddings.shape}, dtype: {embeddings.dtype}, "
                       f"C-contiguous: {embeddings.flags['C_CONTIGUOUS']}")
        else:
            logger.warning(f"No embeddings after deduplication for {split}")
            return
        
        # 构建索引
        if FAISS_AVAILABLE:
            try:
                self.db = faiss.IndexFlatL2(self.dim)
                # 确保 embeddings 是正确的格式
                embeddings_copy = np.copy(embeddings, order='C')
                self.db.add(embeddings_copy)
            except Exception as e:
                logger.error(f"Faiss error: {e}")
                logger.info("Falling back to PyTorch brute force search")
                self.db = torch.from_numpy(embeddings)
        else:
            # 使用PyTorch进行暴力搜索
            self.db = torch.from_numpy(embeddings)
        
        logger.info(f"✓ Built index with {len(self.labels)} items")
    
    def search(self, query, k: int = 1):
        """
        搜索最近邻
        
        Args:
            query: 查询向量
            k: 返回的最近邻数量
        
        Returns:
            检索结果
        """
        if self.labels is None or self.db is None:
            return self.get_default_result()
        
        # 转换查询为numpy
        if torch.is_tensor(query):
            query = query.cpu().numpy()
        if not isinstance(query, np.ndarray):
            query = np.array(query, dtype=np.float32)
        
        if query.ndim == 1:
            query = query.reshape(1, -1)
        
        # 确保查询是 C-contiguous 和 float32
        query = np.ascontiguousarray(query, dtype=np.float32)
        
        # 搜索
        if FAISS_AVAILABLE:
            _, indices = self.db.search(query, k)
        else:
            # PyTorch暴力搜索
            query_torch = torch.from_numpy(query)
            distances = torch.cdist(query_torch, self.db)
            _, indices = distances.topk(k, largest=False)
            indices = indices.cpu().numpy()
        
        # 获取结果
        results = [self.get_url(idx) for idx in indices[0]]
        
        return results[0] if k == 1 else results
    
    def get_url(self, index: int) -> str:
        """获取URL（子类实现）"""
        raise NotImplementedError
    
    def get_default_result(self):
        """获取默认结果"""
        return ""


class ImageRetriever(BaseRetriever):
    """图像检索器"""
    
    def __init__(
        self,
        data_path: Path,
        key: str = 'image_hash',
        value: str = 'image_embedding',
        condition: Dict[str, Any] = None,
        image_path: Path = None,
        dim: int = 512,
    ):
        """
        Args:
            data_path: 数据路径
            key: 图像哈希键
            value: 图像嵌入键
            condition: 条件过滤
            image_path: 图像文件路径
            dim: 嵌入维度
        """
        super().__init__(data_path, key, value, condition, dim)
        
        if condition is None:
            self.condition = {
                'key': 'type',
                'values': ['imageElement', 'maskElement', 'svgElement', 'humanElement'],
            }
        
        self.image_path = image_path or self.data_path / 'images'
    
    def get_url(self, index: int) -> str:
        """获取图像URL"""
        label = self.labels[index]
        
        if isinstance(label, bytes):
            label = label.decode('utf-8')
        
        if label:
            image_file = self.image_path / f"{label}.png"
            if image_file.exists():
                return self._make_data_uri(image_file)
        
        return ""
    
    def _make_data_uri(self, file_path: Path, mime_type: str = 'image/png') -> str:
        """创建data URI"""
        try:
            with open(file_path, 'rb') as f:
                image_bytes = f.read()
            data = b64encode(image_bytes).decode('ascii')
            return f"data:{mime_type};base64,{data}"
        except Exception as e:
            logger.warning(f"Failed to read image {file_path}: {e}")
            return ""


class TextRetriever(BaseRetriever):
    """文本检索器"""
    
    def __init__(
        self,
        data_path: Path,
        key: str = 'text_hash',
        value: str = 'text_embedding',
        condition: Dict[str, Any] = None,
        text_path: Path = None,
        dim: int = 512,
    ):
        """
        Args:
            data_path: 数据路径
            key: 文本哈希键
            value: 文本嵌入键
            condition: 条件过滤
            text_path: 文本文件路径
            dim: 嵌入维度
        """
        super().__init__(data_path, key, value, condition, dim)
        
        if condition is None:
            self.condition = {
                'key': 'type',
                'values': ['textElement'],
            }
        
        self.text_path = text_path or self.data_path / 'texts'
    
    def get_url(self, index: int) -> str:
        """获取文本内容"""
        label = self.labels[index]
        
        if isinstance(label, bytes):
            label = label.decode('utf-8')
        
        if label:
            text_file = self.text_path / f"{label}.txt"
            if text_file.exists():
                try:
                    with open(text_file, 'r', encoding='utf-8') as f:
                        return f.read()
                except Exception as e:
                    logger.warning(f"Failed to read text {text_file}: {e}")
        
        return "TEXT"


# 测试代码
if __name__ == "__main__":
    logging.basicConfig(level=logging.INFO)
    
    # 测试路径
    data_path = Path("./data/crello_json")
    
    if data_path.exists():
        # 测试图像检索
        print("测试图像检索器...")
        image_retriever = ImageRetriever(
            data_path,
            image_path=data_path.parent / "crello" / "images"
        )
        image_retriever.build("test")
        
        # 测试查询
        if image_retriever.labels is not None:
            test_query = np.random.randn(512).astype(np.float32)
            result = image_retriever.search(test_query)
            print(f"图像检索结果长度: {len(result)}")
        
        # 测试文本检索
        print("\n测试文本检索器...")
        text_retriever = TextRetriever(
            data_path,
            text_path=data_path.parent / "crello" / "texts"
        )
        text_retriever.build("test")
        
        # 测试查询
        if text_retriever.labels is not None:
            test_query = np.random.randn(512).astype(np.float32)
            result = text_retriever.search(test_query)
            print(f"文本检索结果: {result[:50]}...")
        
        print("\n✓ 测试完成!")
    else:
        print(f"数据路径不存在: {data_path}")

===== train_pytorch.py =====
"""
PyTorch训练脚本
MFP模型的训练和评估
"""

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
from torch.utils.tensorboard import SummaryWriter
from pathlib import Path
import argparse
import json
from tqdm import tqdm
import time

from dataset import create_dataloader
from models_pytorch import MFP


class MFPTrainer:
    """MFP模型训练器"""
    
    def __init__(
        self,
        model: nn.Module,
        train_loader: DataLoader,
        val_loader: DataLoader,
        device: str = 'cuda',
        learning_rate: float = 1e-4,
        num_epochs: int = 100,
        save_dir: str = './checkpoints',
        log_dir: str = './logs',
    ):
        self.model = model.to(device)
        self.train_loader = train_loader
        self.val_loader = val_loader
        self.device = device
        self.num_epochs = num_epochs
        
        # 优化器
        self.optimizer = optim.Adam(
            model.parameters(),
            lr=learning_rate,
            betas=(0.9, 0.999),
        )
        
        # 学习率调度器
        self.scheduler = optim.lr_scheduler.ReduceLROnPlateau(
            self.optimizer,
            mode='min',
            factor=0.5,
            patience=5,
            verbose=True,
        )
        
        # 目录设置
        self.save_dir = Path(save_dir)
        self.save_dir.mkdir(parents=True, exist_ok=True)
        
        # TensorBoard
        self.writer = SummaryWriter(log_dir)
        
        # 跟踪最佳模型
        self.best_val_loss = float('inf')
        self.global_step = 0
    
    def compute_loss(
        self,
        predictions: dict,
        targets: dict,
        mask: torch.Tensor,
    ) -> dict:
        """
        计算多任务损失
        
        Args:
            predictions: 模型预测
            targets: 真实标签
            mask: 有效位置掩码 (B, S)
        
        Returns:
            损失字典
        """
        losses = {}
        total_loss = 0.0
        
        for key in predictions.keys():
            pred = predictions[key]
            target = targets[key]
            
            # 获取列信息
            column = self.model.input_columns[key]
            
            if column['type'] == 'categorical':
                # 分类任务：交叉熵损失
                # pred: (B, S, F, C), target: (B, S, F)
                B, S, F, C = pred.shape
                pred = pred.reshape(B * S * F, C)
                target = target.reshape(B * S * F)
                
                loss = F.cross_entropy(pred, target, reduction='none')
                loss = loss.reshape(B, S, F)
                
                # 应用掩码并求平均
                mask_expanded = mask.unsqueeze(-1).expand_as(loss)
                loss = (loss * mask_expanded.float()).sum() / mask_expanded.sum()
            else:
                # 回归任务：MSE损失
                # pred: (B, S, D), target: (B, S, D)
                loss = F.mse_loss(pred, target, reduction='none')
                
                # 应用掩码
                mask_expanded = mask.unsqueeze(-1).expand_as(loss)
                loss = (loss * mask_expanded.float()).sum() / mask_expanded.sum()
            
            losses[f'{key}_loss'] = loss
            total_loss += loss
        
        losses['total_loss'] = total_loss
        return losses
    
    def train_epoch(self, epoch: int):
        """训练一个epoch"""
        self.model.train()
        epoch_losses = {}
        
        pbar = tqdm(self.train_loader, desc=f'Epoch {epoch}')
        for batch in pbar:
            # 移动到设备
            inputs = {k: v.to(self.device) if torch.is_tensor(v) else v 
                     for k, v in batch.items()}
            
            # 前向传播
            outputs = self.model(inputs)
            
            # 生成掩码
            lengths = inputs['length'].squeeze(-1)
            max_len = inputs['left'].size(1)
            mask = torch.arange(max_len, device=self.device).unsqueeze(0) < lengths.unsqueeze(1)
            
            # 计算损失
            losses = self.compute_loss(outputs, inputs, mask)
            
            # 反向传播
            self.optimizer.zero_grad()
            losses['total_loss'].backward()
            torch.nn.utils.clip_grad_norm_(self.model.parameters(), 1.0)
            self.optimizer.step()
            
            # 记录损失
            for key, value in losses.items():
                if key not in epoch_losses:
                    epoch_losses[key] = []
                epoch_losses[key].append(value.item())
            
            # 更新进度条
            pbar.set_postfix({'loss': f"{losses['total_loss'].item():.4f}"})
            
            # TensorBoard记录
            if self.global_step % 100 == 0:
                for key, value in losses.items():
                    self.writer.add_scalar(f'train/{key}', value.item(), self.global_step)
            
            self.global_step += 1
        
        # 计算epoch平均损失
        avg_losses = {k: sum(v) / len(v) for k, v in epoch_losses.items()}
        return avg_losses
    
    @torch.no_grad()
    def validate(self, epoch: int):
        """验证"""
        self.model.eval()
        epoch_losses = {}
        
        for batch in tqdm(self.val_loader, desc='Validation'):
            # 移动到设备
            inputs = {k: v.to(self.device) if torch.is_tensor(v) else v 
                     for k, v in batch.items()}
            
            # 前向传播
            outputs = self.model(inputs)
            
            # 生成掩码
            lengths = inputs['length'].squeeze(-1)
            max_len = inputs['left'].size(1)
            mask = torch.arange(max_len, device=self.device).unsqueeze(0) < lengths.unsqueeze(1)
            
            # 计算损失
            losses = self.compute_loss(outputs, inputs, mask)
            
            # 记录损失
            for key, value in losses.items():
                if key not in epoch_losses:
                    epoch_losses[key] = []
                epoch_losses[key].append(value.item())
        
        # 计算平均损失
        avg_losses = {k: sum(v) / len(v) for k, v in epoch_losses.items()}
        
        # TensorBoard记录
        for key, value in avg_losses.items():
            self.writer.add_scalar(f'val/{key}', value, epoch)
        
        return avg_losses
    
    def save_checkpoint(self, epoch: int, is_best: bool = False):
        """保存checkpoint"""
        checkpoint = {
            'epoch': epoch,
            'model_state_dict': self.model.state_dict(),
            'optimizer_state_dict': self.optimizer.state_dict(),
            'best_val_loss': self.best_val_loss,
        }
        
        # 保存最新模型
        torch.save(checkpoint, self.save_dir / 'latest.pth')
        
        # 保存最佳模型
        if is_best:
            torch.save(checkpoint, self.save_dir / 'best.pth')
            print(f"✓ 保存最佳模型 (epoch {epoch})")
    
    def train(self):
        """完整训练流程"""
        print("开始训练...")
        print(f"设备: {self.device}")
        print(f"训练批次: {len(self.train_loader)}")
        print(f"验证批次: {len(self.val_loader)}")
        
        for epoch in range(1, self.num_epochs + 1):
            start_time = time.time()
            
            # 训练
            train_losses = self.train_epoch(epoch)
            
            # 验证
            val_losses = self.validate(epoch)
            
            # 学习率调度
            self.scheduler.step(val_losses['total_loss'])
            
            # 打印信息
            epoch_time = time.time() - start_time
            print(f"\nEpoch {epoch}/{self.num_epochs} ({epoch_time:.1f}s)")
            print(f"  Train Loss: {train_losses['total_loss']:.4f}")
            print(f"  Val Loss:   {val_losses['total_loss']:.4f}")
            print(f"  LR: {self.optimizer.param_groups[0]['lr']:.6f}")
            
            # 保存checkpoint
            is_best = val_losses['total_loss'] < self.best_val_loss
            if is_best:
                self.best_val_loss = val_losses['total_loss']
            
            if epoch % 5 == 0 or is_best:
                self.save_checkpoint(epoch, is_best)
        
        print("\n训练完成!")
        self.writer.close()


def main():
    parser = argparse.ArgumentParser()
    
    # 数据参数
    parser.add_argument('--data_dir', type=str, required=True,
                       help='JSON数据目录')
    parser.add_argument('--batch_size', type=int, default=32)
    parser.add_argument('--num_workers', type=int, default=4)
    
    # 模型参数
    parser.add_argument('--embed_dim', type=int, default=128)
    parser.add_argument('--num_blocks', type=int, default=4)
    parser.add_argument('--num_heads', type=int, default=8)
    parser.add_argument('--dropout', type=float, default=0.1)
    
    # 训练参数
    parser.add_argument('--num_epochs', type=int, default=100)
    parser.add_argument('--learning_rate', type=float, default=1e-4)
    parser.add_argument('--device', type=str, default='cuda')
    
    # 保存参数
    parser.add_argument('--save_dir', type=str, default='./checkpoints')
    parser.add_argument('--log_dir', type=str, default='./logs')
    
    # 预训练权重
    parser.add_argument('--pretrained', type=str, default=None,
                       help='预训练权重路径')
    
    args = parser.parse_args()
    
    # 创建数据加载器
    print("加载数据...")
    train_loader = create_dataloader(
        args.data_dir, 'train', args.batch_size,
        shuffle=True, num_workers=args.num_workers
    )
    val_loader = create_dataloader(
        args.data_dir, 'val', args.batch_size,
        shuffle=False, num_workers=args.num_workers
    )
    
    # 获取input_columns (从数据集推断)
    sample = next(iter(train_loader))
    input_columns = {
        'type': {'is_sequence': True, 'type': 'categorical', 'input_dim': 10, 'shape': [1]},
        'left': {'is_sequence': True, 'type': 'categorical', 'input_dim': 64, 'shape': [1]},
        'top': {'is_sequence': True, 'type': 'categorical', 'input_dim': 64, 'shape': [1]},
        'width': {'is_sequence': True, 'type': 'categorical', 'input_dim': 64, 'shape': [1]},
        'height': {'is_sequence': True, 'type': 'categorical', 'input_dim': 64, 'shape': [1]},
        'color': {'is_sequence': True, 'type': 'categorical', 'input_dim': 16, 'shape': [3]},
        'image_embedding': {'is_sequence': True, 'type': 'numerical', 'shape': [512]},
        'text_embedding': {'is_sequence': True, 'type': 'numerical', 'shape': [512]},
    }
    
    # 创建模型
    print("创建模型...")
    model = MFP(
        input_columns,
        embed_dim=args.embed_dim,
        num_blocks=args.num_blocks,
        num_heads=args.num_heads,
        dropout=args.dropout,
    )
    
    # 加载预训练权重
    if args.pretrained:
        print(f"加载预训练权重: {args.pretrained}")
        model.load_converted_weights(args.pretrained)
    
    print(f"模型参数: {sum(p.numel() for p in model.parameters()):,}")
    
    # 创建训练器
    trainer = MFPTrainer(
        model=model,
        train_loader=train_loader,
        val_loader=val_loader,
        device=args.device,
        learning_rate=args.learning_rate,
        num_epochs=args.num_epochs,
        save_dir=args.save_dir,
        log_dir=args.log_dir,
    )
    
    # 开始训练
    trainer.train()


if __name__ == "__main__":
    main()

===== svg_builder_pytorch.py =====
"""
PyTorch版本的SVG构建器（简化版 - 避免命名空间问题）
"""

from typing import Dict, Optional, List
import numpy as np


class SVGBuilder:
    """SVG构建器 - 简化版，使用字符串模板避免XML命名空间问题"""
    
    def __init__(
        self,
        key: str = 'type',
        colormap: Optional[Dict] = None,
        preprocessor = None,
        canvas_width: int = 256,
        canvas_height: int = 256,
        max_width: Optional[int] = None,
        max_height: Optional[int] = None,
        opacity: float = 0.5,
        image_db = None,
        text_db = None,
        render_text: bool = False,
        **kwargs
    ):
        assert key, "key参数不能为空"
        
        self.key = key
        self.canvas_width = canvas_width
        self.canvas_height = canvas_height
        self.max_width = max_width
        self.max_height = max_height
        self.opacity = opacity
        self.image_db = image_db
        self.text_db = text_db
        self.render_text = render_text
        
        # 初始化颜色映射
        if key == 'color':
            self.colormap = None
        elif preprocessor is not None:
            vocabulary = preprocessor.get(key, {}).get('vocabulary', [])
            self.colormap = self._make_colormap(vocabulary, colormap)
        elif colormap is not None:
            self.colormap = colormap
        else:
            self.colormap = self._make_default_colormap()
    
    def _make_default_colormap(self) -> Dict:
        """创建默认颜色映射"""
        return {
            '': 'none',
            'svgElement': 'rgb(66, 166, 246)',
            'textElement': 'rgb(241, 98, 147)',
            'imageElement': 'rgb(175, 214, 130)',
            'maskElement': 'rgb(79, 196, 248)',
            'coloredBackground': 'rgb(226, 191, 232)',
            'videoElement': 'rgb(255, 207, 102)',
            'humanElement': 'rgb(255, 139, 101)',
        }
    
    def _make_colormap(self, vocabulary: List[str], base_colormap=None) -> Dict:
        """根据词汇表自动生成颜色映射"""
        if base_colormap:
            return base_colormap
        
        try:
            from matplotlib import cm
            vocab_size = len(vocabulary)
            cmap = cm.get_cmap('tab20', vocab_size)
            return {
                label: f'rgb({int(c[0]*255)},{int(c[1]*255)},{int(c[2]*255)})'
                for label, c in zip(vocabulary, cmap(range(vocab_size)))
            }
        except ImportError:
            return self._make_default_colormap()
    
    def compute_canvas_size(self, document: Dict):
        """计算实际画布大小"""
        canvas_width = document.get('canvas_width', self.canvas_width)
        canvas_height = document.get('canvas_height', self.canvas_height)
        
        scale = 1.0
        if self.max_width is not None:
            scale = min(self.max_width / canvas_width, scale)
        if self.max_height is not None:
            scale = min(self.max_height / canvas_height, scale)
        
        return canvas_width * scale, canvas_height * scale
    
    def __call__(self, document: Dict) -> str:
        """将文档转换为SVG字符串（使用字符串模板）"""
        canvas_width, canvas_height = self.compute_canvas_size(document)
        
        # SVG头部
        svg_parts = [
            f'<svg width="{int(canvas_width)}" height="{int(canvas_height)}" '
            f'viewBox="0 0 1 1" style="background-color: #FFF" '
            f'preserveAspectRatio="none" '
            f'xmlns="http://www.w3.org/2000/svg" '
            f'xmlns:xlink="http://www.w3.org/1999/xlink">'
        ]
        
        # 添加元素
        elements = document.get('elements', [])
        for i, element in enumerate(elements):
            svg_parts.append(self._element_to_svg(element, i))
        
        # SVG尾部
        svg_parts.append('</svg>')
        
        return '\n'.join(svg_parts)
    
    def _element_to_svg(self, element: Dict, index: int) -> str:
        """将单个元素转换为SVG字符串"""
        # 获取颜色
        if self.key == 'color':
            color = element.get('color', [0, 0, 0])
            if isinstance(color, (list, tuple, np.ndarray)):
                fill = f'rgb({int(color[0])},{int(color[1])},{int(color[2])})'
            else:
                fill = 'rgb(0,0,0)'
        else:
            element_type = element.get(self.key, '')
            if isinstance(element_type, (list, tuple)):
                element_type = element_type[0] if len(element_type) > 0 else ''
            if isinstance(element_type, (int, float, np.integer, np.floating)):
                element_type = str(int(element_type))
            if isinstance(element_type, bytes):
                element_type = element_type.decode('utf-8')
            fill = self.colormap.get(element_type, 'rgb(128,128,128)')
        
        # 获取位置和尺寸
        left = float(element.get('left', 0))
        top = float(element.get('top', 0))
        width = float(element.get('width', 0.1))
        height = float(element.get('height', 0.1))
        opacity_val = float(element.get('opacity', 1.0))
        
        # 元素ID和类型
        uuid = element.get('uuid', f'elem_{index}')
        if isinstance(uuid, bytes):
            uuid = uuid.decode('utf-8')
        elem_type = str(element.get('type', ''))
        
        # 检查图像
        image_url = None
        if self.image_db:
            et = element.get('type', '')
            if isinstance(et, bytes):
                et = et.decode('utf-8')
            if et in self.image_db.condition.get('values', []):
                if self.image_db.value in element:
                    image_url = self.image_db.search(element[self.image_db.value])
        
        # 检查文本
        text_content = None
        if self.text_db or self.render_text:
            et = element.get('type', '')
            if isinstance(et, bytes):
                et = et.decode('utf-8')
            if et == 'textElement':
                if self.text_db and self.text_db.value in element:
                    text_content = self.text_db.search(element[self.text_db.value])
                else:
                    text_content = "TEXT TEXT TEXT"
        
        # 生成SVG
        if image_url and image_url != '':
            return self._make_image_svg(uuid, elem_type, left, top, width, height, opacity_val, image_url)
        elif self.render_text and text_content:
            return self._make_text_svg(uuid, elem_type, left, top, width, height, opacity_val, fill, text_content, element)
        else:
            return self._make_rect_svg(uuid, elem_type, left, top, width, height, opacity_val * self.opacity, fill)
    
    def _make_rect_svg(self, uuid: str, elem_type: str, left: float, top: float, 
                       width: float, height: float, opacity: float, fill: str) -> str:
        """创建矩形SVG"""
        return (
            f'<rect id="{uuid}" class="{elem_type}" '
            f'x="{left:.6f}" y="{top:.6f}" '
            f'width="{width:.6f}" height="{height:.6f}" '
            f'fill="{fill}" opacity="{opacity:.3f}"/>'
        )
    
    def _make_image_svg(self, uuid: str, elem_type: str, left: float, top: float,
                        width: float, height: float, opacity: float, url: str) -> str:
        """创建图像SVG"""
        return (
            f'<image id="{uuid}" class="{elem_type}" '
            f'x="{left:.6f}" y="{top:.6f}" '
            f'width="{width:.6f}" height="{height:.6f}" '
            f'xlink:href="{url}" opacity="{opacity:.3f}" '
            f'preserveAspectRatio="none"/>'
        )
    
    def _make_text_svg(self, uuid: str, elem_type: str, left: float, top: float,
                       width: float, height: float, opacity: float, fill: str,
                       text: str, element: Dict) -> str:
        """创建文本SVG"""
        margin = height * 0.1
        font_size = height * 0.8
        font_family = element.get('font_family', 'Arial')
        if isinstance(font_family, bytes):
            font_family = font_family.decode('utf-8')
        
        display_text = str(text)[:100].strip()
        # 转义XML特殊字符
        display_text = display_text.replace('&', '&amp;').replace('<', '&lt;').replace('>', '&gt;')
        
        opacity_str = f' opacity="{opacity:.3f}"' if opacity < 1 else ''
        
        return (
            f'<svg id="{uuid}" class="{elem_type}" '
            f'x="{left:.6f}" y="{(top - margin):.6f}" '
            f'width="{width:.6f}" height="{(height + margin * 2):.6f}" '
            f'overflow="visible"{opacity_str}>'
            f'<text x="50%" y="50%" text-anchor="middle" dominant-baseline="central" '
            f'fill="{fill}" font-size="{font_size:.6f}" font-family="{font_family}">'
            f'{display_text}</text></svg>'
        )


# 测试代码
if __name__ == "__main__":
    print("="*60)
    print("SVG Builder 测试（简化版）")
    print("="*60)
    
    test_doc = {
        'id': 'test_001',
        'canvas_width': 800,
        'canvas_height': 600,
        'elements': [
            {
                'type': 'coloredBackground',
                'left': 0.0,
                'top': 0.0,
                'width': 1.0,
                'height': 1.0,
                'color': [240, 240, 240],
                'opacity': 1.0,
            },
            {
                'type': 'imageElement',
                'left': 0.1,
                'top': 0.1,
                'width': 0.3,
                'height': 0.4,
                'color': [255, 100, 100],
                'opacity': 1.0,
            },
            {
                'type': 'textElement',
                'left': 0.5,
                'top': 0.2,
                'width': 0.4,
                'height': 0.1,
                'color': [100, 100, 255],
                'opacity': 1.0,
                'font_family': 'Arial',
            },
        ]
    }
    
    print("\n测试1: Layout视图")
    builder_layout = SVGBuilder(key='type', max_width=400, opacity=0.8)
    svg_layout = builder_layout(test_doc)
    with open('test_layout.svg', 'w', encoding='utf-8') as f:
        f.write(svg_layout)
    print(f"✓ 生成 {len(svg_layout)} 字符")
    
    print("\n测试2: Visual视图")
    builder_visual = SVGBuilder(key='color', max_width=400, opacity=1.0, render_text=True)
    svg_visual = builder_visual(test_doc)
    with open('test_visual.svg', 'w', encoding='utf-8') as f:
        f.write(svg_visual)
    print(f"✓ 生成 {len(svg_visual)} 字符")
    
    print("\n" + "="*60)
    print("✓ 测试完成！")
    print("="*60)

===== dataset.py =====
"""
PyTorch数据加载器 - 修复版
生成与TF版本一致的input_columns格式
"""

import json
import torch
from torch.utils.data import Dataset, DataLoader
from pathlib import Path
import numpy as np
from typing import Dict, List, Optional


class DesignLayoutDataset(Dataset):
    """设计布局数据集"""
    
    def __init__(
        self,
        data_path: str,
        split: str = 'train',
        max_length: int = 20,
        bins: int = 64,
        min_font_freq: int = 500,
    ):
        self.data_path = Path(data_path)
        self.split = split
        self.max_length = max_length
        self.bins = bins
        self.min_font_freq = min_font_freq
        
        # 加载数据
        json_file = self.data_path / f"{split}.json"
        print(f"加载数据: {json_file}")
        with open(json_file, 'r', encoding='utf-8') as f:
            self.data = json.load(f)
        
        print(f"✓ 加载了 {len(self.data)} 个样本")
        
        # 加载词汇表
        vocab_file = self.data_path.parent / "vocabulary.json"
        with open(vocab_file, 'r', encoding='utf-8') as f:
            self.vocabulary = json.load(f)
        
        # 构建查找表
        self._build_lookups()
    
    def _build_lookups(self):
        """构建字符串到索引的映射"""
        print("\n构建查找表...")
        
        # === Type映射 ===
        type_vocab = self.vocabulary['type']
        if isinstance(type_vocab, list):
            self.type_to_idx = {v: i+1 for i, v in enumerate(type_vocab)}
        else:
            self.type_to_idx = {k: i+1 for i, k in enumerate(type_vocab.keys())}
        
        type_vocab_size = len(self.type_to_idx)
        self.type_to_idx['<NULL>'] = 0
        self.type_to_idx['<MASK>'] = type_vocab_size + 1
        
        print(f"  Type词汇表: {len(self.type_to_idx)} 个类型")
        
        # === Canvas Width映射 ===
        if 'canvas_width' in self.vocabulary:
            width_vocab = self.vocabulary['canvas_width']
            if isinstance(width_vocab, dict):
                widths = sorted([int(k) for k in width_vocab.keys()])
            elif isinstance(width_vocab, list):
                widths = sorted([int(v) for v in width_vocab])
            else:
                widths = list(range(200, 2001, 100))
            
            self.width_to_idx = {w: i+1 for i, w in enumerate(widths)}
            self.idx_to_width = {i+1: w for i, w in enumerate(widths)}
            self.idx_to_width[0] = widths[0] if widths else 800
            
            self.width_vocab_size = len(widths) + 1
            print(f"  Canvas Width词汇表: {len(widths)} 个尺寸")
            print(f"    范围: {min(widths)} - {max(widths)}")
        else:
            self.width_to_idx = {}
            self.idx_to_width = {0: 800}
            self.width_vocab_size = 1
        
        # === Canvas Height映射 ===
        if 'canvas_height' in self.vocabulary:
            height_vocab = self.vocabulary['canvas_height']
            if isinstance(height_vocab, dict):
                heights = sorted([int(k) for k in height_vocab.keys()])
            elif isinstance(height_vocab, list):
                heights = sorted([int(v) for v in height_vocab])
            else:
                heights = list(range(200, 2001, 100))
            
            self.height_to_idx = {h: i+1 for i, h in enumerate(heights)}
            self.idx_to_height = {i+1: h for i, h in enumerate(heights)}
            self.idx_to_height[0] = heights[0] if heights else 600
            
            self.height_vocab_size = len(heights) + 1
            print(f"  Canvas Height词汇表: {len(heights)} 个尺寸")
            print(f"    范围: {min(heights)} - {max(heights)}")
        else:
            self.height_to_idx = {}
            self.idx_to_height = {0: 600}
            self.height_vocab_size = 1
        
        # === Font映射 ===
        if 'font_family' in self.vocabulary:
            font_vocab = self.vocabulary['font_family']
            
            if isinstance(font_vocab, dict):
                total_fonts = len(font_vocab)
                filtered_fonts = [
                    font for font, count in font_vocab.items() 
                    if count >= self.min_font_freq
                ]
                filtered_fonts.sort()
                
                print(f"  Font过滤: {total_fonts} -> {len(filtered_fonts)} (频率>={self.min_font_freq})")
                self.font_to_idx = {font: i+1 for i, font in enumerate(filtered_fonts)}
            else:
                self.font_to_idx = {v: i+1 for i, v in enumerate(font_vocab)}
            
            vocab_size = len(self.font_to_idx)
            self.font_to_idx['<NULL>'] = 0
            self.font_to_idx['<OOV>'] = vocab_size + 1
            self.font_to_idx['<MASK>'] = vocab_size + 2
            
            self.font_oov_idx = vocab_size + 1
            self.font_vocab_size = vocab_size + 2
            
            print(f"  Font词汇表: {len(self.font_to_idx)} 个token (含特殊token)")
        else:
            self.font_to_idx = {}
            self.font_oov_idx = 0
            self.font_vocab_size = 0
        
        # 反向映射
        self.idx_to_type = {v: k for k, v in self.type_to_idx.items()}
        self.idx_to_font = {v: k for k, v in self.font_to_idx.items()}
    
    def discretize(self, value: float, min_val: float = 0.0, max_val: float = 1.0) -> int:
        """将连续值离散化到bins"""
        value = np.clip(value, min_val, max_val)
        return int((value - min_val) / (max_val - min_val) * (self.bins - 1))
    
    def __len__(self):
        return len(self.data)
    
    def __getitem__(self, idx) -> Dict[str, torch.Tensor]:
        """获取单个样本"""
        item = self.data[idx]
        length = min(item['length'], self.max_length)
        
        # Canvas尺寸
        canvas_w = item['canvas_width']
        canvas_h = item['canvas_height']
        
        width_idx = self.width_to_idx.get(canvas_w, 0)
        height_idx = self.height_to_idx.get(canvas_h, 0)
        
        if width_idx == 0 and self.width_to_idx:
            closest_w = min(self.width_to_idx.keys(), key=lambda x: abs(x - canvas_w))
            width_idx = self.width_to_idx[closest_w]
            
        if height_idx == 0 and self.height_to_idx:
            closest_h = min(self.height_to_idx.keys(), key=lambda x: abs(x - canvas_h))
            height_idx = self.height_to_idx[closest_h]
        
        sample = {
            'id': item['id'],
            'length': torch.tensor([length], dtype=torch.long),
            'canvas_width': torch.tensor([width_idx], dtype=torch.long),
            'canvas_height': torch.tensor([height_idx], dtype=torch.long),
        }
        
        # 位置和尺寸
        for key in ['left', 'top', 'width', 'height']:
            values = [self.discretize(item[key][i]) for i in range(length)]
            values += [0] * (self.max_length - length)
            sample[key] = torch.tensor(values, dtype=torch.long).unsqueeze(-1)
        
        # 类型编码
        type_ids = [self.type_to_idx.get(item['type'][i], 0) for i in range(length)]
        type_ids += [0] * (self.max_length - length)
        sample['type'] = torch.tensor(type_ids, dtype=torch.long).unsqueeze(-1)
        
        # 不透明度 - 🔧 修复：需要离散化
        if 'opacity' in item:
            opacity_values = []
            for i in range(length):
                # 离散化到8个bins
                discrete_val = int(item['opacity'][i] * 7)  # 0.0-1.0 -> 0-7
                opacity_values.append(discrete_val)
            opacity_values += [0] * (self.max_length - length)
            sample['opacity'] = torch.tensor(opacity_values, dtype=torch.long).unsqueeze(-1)
        
        # 颜色 - 🔧 修复：需要离散化RGB值
        if 'color' in item:
            colors = []
            for i in range(length):
                rgb = item['color'][i]
                # 离散化每个通道：0-255 -> 0-15
                discrete_rgb = [int(c * 15 / 255) for c in rgb]
                colors.append(discrete_rgb)
            for _ in range(self.max_length - length):
                colors.append([0, 0, 0])
            sample['color'] = torch.tensor(colors, dtype=torch.long)
        
        # 字体编码
        if 'font_family' in item and self.font_to_idx:
            font_ids = []
            for i in range(length):
                font_name = item['font_family'][i]
                font_id = self.font_to_idx.get(font_name, self.font_oov_idx)
                font_ids.append(font_id)
            
            font_ids += [0] * (self.max_length - length)
            sample['font_family'] = torch.tensor(font_ids, dtype=torch.long).unsqueeze(-1)
        
        # 图像嵌入
        if 'image_embedding' in item:
            image_embs = item['image_embedding'][:length]
            for _ in range(self.max_length - length):
                image_embs.append([0.0] * 512)
            sample['image_embedding'] = torch.tensor(image_embs, dtype=torch.float32)
        
        # 文本嵌入
        if 'text_embedding' in item:
            text_embs = item['text_embedding'][:length]
            for _ in range(self.max_length - length):
                text_embs.append([0.0] * 512)
            sample['text_embedding'] = torch.tensor(text_embs, dtype=torch.float32)
        
        # UUID (demo only)
        if 'uuid' in item:
            uuid_vals = item['uuid'][:length] + [''] * (self.max_length - length)
            # 简单哈希uuid到整数
            uuid_ids = [hash(u) % 10000 for u in uuid_vals]
            sample['uuid'] = torch.tensor(uuid_ids, dtype=torch.long).unsqueeze(-1)
        
        return sample
    
    def get_input_columns(self) -> Dict:
        """
        生成input_columns配置 - 严格对齐TF格式
        
        关键：input_dim不包含<MASK>和<NULL>，这些会在Encoder中+2
        """
        input_columns = {
            'id': {
                'demo_only': True,
                'shape': [1],
                'is_sequence': False,
                'primary_label': None,
            },
            'length': {
                'type': 'categorical',
                'input_dim': 50,
                'shape': [1],
                'is_sequence': False,
                'primary_label': None,
            },
            'canvas_width': {
                'type': 'categorical',
                'input_dim': len(self.width_to_idx) - 1 if self.width_to_idx else 40,
                'shape': [1],
                'is_sequence': False,
                'primary_label': None,
            },
            'canvas_height': {
                'type': 'categorical',
                'input_dim': len(self.height_to_idx) - 1 if self.height_to_idx else 45,
                'shape': [1],
                'is_sequence': False,
                'primary_label': None,
            },
            'type': {
                'type': 'categorical',
                'input_dim': 6,  # 固定为6（与TF一致）
                'shape': [1],
                'is_sequence': True,
                'primary_label': 0,
            },
            'left': {
                'type': 'categorical',
                'input_dim': 64,
                'shape': [1],
                'is_sequence': True,
                'primary_label': None,
            },
            'top': {
                'type': 'categorical',
                'input_dim': 64,
                'shape': [1],
                'is_sequence': True,
                'primary_label': None,
            },
            'width': {
                'type': 'categorical',
                'input_dim': 64,
                'shape': [1],
                'is_sequence': True,
                'primary_label': None,
            },
            'height': {
                'type': 'categorical',
                'input_dim': 64,
                'shape': [1],
                'is_sequence': True,
                'primary_label': None,
            },
            'opacity': {
                'type': 'categorical',
                'input_dim': 8,  # 固定为8（与TF一致）
                'shape': [1],
                'is_sequence': True,
                'primary_label': None,
            },
            'color': {
                'type': 'categorical',
                'input_dim': 16,  # 固定为16（与TF一致）
                'shape': [3],
                'is_sequence': True,
                'primary_label': None,
                'loss_condition': {
                    'key': 'type',
                    'mask': [False, False, True, False, True, False]
                }
            },
            'image_embedding': {
                'type': 'numerical',
                'shape': [512],
                'is_sequence': True,
                'primary_label': None,
                'loss_condition': {
                    'key': 'type',
                    'mask': [False, True, False, True, False, True]
                }
            },
            'text_embedding': {
                'type': 'numerical',
                'shape': [512],
                'is_sequence': True,
                'primary_label': None,
                'loss_condition': {
                    'key': 'type',
                    'mask': [False, False, True, False, False, False]
                }
            },
            'font_family': {
                'type': 'categorical',
                'input_dim': 35,  # 固定为35（与TF一致）
                'shape': [1],
                'is_sequence': True,
                'primary_label': None,
                'loss_condition': {
                    'key': 'type',
                    'mask': [False, False, True, False, False, False]
                }
            }
        }
        
        return input_columns


def collate_fn(batch: List[Dict]) -> Dict[str, torch.Tensor]:
    """批处理函数"""
    keys = batch[0].keys()
    collated = {}
    
    for key in keys:
        if key == 'id':
            collated[key] = [item[key] for item in batch]
        else:
            collated[key] = torch.stack([item[key] for item in batch])
    
    return collated


def create_dataloader(
    data_path: str,
    split: str = 'train',
    batch_size: int = 32,
    shuffle: bool = True,
    num_workers: int = 4,
    **dataset_kwargs
) -> DataLoader:
    """创建数据加载器"""
    dataset = DesignLayoutDataset(data_path, split=split, **dataset_kwargs)
    
    dataloader = DataLoader(
        dataset,
        batch_size=batch_size,
        shuffle=shuffle,
        num_workers=num_workers,
        collate_fn=collate_fn,
        pin_memory=True,
    )
    
    return dataloader


if __name__ == "__main__":
    data_path = "/home/dell/Project-HCL/BaseLine/flexdm_pt/data/crello_json"
    
    print("="*60)
    print("数据集测试")
    print("="*60)
    
    train_dataset = DesignLayoutDataset(
        data_path=data_path,
        split='train',
        max_length=20,
        min_font_freq=500,
    )
    
    train_loader = create_dataloader(
        data_path=data_path,
        split='train',
        batch_size=16,
        shuffle=True,
    )
    
    print(f"\n训练集批次数: {len(train_loader)}")
    
    batch = next(iter(train_loader))
    print("\n样本批次:")
    for key, value in batch.items():
        if isinstance(value, torch.Tensor):
            print(f"  {key:20s}: shape={list(value.shape)}, dtype={value.dtype}")
        else:
            print(f"  {key:20s}: {type(value)}")
    
    input_columns = train_dataset.get_input_columns()
    print(f"\n生成的input_columns:")
    for key, config in input_columns.items():
        print(f"  {key:20s}: {config}")
    
    import json
    output_file = "input_columns_fixed.json"
    with open(output_file, 'w') as f:
        json.dump(input_columns, f, indent=2)
    print(f"\n✓ 配置已保存到: {output_file}")



demo.ipynb
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Faiss not available, using brute force search\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA可用: False\n",
      "设备数量: 0\n",
      "✓ 导入完成（CPU模式）\n",
      "\n",
      "✓ 配置: device=cpu, batch_size=4\n",
      "\n",
      "================================================================================\n",
      "MFP PyTorch Demo - 纯CPU版本\n",
      "================================================================================\n",
      "\n",
      "1. 加载数据集\n",
      "加载数据: /home/dell/Project-HCL/BaseLine/flexdm_pt/data/crello_json/test.json\n",
      "✓ 加载了 2248 个样本\n",
      "\n",
      "构建查找表...\n",
      "  Type词汇表: 7 个类型\n",
      "  Canvas Width词汇表: 41 个尺寸\n",
      "    范围: 160 - 3000\n",
      "  Canvas Height词汇表: 46 个尺寸\n",
      "    范围: 90 - 2560\n",
      "  Font过滤: 290 -> 34 (频率>=500)\n",
      "  Font词汇表: 37 个token (含特殊token)\n",
      "✓ 数据集大小: 2248\n",
      "\n",
      "2. 加载映射\n",
      "✓ 字体映射: 37 个字体\n",
      "✓ Width映射: 42 个尺寸\n",
      "✓ Height映射: 47 个尺寸\n",
      "\n",
      "3. 创建DataLoader\n",
      "✓ 批次形状: torch.Size([4, 20, 1])\n",
      "\n",
      "4. 加载模型配置\n",
      "✓ 输入列数: 17\n",
      "\n",
      "5. 加载模型\n",
      "加载模型: /home/dell/Project-HCL/BaseLine/flexdm_pt/chechpoints/best_pytorch.pth\n",
      "\n",
      "============================================================\n",
      "初始化MFP模型\n",
      "============================================================\n",
      "初始化Encoder:\n",
      "  type: Embedding(8, 256)\n",
      "  left: Embedding(66, 256)\n",
      "  top: Embedding(66, 256)\n",
      "  width: Embedding(66, 256)\n",
      "  height: Embedding(66, 256)\n",
      "  opacity: Embedding(10, 256)\n",
      "  color: Embedding(18, 256)\n",
      "  image_embedding: Linear(512, 256)\n",
      "  text_embedding: Linear(512, 256)\n",
      "  font_family: Embedding(37, 256)\n",
      "总计: 10 个特征\n",
      "\n",
      "初始化Transformer:\n",
      "  blocks=4, embed_dim=256, num_heads=8\n",
      "\n",
      "初始化Decoder:\n",
      "  type: Linear(256, 6) -> (1, 6)\n",
      "  left: Linear(256, 64) -> (1, 64)\n",
      "  top: Linear(256, 64) -> (1, 64)\n",
      "  width: Linear(256, 64) -> (1, 64)\n",
      "  height: Linear(256, 64) -> (1, 64)\n",
      "  opacity: Linear(256, 8) -> (1, 8)\n",
      "  color: Linear(256, 48) -> (3, 16)\n",
      "  image_embedding: Linear(256, 512)\n",
      "  text_embedding: Linear(256, 512)\n",
      "  font_family: Linear(256, 35) -> (1, 35)\n",
      "总计: 10 个输出头\n",
      "\n",
      "总参数数: 2,824,289\n",
      "============================================================\n",
      "\n",
      "  警告: 缺失 97 个键\n",
      "  警告: 多余 84 个键\n",
      "✓ 模型加载完成（CPU）\n",
      "\n",
      "6. 构建检索数据库\n",
      "\n",
      "7. 创建SVG构建器\n",
      "✓ 构建器创建完成\n",
      "\n",
      "================================================================================\n",
      "8. 开始可视化 - 任务: pos\n",
      "================================================================================\n",
      "渲染 4 个样本...\n",
      "  - GT Layout\n",
      "  - GT Visual\n",
      "  - 模型推理\n",
      "  - Pred Layout\n",
      "  - Pred Visual\n",
      "✓ 渲染完成\n",
      "\n",
      "✓ 生成了 4 个样本的可视化结果\n",
      "列名: ['gt-layout', 'gt-visual', 'pred-layout', 'pred-visual']\n",
      "\n",
      "================================================================================\n",
      "可视化结果:\n",
      "================================================================================\n",
      "\n",
      "Sample 0:\n"
     ]
    },
    {
     "data": {
      "text/html": [

      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 1:\n"
     ]
    },
    {
     "data": {
      "text/html": [
  
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 2:\n"
     ]
    },
    {
     "data": {
      "text/html": [

      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Demo完成!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "MFP PyTorch Demo - 纯CPU版本\n",
    "完全禁用CUDA，强制使用CPU\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "\n",
    "os.chdir(\"/home/dell/Project-HCL/BaseLine/flexdm_pt/scripts\")\n",
    "# 🔧 在导入torch之前禁用CUDA\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = ''  # 对torch隐藏所有GPU\n",
    "\n",
    "import json\n",
    "import logging\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Optional\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# 确认CUDA已禁用\n",
    "print(f\"CUDA可用: {torch.cuda.is_available()}\")  # 应该是False\n",
    "print(f\"设备数量: {torch.cuda.device_count()}\")  # 应该是0\n",
    "\n",
    "from models_pytorch import MFP\n",
    "from dataset import DesignLayoutDataset\n",
    "from svg_builder_pytorch import SVGBuilder\n",
    "from retriever_pytorch import ImageRetriever, TextRetriever\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "print(\"✓ 导入完成（CPU模式）\\n\")\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 配置\n",
    "# ============================================================\n",
    "class DemoConfig:\n",
    "    def __init__(self):\n",
    "        self.ckpt_dir = \"/home/dell/Project-HCL/BaseLine/flexdm_pt/chechpoints\"\n",
    "        self.dataset_name = \"crello_json\"\n",
    "        self.db_root = \"/home/dell/Project-HCL/BaseLine/flexdm_pt/data/crello_json\"\n",
    "        self.batch_size = 4\n",
    "        self.device = 'cpu'  # 强制CPU\n",
    "        self.target_task = \"pos\"\n",
    "        \n",
    "        self.column_names = {\n",
    "            \"txt\": [\"gt-layout\", \"gt-visual\", \"input\", \"pred\"],\n",
    "            \"img\": [\"gt-layout\", \"gt-visual\", \"input\", \"pred\"],\n",
    "            \"attr\": [\"gt-layout\", \"gt-visual\", \"input\", \"pred\"],\n",
    "            \"pos\": [\"gt-layout\", \"gt-visual\", \"pred-layout\", \"pred-visual\"],\n",
    "            \"elem\": [\"gt-layout\", \"gt-visual\", \"input-layout\", \"input-visual\", \n",
    "                     \"pred-layout\", \"pred-visual\"],\n",
    "        }\n",
    "        \n",
    "        self.attribute_groups = {\n",
    "            \"type\": [\"type\"],\n",
    "            \"pos\": [\"left\", \"top\", \"width\", \"height\"],\n",
    "            \"attr\": [\"opacity\", \"color\", \"font_family\"],\n",
    "            \"img\": [\"image_embedding\"],\n",
    "            \"txt\": [\"text_embedding\"],\n",
    "        }\n",
    "\n",
    "config = DemoConfig()\n",
    "print(f\"✓ 配置: device={config.device}, batch_size={config.batch_size}\\n\")\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 类型映射\n",
    "# ============================================================\n",
    "DEFAULT_TYPE_MAPPING = {\n",
    "    0: '', 1: 'svgElement', 2: 'textElement', 3: 'imageElement',\n",
    "    4: 'coloredBackground', 5: 'maskElement', 6: 'humanElement',\n",
    "}\n",
    "\n",
    "def load_type_mapping_from_vocab(vocab_file: str):\n",
    "    return DEFAULT_TYPE_MAPPING\n",
    "\n",
    "def load_font_mapping_from_dataset(dataset):\n",
    "    return dataset.idx_to_font if hasattr(dataset, 'idx_to_font') else {}\n",
    "\n",
    "def load_canvas_mappings_from_dataset(dataset):\n",
    "    width_mapping = dataset.idx_to_width if hasattr(dataset, 'idx_to_width') else {}\n",
    "    height_mapping = dataset.idx_to_height if hasattr(dataset, 'idx_to_height') else {}\n",
    "    return width_mapping, height_mapping\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 数据处理工具\n",
    "# ============================================================\n",
    "def _extract_scalar(tensor):\n",
    "    if tensor.dim() == 0:\n",
    "        return tensor.item()\n",
    "    elif tensor.dim() == 1:\n",
    "        return tensor[0].item() if tensor.size(0) == 1 else tensor.argmax().item()\n",
    "    else:\n",
    "        return tensor.argmax(dim=-1)[0].item() if tensor.size(0) > 0 else 0\n",
    "\n",
    "\n",
    "def tensor_to_list(data, type_mapping, font_mapping=None, \n",
    "                   width_mapping=None, height_mapping=None, bins=64):\n",
    "    batch_size = data['length'].size(0)\n",
    "    items = []\n",
    "    scale = 1.0 / (bins - 1.0)\n",
    "    \n",
    "    for i in range(batch_size):\n",
    "        # Canvas尺寸\n",
    "        canvas_w = 800\n",
    "        canvas_h = 600\n",
    "        \n",
    "        if 'canvas_width' in data:\n",
    "            width_idx = data['canvas_width'][i].item()\n",
    "            if width_mapping and width_idx in width_mapping:\n",
    "                canvas_w = width_mapping[width_idx]\n",
    "        \n",
    "        if 'canvas_height' in data:\n",
    "            height_idx = data['canvas_height'][i].item()\n",
    "            if height_mapping and height_idx in height_mapping:\n",
    "                canvas_h = height_mapping[height_idx]\n",
    "        \n",
    "        item = {\n",
    "            'id': data['id'][i] if 'id' in data else f'sample_{i}',\n",
    "            'canvas_width': canvas_w,\n",
    "            'canvas_height': canvas_h,\n",
    "            'length': data['length'][i].item(),\n",
    "            'elements': []\n",
    "        }\n",
    "        \n",
    "        for j in range(item['length']):\n",
    "            element = {}\n",
    "            \n",
    "            for key, value in data.items():\n",
    "                if key in ['id', 'length', 'canvas_width', 'canvas_height']:\n",
    "                    continue\n",
    "                if not torch.is_tensor(value):\n",
    "                    continue\n",
    "                if value.dim() < 2 or value.size(1) <= j:\n",
    "                    continue\n",
    "                \n",
    "                elem_value = value[i, j]\n",
    "                \n",
    "                if key == 'type':\n",
    "                    element[key] = type_mapping.get(int(_extract_scalar(elem_value)), '')\n",
    "                elif key == 'font_family' and font_mapping:\n",
    "                    element[key] = font_mapping.get(int(_extract_scalar(elem_value)), 'Arial')\n",
    "                elif key in ['left', 'top', 'width', 'height']:\n",
    "                    discrete_idx = _extract_scalar(elem_value)\n",
    "                    element[key] = float(np.clip(scale * discrete_idx, 0.0, 1.0))\n",
    "                elif key == 'color':\n",
    "                    # 处理color：需要反离散化\n",
    "                    # 模型输出shape: (B, S, 3, 16) -> logits\n",
    "                    if elem_value.dim() == 2 and elem_value.size(0) == 3:\n",
    "                        # 取argmax得到离散索引 (3,) 每个值在0-15\n",
    "                        discrete_indices = elem_value.argmax(dim=-1).cpu().numpy()\n",
    "                        # 反离散化到0-255\n",
    "                        rgb = [int(idx * 255 / 15) for idx in discrete_indices]\n",
    "                        element[key] = rgb\n",
    "                    elif elem_value.dim() == 1 and elem_value.size(0) == 3:\n",
    "                        # 已经是离散索引\n",
    "                        rgb = [int(idx * 255 / 15) for idx in elem_value.cpu().numpy()]\n",
    "                        element[key] = rgb\n",
    "                    else:\n",
    "                        element[key] = [128, 128, 128]\n",
    "                elif key == 'opacity':\n",
    "                    # 反离散化：0-7 -> 0.0-1.0\n",
    "                    discrete_idx = _extract_scalar(elem_value)\n",
    "                    element[key] = float(discrete_idx / 7.0)\n",
    "                elif 'embedding' in key:\n",
    "                    element[key] = elem_value.cpu().numpy()\n",
    "                elif key == 'uuid':\n",
    "                    element[key] = str(_extract_scalar(elem_value))\n",
    "                else:\n",
    "                    element[key] = _extract_scalar(elem_value)\n",
    "            \n",
    "            item['elements'].append(element)\n",
    "        \n",
    "        items.append(item)\n",
    "    \n",
    "    return items\n",
    "\n",
    "\n",
    "def get_seq_mask(lengths, max_len=None):\n",
    "    if lengths.dim() == 2:\n",
    "        lengths = lengths.squeeze(-1)\n",
    "    if max_len is None:\n",
    "        max_len = lengths.max().item()\n",
    "    mask = torch.arange(max_len, device=lengths.device).unsqueeze(0) < lengths.unsqueeze(1)\n",
    "    return mask\n",
    "\n",
    "\n",
    "def get_initial_masks(input_columns, seq_mask):\n",
    "    masks = {}\n",
    "    batch_size, seq_len = seq_mask.shape\n",
    "    for key, column in input_columns.items():\n",
    "        if column.get('is_sequence', False):\n",
    "            masks[key] = torch.zeros_like(seq_mask, dtype=torch.bool)\n",
    "        else:\n",
    "            masks[key] = torch.ones(batch_size, dtype=torch.bool)\n",
    "    return masks\n",
    "\n",
    "\n",
    "def set_visual_default(item):\n",
    "    item = item.copy()\n",
    "    for elem in item.get('elements', []):\n",
    "        elem.setdefault('color', [128, 128, 128])\n",
    "        elem.setdefault('opacity', 1.0)\n",
    "        elem.setdefault('font_family', 'Arial')\n",
    "    return item\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 模型相关（纯CPU版本）\n",
    "# ============================================================\n",
    "def load_model(checkpoint_path, input_columns):\n",
    "    \"\"\"加载模型 - 强制CPU\"\"\"\n",
    "    print(f\"加载模型: {checkpoint_path}\")\n",
    "    \n",
    "    model = MFP(\n",
    "        input_columns=input_columns,\n",
    "        embed_dim=256,\n",
    "        num_blocks=4,\n",
    "        num_heads=8,\n",
    "        dropout=0.1,\n",
    "    )\n",
    "    \n",
    "    # 强制加载到CPU\n",
    "    checkpoint = torch.load(checkpoint_path, map_location='cpu')\n",
    "    state_dict = checkpoint.get('state_dict', checkpoint)\n",
    "    \n",
    "    missing, unexpected = model.load_state_dict(state_dict, strict=False)\n",
    "    \n",
    "    if missing:\n",
    "        print(f\"  警告: 缺失 {len(missing)} 个键\")\n",
    "    if unexpected:\n",
    "        print(f\"  警告: 多余 {len(unexpected)} 个键\")\n",
    "    \n",
    "    model.eval()\n",
    "    print(\"✓ 模型加载完成（CPU）\\n\")\n",
    "    return model\n",
    "\n",
    "\n",
    "def apply_task_masks(example, input_columns, target_task, attribute_groups):\n",
    "    seq_mask = get_seq_mask(example['length'], example['left'].size(1))\n",
    "    mfp_masks = get_initial_masks(input_columns, seq_mask)\n",
    "    \n",
    "    for key in mfp_masks.keys():\n",
    "        if not input_columns[key].get('is_sequence', False):\n",
    "            continue\n",
    "        \n",
    "        mask = mfp_masks[key].clone()\n",
    "        \n",
    "        if target_task == \"elem\":\n",
    "            mask[:, 0] = True\n",
    "        else:\n",
    "            if key != \"type\" and target_task in attribute_groups:\n",
    "                if key in attribute_groups[target_task]:\n",
    "                    mask = seq_mask.clone()\n",
    "        \n",
    "        mfp_masks[key] = mask\n",
    "    \n",
    "    return mfp_masks\n",
    "\n",
    "\n",
    "def model_inference_with_masks(model, inputs, masks):\n",
    "    \"\"\"模型推理 - 纯CPU\"\"\"\n",
    "    masked_inputs = {}\n",
    "    \n",
    "    for key, value in inputs.items():\n",
    "        if key in masks and torch.is_tensor(value):\n",
    "            mask = masks[key]\n",
    "            if mask.any():\n",
    "                masked_value = value.clone()\n",
    "                if value.dim() == 3:\n",
    "                    masked_value[mask] = 0\n",
    "                masked_inputs[key] = masked_value\n",
    "            else:\n",
    "                masked_inputs[key] = value\n",
    "        else:\n",
    "            masked_inputs[key] = value\n",
    "    \n",
    "    # 确保所有数据在CPU上\n",
    "    for key in masked_inputs:\n",
    "        if torch.is_tensor(masked_inputs[key]):\n",
    "            masked_inputs[key] = masked_inputs[key].cpu()\n",
    "    \n",
    "    outputs = model(masked_inputs)\n",
    "    return outputs\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 可视化主函数\n",
    "# ============================================================\n",
    "def visualize_reconstruction(model, example, builders, config, input_columns,\n",
    "                            type_mapping, font_mapping=None, width_mapping=None, \n",
    "                            height_mapping=None, bins=64):\n",
    "    svgs = []\n",
    "    target_task = config.target_task\n",
    "    \n",
    "    # 确保数据在CPU\n",
    "    for key in example:\n",
    "        if torch.is_tensor(example[key]):\n",
    "            example[key] = example[key].cpu()\n",
    "    \n",
    "    items = tensor_to_list(example, type_mapping, font_mapping, \n",
    "                          width_mapping, height_mapping, bins)\n",
    "    \n",
    "    print(f\"渲染 {len(items)} 个样本...\")\n",
    "    \n",
    "    # GT\n",
    "    print(\"  - GT Layout\")\n",
    "    svgs.append([builders[\"layout\"](item) for item in items])\n",
    "    print(\"  - GT Visual\")\n",
    "    svgs.append([builders[\"visual\"](item) for item in items])\n",
    "    \n",
    "    # 输入视图\n",
    "    if target_task == \"txt\":\n",
    "        print(\"  - Input (无文本)\")\n",
    "        svgs.append([builders[\"visual_wo_text\"](item) for item in items])\n",
    "    elif target_task == \"img\":\n",
    "        print(\"  - Input (无图像)\")\n",
    "        svgs.append([builders[\"visual_wo_image\"](item) for item in items])\n",
    "    elif target_task == \"attr\":\n",
    "        print(\"  - Input (默认属性)\")\n",
    "        svgs.append([builders[\"visual\"](set_visual_default(item)) for item in items])\n",
    "    \n",
    "    # 掩码\n",
    "    mfp_masks = apply_task_masks(example, input_columns, target_task, \n",
    "                                 config.attribute_groups)\n",
    "    \n",
    "    # 元素级任务\n",
    "    if target_task == \"elem\":\n",
    "        example_copy = {}\n",
    "        for key, value in example.items():\n",
    "            if isinstance(value, torch.Tensor) and value.dim() >= 2 and value.size(1) > 1:\n",
    "                indices = torch.where(~mfp_masks[key][0, :])[0]\n",
    "                example_copy[key] = torch.index_select(value, 1, indices)\n",
    "            else:\n",
    "                example_copy[key] = value\n",
    "        \n",
    "        example_copy['length'] = example['length'] - 1\n",
    "        items_copy = tensor_to_list(example_copy, type_mapping, font_mapping,\n",
    "                                    width_mapping, height_mapping, bins)\n",
    "        svgs.append([builders[\"layout\"](item) for item in items_copy])\n",
    "        svgs.append([builders[\"visual\"](item) for item in items_copy])\n",
    "    \n",
    "    # 预测\n",
    "    print(\"  - 模型推理\")\n",
    "    with torch.no_grad():\n",
    "        pred = model_inference_with_masks(model, example, mfp_masks)\n",
    "    \n",
    "    for key in example:\n",
    "        if key not in pred:\n",
    "            pred[key] = example[key]\n",
    "    \n",
    "    pred_items = tensor_to_list(pred, type_mapping, font_mapping,\n",
    "                                width_mapping, height_mapping, bins)\n",
    "    \n",
    "    if target_task in [\"pos\", \"elem\"]:\n",
    "        print(\"  - Pred Layout\")\n",
    "        svgs.append([builders[\"layout\"](item) for item in pred_items])\n",
    "    \n",
    "    print(\"  - Pred Visual\")\n",
    "    svgs.append([builders[\"visual\"](item) for item in pred_items])\n",
    "    \n",
    "    print(\"✓ 渲染完成\\n\")\n",
    "    return list(zip(*svgs))\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 主流程\n",
    "# ============================================================\n",
    "print(\"=\"*80)\n",
    "print(\"MFP PyTorch Demo - 纯CPU版本\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# 1. 加载数据集\n",
    "print(\"\\n1. 加载数据集\")\n",
    "dataset = DesignLayoutDataset(config.db_root, split='test', max_length=20)\n",
    "print(f\"✓ 数据集大小: {len(dataset)}\\n\")\n",
    "\n",
    "# 2. 加载映射\n",
    "print(\"2. 加载映射\")\n",
    "vocab_file = Path(config.db_root).parent / \"vocabulary.json\"\n",
    "type_mapping = load_type_mapping_from_vocab(str(vocab_file))\n",
    "font_mapping = load_font_mapping_from_dataset(dataset)\n",
    "width_mapping, height_mapping = load_canvas_mappings_from_dataset(dataset)\n",
    "\n",
    "if font_mapping:\n",
    "    print(f\"✓ 字体映射: {len(font_mapping)} 个字体\")\n",
    "if width_mapping:\n",
    "    print(f\"✓ Width映射: {len(width_mapping)} 个尺寸\")\n",
    "if height_mapping:\n",
    "    print(f\"✓ Height映射: {len(height_mapping)} 个尺寸\")\n",
    "print()\n",
    "\n",
    "# 3. 创建DataLoader\n",
    "print(\"3. 创建DataLoader\")\n",
    "from torch.utils.data import DataLoader\n",
    "from dataset import collate_fn\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=config.batch_size, \n",
    "                       shuffle=False, collate_fn=collate_fn)\n",
    "example = next(iter(dataloader))\n",
    "\n",
    "# 强制转CPU\n",
    "for key in example:\n",
    "    if torch.is_tensor(example[key]):\n",
    "        example[key] = example[key].cpu()\n",
    "\n",
    "print(f\"✓ 批次形状: {example['left'].shape}\\n\")\n",
    "\n",
    "# 4. 加载配置\n",
    "print(\"4. 加载模型配置\")\n",
    "input_columns_file = './input_columns_generated.json'\n",
    "with open(input_columns_file, 'r') as f:\n",
    "    input_columns = json.load(f)\n",
    "print(f\"✓ 输入列数: {len(input_columns)}\\n\")\n",
    "\n",
    "# 5. 加载模型\n",
    "print(\"5. 加载模型\")\n",
    "checkpoint_path = Path(config.ckpt_dir) / \"best_pytorch.pth\"\n",
    "model = load_model(str(checkpoint_path), input_columns)\n",
    "\n",
    "# 6. 构建检索数据库\n",
    "print(\"6. 构建检索数据库\")\n",
    "db_root = Path(config.db_root).parent / config.dataset_name\n",
    "image_db = ImageRetriever(db_root, image_path=db_root / \"images\")\n",
    "image_db.build(\"test\")\n",
    "text_db = TextRetriever(db_root, text_path=db_root / \"texts\")\n",
    "text_db.build(\"test\")\n",
    "print()\n",
    "\n",
    "# 7. 创建SVG构建器\n",
    "print(\"7. 创建SVG构建器\")\n",
    "builders = {\n",
    "    \"layout\": SVGBuilder(key='type', max_width=128, max_height=192, opacity=0.8),\n",
    "    \"visual\": SVGBuilder(key='color', max_width=128, max_height=192, \n",
    "                        image_db=image_db, text_db=text_db, \n",
    "                        render_text=True, opacity=1.0),\n",
    "    \"visual_wo_text\": SVGBuilder(key='color', max_width=128, max_height=192,\n",
    "                                 image_db=image_db, text_db=None, \n",
    "                                 render_text=False, opacity=1.0),\n",
    "    \"visual_wo_image\": SVGBuilder(key='color', max_width=128, max_height=192,\n",
    "                                  image_db=None, text_db=text_db, \n",
    "                                  render_text=True, opacity=1.0),\n",
    "}\n",
    "print(\"✓ 构建器创建完成\\n\")\n",
    "\n",
    "# 8. 运行可视化\n",
    "print(\"=\"*80)\n",
    "print(f\"8. 开始可视化 - 任务: {config.target_task}\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "svgs = visualize_reconstruction(model, example, builders, config, input_columns,\n",
    "                                type_mapping, font_mapping, width_mapping, \n",
    "                                height_mapping, bins=64)\n",
    "\n",
    "print(f\"✓ 生成了 {len(svgs)} 个样本的可视化结果\")\n",
    "print(f\"列名: {config.column_names[config.target_task]}\\n\")\n",
    "\n",
    "# 9. 显示结果\n",
    "print(\"=\"*80)\n",
    "print(\"可视化结果:\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for i, row in enumerate(svgs[:3]):\n",
    "    print(f\"\\nSample {i}:\")\n",
    "    display(HTML(\"<div style='margin: 10px 0;'>%s</div>\" % \" \".join(row)))\n",
    "\n",
    "print(\"\\n✓ Demo完成!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}



input_columns_generated.json
{
  "id": {
    "demo_only": true,
    "shape": [
      1
    ],
    "is_sequence": false,
    "primary_label": null
  },
  "length": {
    "type": "categorical",
    "input_dim": 50,
    "shape": [
      1
    ],
    "is_sequence": false,
    "primary_label": null
  },
  "group": {
    "type": "categorical",
    "input_dim": 7,
    "shape": [
      1
    ],
    "is_sequence": false,
    "primary_label": null
  },
  "format": {
    "type": "categorical",
    "input_dim": 68,
    "shape": [
      1
    ],
    "is_sequence": false,
    "primary_label": null
  },
  "canvas_width": {
    "type": "categorical",
    "input_dim": 41,
    "shape": [
      1
    ],
    "is_sequence": false,
    "primary_label": null
  },
  "canvas_height": {
    "type": "categorical",
    "input_dim": 46,
    "shape": [
      1
    ],
    "is_sequence": false,
    "primary_label": null
  },
  "category": {
    "type": "categorical",
    "input_dim": 24,
    "shape": [
      1
    ],
    "is_sequence": false,
    "primary_label": null
  },
  "type": {
    "type": "categorical",
    "input_dim": 6,
    "shape": [
      1
    ],
    "is_sequence": true,
    "primary_label": 0
  },
  "left": {
    "type": "categorical",
    "input_dim": 64,
    "shape": [
      1
    ],
    "is_sequence": true,
    "primary_label": null
  },
  "top": {
    "type": "categorical",
    "input_dim": 64,
    "shape": [
      1
    ],
    "is_sequence": true,
    "primary_label": null
  },
  "width": {
    "type": "categorical",
    "input_dim": 64,
    "shape": [
      1
    ],
    "is_sequence": true,
    "primary_label": null
  },
  "height": {
    "type": "categorical",
    "input_dim": 64,
    "shape": [
      1
    ],
    "is_sequence": true,
    "primary_label": null
  },
  "opacity": {
    "type": "categorical",
    "input_dim": 8,
    "shape": [
      1
    ],
    "is_sequence": true,
    "primary_label": null
  },
  "color": {
    "type": "categorical",
    "input_dim": 16,
    "shape": [
      3
    ],
    "is_sequence": true,
    "primary_label": null,
    "loss_condition": {
      "key": "type",
      "mask": [
        false,
        false,
        true,
        false,
        true,
        false
      ]
    }
  },
  "image_embedding": {
    "type": "numerical",
    "shape": [
      512
    ],
    "is_sequence": true,
    "primary_label": null,
    "loss_condition": {
      "key": "type",
      "mask": [
        false,
        true,
        false,
        true,
        false,
        true
      ]
    }
  },
  "text_embedding": {
    "type": "numerical",
    "shape": [
      512
    ],
    "is_sequence": true,
    "primary_label": null,
    "loss_condition": {
      "key": "type",
      "mask": [
        false,
        false,
        true,
        false,
        false,
        false
      ]
    }
  },
  "font_family": {
    "type": "categorical",
    "input_dim": 35,
    "shape": [
      1
    ],
    "is_sequence": true,
    "primary_label": null,
    "loss_condition": {
      "key": "type",
      "mask": [
        false,
        false,
        true,
        false,
        false,
        false
      ]
    }
  }
}

attributes:
{
  "total_attributes": 22,
  "attribute_names": [
    "canvas_height",
    "canvas_width",
    "category",
    "color",
    "font_family",
    "font_size",
    "format",
    "group",
    "height",
    "id",
    "image_embedding",
    "image_hash",
    "left",
    "length",
    "opacity",
    "ratio_w_to_h",
    "text_embedding",
    "text_hash",
    "top",
    "type",
    "uuid",
    "width"
  ],
  "attribute_details": {
    "id": {
      "type": "str",
      "is_list": false,
      "sample_value": "592d702795a7a863ddcda477"
    },
    "category": {
      "type": "str",
      "is_list": false,
      "sample_value": "foodDrinks"
    },
    "length": {
      "type": "int",
      "is_list": false,
      "sample_value": 8
    },
    "format": {
      "type": "str",
      "is_list": false,
      "sample_value": "Poster US"
    },
    "canvas_width": {
      "type": "int",
      "is_list": false,
      "sample_value": 1296
    },
    "group": {
      "type": "str",
      "is_list": false,
      "sample_value": "MM"
    },
    "canvas_height": {
      "type": "int",
      "is_list": false,
      "sample_value": 1728
    },
    "ratio_w_to_h": {
      "type": "list",
      "is_list": true,
      "sample_value": [
        1.000000238418579,
        286.5,
        286.5
      ]
    },
    "opacity": {
      "type": "list",
      "is_list": true,
      "sample_value": [
        1.0,
        1.0,
        1.0
      ]
    },
    "left": {
      "type": "list",
      "is_list": true,
      "sample_value": [
        0.0,
        0.5462962985038757,
        0.7623456716537476
      ]
    },
    "uuid": {
      "type": "list",
      "is_list": true,
      "sample_value": [
        "Hq0XyhgUcLHE1laD0UlUik1HiKoVQ80MI9vMloYF9CqW1dqFCcSdAKqm0vxHS70Z",
        "xuzFek51dUHnIufvr9voBLx2wBdDj6mrwRgqiF9EaKBULkwyx4Y8QiXF5u8QOsvV",
        "A1WaIDJEP1kCGkEeknusmufjMFYF208wG6Lhi1U6pIR5ZPaUXg5dRfUabn5NVpK5"
      ]
    },
    "font_family": {
      "type": "list",
      "is_list": true,
      "sample_value": [
        "DummyFont",
        "DummyFont",
        "DummyFont"
      ]
    },
    "top": {
      "type": "list",
      "is_list": true,
      "sample_value": [
        0.0,
        0.0,
        0.0
      ]
    },
    "height": {
      "type": "list",
      "is_list": true,
      "sample_value": [
        1.0027638673782349,
        0.22106482088565826,
        0.22106482088565826
      ]
    },
    "text_embedding": {
      "type": "list",
      "is_list": true,
      "sample_value": "List of list"
    },
    "type": {
      "type": "list",
      "is_list": true,
      "sample_value": [
        "imageElement",
        "svgElement",
        "svgElement"
      ]
    },
    "image_embedding": {
      "type": "list",
      "is_list": true,
      "sample_value": "List of list"
    },
    "width": {
      "type": "list",
      "is_list": true,
      "sample_value": [
        1.0027635097503662,
        0.0007716049440205097,
        0.0007716049440205097
      ]
    },
    "font_size": {
      "type": "list",
      "is_list": true,
      "sample_value": [
        0.0,
        0.0,
        0.0
      ]
    },
    "text_hash": {
      "type": "list",
      "is_list": true,
      "sample_value": [
        "bcf036b6f33e182d4705f4f5b1af13ac",
        "bcf036b6f33e182d4705f4f5b1af13ac",
        "bcf036b6f33e182d4705f4f5b1af13ac"
      ]
    },
    "image_hash": {
      "type": "list",
      "is_list": true,
      "sample_value": [
        "1bd8bf20acd5abb93b4d5cbf8608aefa",
        "cb57579ee4d8de697b268e885aeab457",
        "cb57579ee4d8de697b268e885aeab457"
      ]
    },
    "color": {
      "type": "list",
      "is_list": true,
      "sample_value": "List of list"
    }
  }
}

sample：

[
{
    "canvas_height": 315,
    "category": "sportExtreme",
    "group": "HC",
    "length": 10,
    "id": "5dbbfea2abc8ea6d1c14e913",
    "canvas_width": 851,
    "format": "Facebook cover",
    "text_embedding": [[0.03842202574014664, 0.08975290507078171,..... -0.33006733655929565]],
    "left": [0.09012925624847412, -0.04112808406352997, 0.18719154596328735, 0.3626321852207184, -0.035722680389881134, 0.43025699257850647, 0.1833137422800064, 0.43779969215393066, 0.3774383068084717, 0.3948228657245636],
    "type": ["imageElement", "svgElement", "maskElement", "svgElement", "svgElement", "textElement", "svgElement", "textElement", "svgElement", "textElement"],
    "image_hash": ["4a23e121a59596b15c4d1ed3b36155d9", "2b0b6181e1974721930669b35ec69321", "ddd1d7cfcea50b99502c8888a53fa959", "8c83f1c4dc3209bcfbc7e5e4f5d79de0", "7c8f7ebdc59e5810bd3510c702c79610", "cd37744a985b79ed29bb6269e45da27f", "96a9f601b9bcb93f6cd0221f0c9ca8ea", "cd37744a985b79ed29bb6269e45da27f", "dac9411cd16e5c87ce6bb479ef0f2a08", "cd37744a985b79ed29bb6269e45da27f"],
    "uuid": ["4HtvT5BFxipgUnVJk7AoyaqxWm1qIKwSr3rrxvLgeduEEZaW63OzUhl73jdhtXID"，... "iIQyFrcVFegqFIy5Fur8SvDG50si7uh3zZKXGKIbPNaHsOXIvsijBGMStFOc5uKJ"],
    "text_hash": ["bcf036b6f33e182d4705f4f5b1af13ac", "bcf036b6f33e182d4705f4f5b1af13ac", "bcf036b6f33e182d4705f4f5b1af13ac", "bcf036b6f33e182d4705f4f5b1af13ac", "bcf036b6f33e182d4705f4f5b1af13ac", "f589eafcf087c11af27e475bafb047fa", "bcf036b6f33e182d4705f4f5b1af13ac", "456a29cf32ae45eac03f55f9b955fa44", "bcf036b6f33e182d4705f4f5b1af13ac", "b0e5c16957d8b352f56083f7c38a5a52"],
    "color": [[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 1], [0, 0, 0], [231, 53, 60], [0, 0, 0], [255, 255, 255]],
    "height": [1.0, 0.3841269910335541, 0.5860317349433899, 0.09206349402666092, 1.476190447807312, 0.29523810744285583, 0.6000000238418579, 0.29206350445747375, 0.09206349402666092, 0.05079365149140358],
    "font_family": ["DummyFont", "DummyFont", "DummyFont", "DummyFont", "DummyFont", "Yanone Kaffeesatz", "DummyFont", "Yanone Kaffeesatz", "DummyFont", "Yanone Kaffeesatz"],
    "opacity": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0],
    "font_size": [0.0, 0.0, 0.0, 0.0, 0.0, 0.29523810744285583, 0.0, 0.29206350445747375, 0.0, 0.05079365149140358],
    "top": [0.0, 0.30793651938438416, 0.21269841492176056, 0.8355555534362793, -0.1653968244791031, 0.12008100748062134, 0.20000000298023224, 0.276451051235199, 0.8038095235824585, 0.8242316842079163],
    "width": [1.1121034622192383, 0.27262043952941895, 0.26133960485458374, 0.1057579293847084, 0.5593419671058655, 0.20152761042118073, 0.2220916599035263, 0.21680375933647156, 0.1374853104352951, 0.15041127800941467],
    "ratio_w_to_h": [0.899196982383728, 1.409017562866211, 2.242414712905884, 0.8705114722251892, 2.639155626296997, 1.4650007486343384, 2.701587200164795, 1.347132921218872, 0.6696242094039917, 0.33769840002059937],
    "image_embedding": [[-0.15892302989959717, 0.45916473865509033,...  -0.364339679479599, -0.293390691280365]]
  },


  上述为我项目的全部代码以及数据集样本（数据存放在train.json,test.json,val.json）
  我该如何训练这个模型，请帮我写出launch.json以及辅助训练代码,注意模型的输入参考input_columns_generated.json
  