===== models_pytorch.py =====
"""
PyTorch模型架构 - 完全修复版本
严格对齐TensorFlow原始实现
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
from typing import Dict, Optional
import math


# ==================== Transformer Components ====================

class MultiHeadSelfAttention(nn.Module):
    """多头自注意力机制"""
    
    def __init__(
        self,
        embed_dim: int,
        num_heads: int = 8,
        dropout: float = 0.1,
        lookahead: bool = True,
    ):
        super().__init__()
        assert embed_dim % num_heads == 0
        
        self.embed_dim = embed_dim
        self.num_heads = num_heads
        self.head_dim = embed_dim // num_heads
        self.lookahead = lookahead
        
        self.q_proj = nn.Linear(embed_dim, embed_dim)
        self.k_proj = nn.Linear(embed_dim, embed_dim)
        self.v_proj = nn.Linear(embed_dim, embed_dim)
        self.out_proj = nn.Linear(embed_dim, embed_dim)
        
        self.dropout = nn.Dropout(dropout)
        
    def forward(self, x: torch.Tensor, mask: Optional[torch.Tensor] = None):
        B, S, D = x.shape
        
        q = self.q_proj(x).view(B, S, self.num_heads, self.head_dim).transpose(1, 2)
        k = self.k_proj(x).view(B, S, self.num_heads, self.head_dim).transpose(1, 2)
        v = self.v_proj(x).view(B, S, self.num_heads, self.head_dim).transpose(1, 2)
        
        scores = torch.matmul(q, k.transpose(-2, -1)) / math.sqrt(self.head_dim)
        
        if mask is not None:
            mask = mask.unsqueeze(1).unsqueeze(2)
            scores = scores.masked_fill(~mask, float('-inf'))
            
            if not self.lookahead:
                causal_mask = torch.triu(
                    torch.ones(S, S, device=x.device, dtype=torch.bool),
                    diagonal=1
                )
                scores = scores.masked_fill(causal_mask, float('-inf'))
        
        attn_weights = F.softmax(scores, dim=-1)
        attn_weights = self.dropout(attn_weights)
        
        out = torch.matmul(attn_weights, v)
        out = out.transpose(1, 2).contiguous().view(B, S, D)
        out = self.out_proj(out)
        return out


class TransformerBlock(nn.Module):
    """Transformer块(DeepSVG风格)"""
    
    def __init__(
        self,
        embed_dim: int = 128,
        num_heads: int = 8,
        ff_dim: Optional[int] = None,
        dropout: float = 0.1,
        lookahead: bool = True,
    ):
        super().__init__()
        ff_dim = ff_dim or (2 * embed_dim)
        
        self.norm1 = nn.LayerNorm(embed_dim)
        self.attn = MultiHeadSelfAttention(
            embed_dim, num_heads, dropout, lookahead
        )
        self.dropout1 = nn.Dropout(dropout)
        
        self.norm2 = nn.LayerNorm(embed_dim)
        self.ffn = nn.Sequential(
            nn.Linear(embed_dim, ff_dim),
            nn.ReLU(),
            nn.Linear(ff_dim, embed_dim),
        )
        self.dropout2 = nn.Dropout(dropout)
    
    def forward(self, x: torch.Tensor, mask: Optional[torch.Tensor] = None):
        residual = x
        x = self.norm1(x)
        x = self.attn(x, mask)
        x = self.dropout1(x)
        x = residual + x
        
        residual = x
        x = self.norm2(x)
        x = self.ffn(x)
        x = self.dropout2(x)
        x = residual + x
        
        return x


class TransformerBlocks(nn.Module):
    """堆叠的Transformer块"""
    
    def __init__(
        self,
        num_blocks: int = 4,
        embed_dim: int = 128,
        num_heads: int = 8,
        dropout: float = 0.1,
        lookahead: bool = True,
    ):
        super().__init__()
        self.blocks = nn.ModuleList([
            TransformerBlock(embed_dim, num_heads, dropout=dropout, lookahead=lookahead)
            for _ in range(num_blocks)
        ])
    
    def forward(self, x: torch.Tensor, mask: Optional[torch.Tensor] = None):
        for block in self.blocks:
            x = block(x, mask)
        return x


# ==================== Encoder(修复版本)====================

class Encoder(nn.Module):
    """编码器 - 严格对齐TF版本"""
    
    def __init__(
        self,
        input_columns: Dict,
        embed_dim: int = 128,
        dropout: float = 0.1,
        max_length: int = 50,
    ):
        super().__init__()
        self.input_columns = input_columns
        self.embed_dim = embed_dim
        
        # 使用列表存储层
        self.emb_layers = nn.ModuleList()
        self.emb_keys = []
        
        print("初始化Encoder:")
        for key, column in input_columns.items():
            # 跳过非序列字段和demo_only字段
            if not column.get('is_sequence', False):
                continue
            if column.get('demo_only', False):
                continue
            
            self.emb_keys.append(key)
            
            if column['type'] == 'categorical':
                # +2 用于<MASK>和<UNUSED>标记
                vocab_size = column['input_dim'] + 2
                self.emb_layers.append(nn.Embedding(vocab_size, embed_dim))
                print(f"  {key}: Embedding({vocab_size}, {embed_dim})")
            elif column['type'] == 'numerical':
                # 数值类型需要额外的特殊标记嵌入
                input_size = column['shape'][-1] if 'shape' in column else 1
                self.emb_layers.append(nn.Linear(input_size, embed_dim))
                print(f"  {key}: Linear({input_size}, {embed_dim})")
        
        print(f"总计: {len(self.emb_keys)} 个特征")
        
        self.pos_embedding = nn.Embedding(max_length + 1, embed_dim)
        self.dropout = nn.Dropout(dropout)
    
    def forward(self, inputs: Dict[str, torch.Tensor]) -> tuple:
        """前向传播"""
        batch_size = inputs['length'].size(0)
        
        # 找到序列长度
        seq_len = None
        for key in self.emb_keys:
            if key in inputs:
                seq_len = inputs[key].size(1)
                break
        
        if seq_len is None:
            raise ValueError("未找到序列特征")
        
        # 编码每个特征
        seq_embs = []
        for idx, key in enumerate(self.emb_keys):
            if key not in inputs:
                continue
            
            x = inputs[key]
            layer = self.emb_layers[idx]
            
            # 根据层类型自动转换输入数据类型
            if isinstance(layer, nn.Embedding):
                if x.dtype != torch.long:
                    x = x.long()
            elif isinstance(layer, nn.Linear):
                if x.dtype != torch.float:
                    x = x.float()
            
            emb = layer(x)
            
            # 处理多维特征(如RGB) - sum across feature dimension
            if len(emb.shape) == 4:  # (B, S, 3, D)
                emb = emb.sum(dim=2)  # -> (B, S, D)
            
            seq_embs.append(emb)
        
        # 融合特征 - element-wise addition
        seq = torch.stack(seq_embs).sum(dim=0)
        
        # 位置编码
        positions = torch.arange(seq_len, device=seq.device).unsqueeze(0).expand(batch_size, -1)
        seq = seq + self.pos_embedding(positions)
        seq = self.dropout(seq)
        
        # 生成掩码
        lengths = inputs['length'].squeeze(-1)
        mask = torch.arange(seq_len, device=seq.device).unsqueeze(0) < lengths.unsqueeze(1)
        
        return seq, mask


# ==================== Decoder(修复版本)====================

class Decoder(nn.Module):
    """解码器 - 严格对齐TF版本"""
    
    def __init__(self, input_columns: Dict, embed_dim: int = 128):
        super().__init__()
        self.input_columns = input_columns
        
        # 使用列表存储层
        self.head_layers = nn.ModuleList()
        self.head_keys = []
        self.head_configs = []
        
        print("初始化Decoder:")
        for key, column in input_columns.items():
            # 跳过非序列字段和demo_only字段
            if not column.get('is_sequence', False):
                continue
            if column.get('demo_only', False):
                continue
            
            self.head_keys.append(key)
            self.head_configs.append(column)
            
            if column['type'] == 'categorical':
                shape = column.get('shape', [1])
                # 关键修复：输出维度 = shape[-1] * input_dim
                output_dim = shape[-1] * column['input_dim']
                self.head_layers.append(nn.Linear(embed_dim, output_dim))
                print(f"  {key}: Linear({embed_dim}, {output_dim}) -> ({shape[-1]}, {column['input_dim']})")
            else:
                shape = column.get('shape', [1])
                output_dim = shape[-1]
                self.head_layers.append(nn.Linear(embed_dim, output_dim))
                print(f"  {key}: Linear({embed_dim}, {output_dim})")
        
        print(f"总计: {len(self.head_keys)} 个输出头")
    
    def forward(self, x: torch.Tensor) -> Dict[str, torch.Tensor]:
        outputs = {}
        batch_size, seq_len, _ = x.shape
        
        for idx, key in enumerate(self.head_keys):
            column = self.head_configs[idx]
            pred = self.head_layers[idx](x)
            
            if column['type'] == 'categorical':
                shape = column.get('shape', [1])
                num_features = shape[-1]
                vocab_size = column['input_dim']
                # Reshape: (B, S, num_features*vocab_size) -> (B, S, num_features, vocab_size)
                pred = pred.view(batch_size, seq_len, num_features, vocab_size)
            
            outputs[key] = pred
        
        return outputs


# ==================== MFP Model ====================

class MFP(nn.Module):
    """Masked Field Prediction模型"""
    
    def __init__(
        self,
        input_columns: Dict,
        embed_dim: int = 128,
        num_blocks: int = 4,
        num_heads: int = 8,
        dropout: float = 0.1,
        max_length: int = 50,
    ):
        super().__init__()
        self.input_columns = input_columns
        
        print("\n" + "="*60)
        print("初始化MFP模型")
        print("="*60)
        
        self.encoder = Encoder(
            input_columns, embed_dim, dropout, max_length
        )
        
        print("\n初始化Transformer:")
        print(f"  blocks={num_blocks}, embed_dim={embed_dim}, num_heads={num_heads}")
        self.transformer = TransformerBlocks(
            num_blocks, embed_dim, num_heads, dropout, lookahead=True
        )
        
        print("")
        self.decoder = Decoder(input_columns, embed_dim)
        
        total_params = sum(p.numel() for p in self.parameters())
        print(f"\n总参数数: {total_params:,}")
        print("="*60 + "\n")
    
    def forward(self, inputs: Dict[str, torch.Tensor]) -> Dict[str, torch.Tensor]:
        x, mask = self.encoder(inputs) #torch.Size([20, 20, 256])
        x = self.transformer(x, mask) #torch.Size([20, 20, 256])
        outputs = self.decoder(x)
        return outputs
    
    def load_converted_weights(self, checkpoint_path: str):
        """加载转换后的权重"""
        checkpoint = torch.load(checkpoint_path, map_location='cpu')
        state_dict = checkpoint['state_dict']
        
        missing_keys, unexpected_keys = self.load_state_dict(state_dict, strict=False)
        
        if missing_keys:
            print(f"警告: 缺失 {len(missing_keys)} 个键")
            for key in missing_keys[:5]:
                print(f"  - {key}")
        if unexpected_keys:
            print(f"警告: 多余 {len(unexpected_keys)} 个键")
            for key in unexpected_keys[:5]:
                print(f"  - {key}")
        
        print("✓ 权重加载完成")


# ==================== 测试代码 ====================

if __name__ == "__main__":
    print("测试MFP模型(修复版本)\n")
    
    # 使用原始TF格式的input_columns
    input_columns = {
        'type': {
            'is_sequence': True, 
            'type': 'categorical', 
            'input_dim': 6, 
            'shape': [1]
        },
        'left': {
            'is_sequence': True, 
            'type': 'categorical', 
            'input_dim': 64, 
            'shape': [1]
        },
        'top': {
            'is_sequence': True, 
            'type': 'categorical', 
            'input_dim': 64, 
            'shape': [1]
        },
        'width': {
            'is_sequence': True, 
            'type': 'categorical', 
            'input_dim': 64, 
            'shape': [1]
        },
        'height': {
            'is_sequence': True, 
            'type': 'categorical', 
            'input_dim': 64, 
            'shape': [1]
        },
        'opacity': {
            'is_sequence': True, 
            'type': 'categorical', 
            'input_dim': 8, 
            'shape': [1]
        },
        'color': {
            'is_sequence': True, 
            'type': 'categorical', 
            'input_dim': 16, 
            'shape': [3]
        },
        'image_embedding': {
            'is_sequence': True, 
            'type': 'numerical', 
            'shape': [512]
        },
        'text_embedding': {
            'is_sequence': True, 
            'type': 'numerical', 
            'shape': [512]
        },
        'font_family': {
            'is_sequence': True, 
            'type': 'categorical', 
            'input_dim': 35, 
            'shape': [1]
        },
        'uuid': {
            'is_sequence': True, 
            'demo_only': True,
            'type': 'categorical', 
            'input_dim': 1215, 
            'shape': [1]
        },
    }
    
    model = MFP(input_columns, embed_dim=256, num_blocks=4)
    
    # 测试前向传播
    batch_size = 2
    seq_len = 10
    
    test_input = {
        'length': torch.tensor([[5], [7]], dtype=torch.long),
        'type': torch.randint(0, 6, (batch_size, seq_len, 1)),
        'left': torch.randint(0, 64, (batch_size, seq_len, 1)),
        'top': torch.randint(0, 64, (batch_size, seq_len, 1)),
        'width': torch.randint(0, 64, (batch_size, seq_len, 1)),
        'height': torch.randint(0, 64, (batch_size, seq_len, 1)),
        'opacity': torch.randint(0, 8, (batch_size, seq_len, 1)),
        'color': torch.randint(0, 16, (batch_size, seq_len, 3)),
        'image_embedding': torch.randn(batch_size, seq_len, 512),
        'text_embedding': torch.randn(batch_size, seq_len, 512),
        'font_family': torch.randint(0, 35, (batch_size, seq_len, 1)),
    }
    
    print("测试前向传播...")
    with torch.no_grad():
        outputs = model(test_input)
    
    print("\n✓ 前向传播成功!")
    print("\n输出形状:")
    for key, value in outputs.items():
        print(f"  {key:20s}: {list(value.shape)}")
    
    print("\n预期形状对比:")
    print("  type:  [2, 10, 1, 6]")
    print("  color: [2, 10, 3, 16]")
    print("  opacity: [2, 10, 1, 8]")

===== train_pytorch_improved.py =====
"""
完整的MFP训练代码 - 严格对齐TensorFlow版本
包含正确的Masking机制
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torch.utils.data import DataLoader
from torch.utils.tensorboard import SummaryWriter
from pathlib import Path
import argparse
import json
from tqdm import tqdm
import time
from typing import Dict
import numpy as np

from dataset import create_dataloader
from models_pytorch import MFP
from masking_pytorch import (
    get_task_names,
    preprocess_for_train,
    get_seq_mask,
)


class MFPTrainer:
    """MFP模型训练器（包含Masking）"""
    
    def __init__(
        self,
        model: nn.Module,
        train_loader: DataLoader,
        val_loader: DataLoader,
        config: Dict,
        device: str = 'cuda',
        save_dir: str = './checkpoints',
        log_dir: str = './logs',
        resume_path: str = None,
    ):
        self.model = model.to(device)
        self.train_loader = train_loader
        self.val_loader = val_loader
        self.config = config
        self.device = device
        self.input_columns = model.input_columns
        
        # 训练配置
        train_cfg = config.get('training', {})
        self.num_epochs = train_cfg.get('num_epochs', 100)
        self.gradient_clip = train_cfg.get('gradient_clip', 1.0)
        self.accumulation_steps = train_cfg.get('accumulation_steps', 1)
        
        # 任务采样
        self.task_names = get_task_names(self.input_columns)
        self.num_tasks = len(self.task_names)
        print(f"\n任务列表: {self.task_names}")
        
        # 损失权重
        self.loss_weights = config.get('loss_weights', {})
        
        # 优化器
        self.optimizer = optim.AdamW(
            model.parameters(),
            lr=train_cfg.get('learning_rate', 1e-4),
            betas=(0.9, 0.999),
            weight_decay=train_cfg.get('weight_decay', 0.01),
        )
        
        # 学习率调度器
        self.scheduler = optim.lr_scheduler.ReduceLROnPlateau(
            self.optimizer,
            mode='min',
            factor=0.5,
            patience=5,
            min_lr=1e-6,
            verbose=True,
        )
        
        # 目录设置
        self.save_dir = Path(save_dir)
        self.save_dir.mkdir(parents=True, exist_ok=True)
        
        # TensorBoard
        self.writer = SummaryWriter(log_dir)
        
        # 训练状态
        self.start_epoch = 0
        self.best_val_loss = float('inf')
        self.global_step = 0
        
        # 恢复训练
        if resume_path and Path(resume_path).exists():
            self.load_checkpoint(resume_path)
        
        print(f"✓ 训练器初始化完成 (设备: {device})")
    
    def compute_loss(
        self,
        predictions: Dict[str, torch.Tensor],
        targets: Dict[str, torch.Tensor],
        masks: Dict[str, torch.Tensor],
        seq_mask: torch.Tensor,
    ) -> Dict[str, torch.Tensor]:
        """
        计算多任务损失（只在masked位置计算）
        
        Args:
            predictions: 模型预测
            targets: 真实标签
            masks: mask字典（True表示需要预测的位置）
            seq_mask: (B, S) 有效位置mask
        
        Returns:
            损失字典
        """
        losses = {}
        total_loss = 0.0
        
        for key in predictions.keys():
            if key not in targets or key not in masks:
                continue
            
            pred = predictions[key]
            target = targets[key]
            mfp_mask = masks[key]
            
            column = self.input_columns.get(key, {})
            weight = self.loss_weights.get(key, 1.0)
            
            if column.get('type') == 'categorical':
                # ⭐ 关键修复：过滤掉特殊token
                input_dim = column['input_dim']
                
                if pred.dim() == 4:  # (B, S, num_feat, C)
                    B, S, num_feat, C = pred.shape
                    
                    # 展平
                    pred_flat = pred.reshape(B * S * num_feat, C)
                    target_flat = target.reshape(B * S * num_feat).long()
                    
                    # ⭐ 将超出范围的目标值clip到有效范围
                    # target_flat = torch.clamp(target_flat, 0, input_dim - 1)
                    
                    # 计算损失
                    loss = F.cross_entropy(pred_flat, target_flat, reduction='none')
                    loss = loss.reshape(B, S, num_feat)
                    
                    # 应用mask
                    mask_expanded = mfp_mask.unsqueeze(-1) & seq_mask.unsqueeze(-1)
                    loss = (loss * mask_expanded.float()).sum() / (mask_expanded.sum() + 1e-8)
                
                elif pred.dim() == 3:  # (B, S, C)
                    B, S, C = pred.shape
                    
                    # 展平
                    pred_flat = pred.reshape(B * S, C)
                    target_flat = target.reshape(B * S).long()
                    
                    # ⭐ 将超出范围的目标值clip到有效范围
                    # target_flat = torch.clamp(target_flat, 0, input_dim - 1)
                    
                    # 计算损失
                    loss = F.cross_entropy(pred_flat, target_flat, reduction='none')
                    loss = loss.reshape(B, S)
                    
                    # 应用mask
                    mask_combined = mfp_mask & seq_mask
                    loss = (loss * mask_combined.float()).sum() / (mask_combined.sum() + 1e-8)
                else:
                    continue
            
            elif column.get('type') == 'numerical':
                # 回归损失
                loss = F.mse_loss(pred, target.float(), reduction='none')
                
                # 应用mask
                mask_expanded = mfp_mask.unsqueeze(-1) & seq_mask.unsqueeze(-1)
                mask_expanded = mask_expanded.expand_as(loss)
                loss = (loss * mask_expanded.float()).sum() / (mask_expanded.sum() + 1e-8)
            else:
                continue
            
            # 应用权重
            weighted_loss = loss * weight
            losses[f'{key}_loss'] = loss.detach()
            total_loss += weighted_loss
        
        losses['total_loss'] = total_loss
        return losses

    
    def train_epoch(self, epoch: int):
        """训练一个epoch（包含Masking）"""
        self.model.train()
        epoch_losses = {}
        
        pbar = tqdm(self.train_loader, desc=f'Epoch {epoch}/{self.num_epochs}')
        self.optimizer.zero_grad()
        
        for batch_idx, batch in enumerate(pbar):
            # 移动到设备
            inputs = {k: v.to(self.device) if torch.is_tensor(v) else v 
                     for k, v in batch.items()}
            
            # 随机选择任务
            batch_size = inputs['length'].size(0)
            task_ids = torch.randint(0, self.num_tasks, (batch_size,))
            
            # 预处理（应用Masking）
            targets, modified_inputs, masks = preprocess_for_train(
                inputs,
                self.input_columns,
                task_ids[0].item(),  # 简化：整个batch使用同一任务
                is_autoreg=False,
            )
            
            # 前向传播
            outputs = self.model(modified_inputs)
            
            # 生成序列mask
            seq_mask = get_seq_mask(inputs['length'], max_len=inputs['left'].size(1))
            
            # 计算损失
            losses = self.compute_loss(outputs, targets, masks, seq_mask)
            loss = losses['total_loss'] / self.accumulation_steps
            
            # 反向传播
            loss.backward()
            
            # 梯度累积
            if (batch_idx + 1) % self.accumulation_steps == 0:
                torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.gradient_clip)
                self.optimizer.step()
                self.optimizer.zero_grad()
            
            # 记录损失
            for key, value in losses.items():
                if key not in epoch_losses:
                    epoch_losses[key] = []
                epoch_losses[key].append(value.item() if torch.is_tensor(value) else value)
            
            # 更新进度条
            pbar.set_postfix({
                'loss': f"{losses['total_loss'].item():.4f}",
                'lr': f"{self.optimizer.param_groups[0]['lr']:.6f}"
            })
            
            # TensorBoard记录
            if self.global_step % 100 == 0:
                for key, value in losses.items():
                    self.writer.add_scalar(
                        f'train/{key}', 
                        value.item() if torch.is_tensor(value) else value, 
                        self.global_step
                    )
                self.writer.add_scalar('train/lr', self.optimizer.param_groups[0]['lr'], self.global_step)
            
            self.global_step += 1
        
        # 计算平均损失
        avg_losses = {k: sum(v) / len(v) for k, v in epoch_losses.items()}
        return avg_losses
    
    @torch.no_grad()
    def validate(self, epoch: int):
        """验证"""
        self.model.eval()
        epoch_losses = {}
        
        for batch in tqdm(self.val_loader, desc='Validation'):
            # 移动到设备
            inputs = {k: v.to(self.device) if torch.is_tensor(v) else v 
                     for k, v in batch.items()}
            
            # 随机选择任务
            batch_size = inputs['length'].size(0)
            task_ids = torch.randint(0, self.num_tasks, (batch_size,))
            
            # 预处理
            targets, modified_inputs, masks = preprocess_for_train(
                inputs,
                self.input_columns,
                task_ids[0].item(),
                is_autoreg=False,
            )
            
            # 前向传播
            outputs = self.model(modified_inputs)
            
            # 生成序列mask
            seq_mask = get_seq_mask(inputs['length'], max_len=inputs['left'].size(1))
            
            # 计算损失
            losses = self.compute_loss(outputs, targets, masks, seq_mask)
            
            # 记录损失
            for key, value in losses.items():
                if key not in epoch_losses:
                    epoch_losses[key] = []
                epoch_losses[key].append(value.item() if torch.is_tensor(value) else value)
        
        # 计算平均损失
        avg_losses = {k: sum(v) / len(v) for k, v in epoch_losses.items()}
        
        # TensorBoard记录
        for key, value in avg_losses.items():
            self.writer.add_scalar(f'val/{key}', value, epoch)
        
        return avg_losses
    
    def save_checkpoint(self, epoch: int, val_loss: float, is_best: bool = False):
        """保存checkpoint"""
        checkpoint = {
            'epoch': epoch,
            'global_step': self.global_step,
            'model_state_dict': self.model.state_dict(),
            'optimizer_state_dict': self.optimizer.state_dict(),
            'scheduler_state_dict': self.scheduler.state_dict(),
            'best_val_loss': self.best_val_loss,
            'val_loss': val_loss,
            'config': self.config,
        }
        
        # 保存最新模型
        torch.save(checkpoint, self.save_dir / 'latest.pth')
        
        # 保存最佳模型
        if is_best:
            torch.save(checkpoint, self.save_dir / 'best.pth')
            print(f"✓ 保存最佳模型 (epoch {epoch}, val_loss: {val_loss:.4f})")
    
    def load_checkpoint(self, checkpoint_path: str):
        """加载checkpoint"""
        print(f"加载checkpoint: {checkpoint_path}")
        checkpoint = torch.load(checkpoint_path, map_location=self.device)
        
        self.model.load_state_dict(checkpoint['model_state_dict'])
        self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
        self.scheduler.load_state_dict(checkpoint['scheduler_state_dict'])
        
        self.start_epoch = checkpoint.get('epoch', 0) + 1
        self.global_step = checkpoint.get('global_step', 0)
        self.best_val_loss = checkpoint.get('best_val_loss', float('inf'))
        
        print(f"✓ 恢复训练从 epoch {self.start_epoch}")
    
    def train(self):
        """完整训练流程"""
        print("\n" + "="*60)
        print("开始训练（包含Masking机制）")
        print("="*60)
        
        for epoch in range(self.start_epoch, self.num_epochs):
            start_time = time.time()
            
            # 训练
            train_losses = self.train_epoch(epoch)
            
            # 验证
            if epoch % 1 == 0:
                val_losses = self.validate(epoch)
            else:
                val_losses = {'total_loss': float('inf')}
            
            # 学习率调度
            self.scheduler.step(val_losses['total_loss'])
            
            # 打印信息
            epoch_time = time.time() - start_time
            print(f"\n{'='*60}")
            print(f"Epoch {epoch}/{self.num_epochs - 1} ({epoch_time:.1f}s)")
            print(f"{'='*60}")
            print(f"Train Loss: {train_losses['total_loss']:.4f}")
            if 'total_loss' in val_losses and val_losses['total_loss'] != float('inf'):
                print(f"Val Loss:   {val_losses['total_loss']:.4f}")
            print(f"LR:         {self.optimizer.param_groups[0]['lr']:.6f}")
            print(f"Best Val:   {self.best_val_loss:.4f}")
            
            # 保存checkpoint
            is_best = val_losses['total_loss'] < self.best_val_loss
            if is_best:
                self.best_val_loss = val_losses['total_loss']
            
            self.save_checkpoint(epoch, val_losses['total_loss'], is_best)
        
        print("\n" + "="*60)
        print("训练完成!")
        print(f"最佳验证损失: {self.best_val_loss:.4f}")
        print("="*60)
        self.writer.close()


def main():
    parser = argparse.ArgumentParser(description='Train MFP Model with Masking')
    
    parser.add_argument('--data_dir', type=str, required=True)
    parser.add_argument('--config', type=str, default='config/train_config.json')
    parser.add_argument('--batch_size', type=int, default=None)
    parser.add_argument('--num_epochs', type=int, default=None)
    parser.add_argument('--learning_rate', type=float, default=None)
    parser.add_argument('--device', type=str, default='cuda')
    parser.add_argument('--save_dir', type=str, default='./checkpoints')
    parser.add_argument('--log_dir', type=str, default='./logs')
    parser.add_argument('--resume', type=str, default=None)
    
    args = parser.parse_args()
    
    # 加载配置
    with open(args.config, 'r') as f:
        config = json.load(f)
    
    # 命令行参数覆盖
    if args.batch_size is not None:
        config['training']['batch_size'] = args.batch_size
    if args.num_epochs is not None:
        config['training']['num_epochs'] = args.num_epochs
    if args.learning_rate is not None:
        config['training']['learning_rate'] = args.learning_rate
    
    # 创建数据加载器
    print("\n加载数据...")
    train_loader = create_dataloader(
        args.data_dir, 'train',
        batch_size=config['training']['batch_size'],
        shuffle=True,
        num_workers=config['data'].get('num_workers', 4),
        max_length=config['data'].get('max_length', 20),
    )
    
    val_loader = create_dataloader(
        args.data_dir, 'val',
        batch_size=config['training']['batch_size'],
        shuffle=False,
        num_workers=config['data'].get('num_workers', 4),
        max_length=config['data'].get('max_length', 20),
    )
    
    # 获取input_columns
    dataset = train_loader.dataset
    input_columns = dataset.get_input_columns()
    
    # 创建模型
    print("\n创建模型...")
    model = MFP(
        input_columns=input_columns,
        embed_dim=config['model']['embed_dim'],
        num_blocks=config['model']['num_blocks'],
        num_heads=config['model']['num_heads'],
        dropout=config['model']['dropout'],
        max_length=config['model']['max_length'],
    )
    
    # 创建训练器
    trainer = MFPTrainer(
        model=model,
        train_loader=train_loader,
        val_loader=val_loader,
        config=config,
        device=args.device,
        save_dir=args.save_dir,
        log_dir=args.log_dir,
        resume_path=args.resume,
    )
    
    # 开始训练
    trainer.train()


if __name__ == "__main__":
    main()

===== masking_pytorch.py =====
"""
PyTorch版本的Masking机制
严格对齐TensorFlow原始实现
"""

import torch
import torch.nn.functional as F
from typing import Dict, List, Tuple
import numpy as np

# 特殊值常量（与TF版本一致）
MASK_VALUE = 10.0
NULL_VALUE = 0.0

# Masking概率（与TF版本一致）
MASK_PROB = 0.15
REPLACE_PROB = 0.1
UNCHANGE_PROB = 0.1
CHANGE_PROB = 1.0 - UNCHANGE_PROB
THRESH = REPLACE_PROB / CHANGE_PROB


def get_task_names(input_columns: Dict) -> List[str]:
    """获取任务名称列表"""
    task_names = ["random", "elem"]
    
    # 从input_columns推断属性组
    attribute_groups = get_attribute_groups(input_columns.keys())
    task_names += list(attribute_groups.keys())
    
    return task_names


def get_attribute_groups(keys: List[str]) -> Dict[str, List[str]]:
    """获取属性组定义"""
    # Crello数据集的属性组
    if 'font_family' in keys or 'opacity' in keys:
        return {
            'type': ['type'],
            'pos': ['left', 'top', 'width', 'height'],
            'attr': ['opacity', 'color', 'font_family'],
            'img': ['image_embedding'],
            'txt': ['text_embedding'],
        }
    # Rico数据集的属性组
    else:
        return {
            'type': ['type'],
            'pos': ['left', 'top', 'width', 'height'],
            'attr': ['icon', 'clickable', 'text_button'],
        }


def get_seq_mask(length: torch.Tensor, max_len: int = None) -> torch.Tensor:
    """
    从长度生成序列mask
    
    Args:
        length: (B, 1) 或 (B,) - 序列长度（zero-based）
        max_len: 最大长度
    
    Returns:
        mask: (B, S) - True表示有效位置
    """
    if length.dim() == 2:
        length = length.squeeze(-1)
    
    # 转换为one-based
    # length = length + 1
    
    if max_len is None:
        max_len = length.max().item()
    
    # 生成mask
    batch_size = length.size(0)
    mask = torch.arange(max_len, device=length.device).unsqueeze(0).expand(batch_size, -1)
    mask = mask < length.unsqueeze(1)
    
    return mask


def apply_token(
    input_tensor: torch.Tensor,
    column: Dict,
    mask: torch.Tensor,
    token_type: str
) -> torch.Tensor:
    """
    应用特殊token（MASK/UNUSED/RANDOM）
    
    Args:
        input_tensor: 输入张量
        column: 列配置
        mask: (B, S) mask，True表示需要替换的位置
        token_type: 'masked', 'unused', 或 'random'
    
    Returns:
        处理后的张量
    """
    assert token_type in ['masked', 'unused', 'random']
    
    # 扩展mask维度以匹配input
    while mask.dim() < input_tensor.dim():
        mask = mask.unsqueeze(-1)
    
    if column['type'] == 'categorical':
        # 分类特征
        if token_type == 'masked':
            # MASK token = input_dim
            value = torch.full_like(input_tensor, column['input_dim'])
        elif token_type == 'unused':
            # UNUSED token = input_dim + 1
            value = torch.full_like(input_tensor, column['input_dim'] + 1)
        else:  # random
            value = torch.randint_like(input_tensor, 0, column['input_dim'])
        
        output = torch.where(mask, value, input_tensor)
    
    else:  # numerical
        # 数值特征
        if token_type == 'masked':
            value = torch.full_like(input_tensor, MASK_VALUE)
        elif token_type == 'unused':
            value = torch.full_like(input_tensor, NULL_VALUE)
        else:  # random
            value = torch.randn_like(input_tensor) * 0.1
        
        output = torch.where(mask, value, input_tensor)
    
    return output


def get_initial_masks(input_columns: Dict, seq_mask: torch.Tensor) -> Dict[str, torch.Tensor]:
    """
    初始化mask字典（全False）
    
    Args:
        input_columns: 列配置
        seq_mask: (B, S) 序列mask
    
    Returns:
        masks: 每个特征的mask（全False）
    """
    masks = {}
    batch_size = seq_mask.size(0)
    
    for key, column in input_columns.items():
        if not column.get('is_sequence', False):
            # 非序列特征 - 全True（表示需要预测）
            masks[key] = torch.ones(batch_size, dtype=torch.bool, device=seq_mask.device)
        else:
            # 序列特征 - 全False
            masks[key] = torch.zeros_like(seq_mask, dtype=torch.bool)
    
    return masks


def filter_padding(
    inputs: Dict[str, torch.Tensor],
    input_columns: Dict,
    mask: torch.Tensor
) -> Dict[str, torch.Tensor]:
    """
    将padding位置设置为NULL
    
    Args:
        inputs: 输入字典
        input_columns: 列配置
        mask: (B, S) 有效位置mask
    
    Returns:
        处理后的输入
    """
    modified_inputs = {}
    unused_mask = ~mask  # padding位置
    
    for key, column in input_columns.items():
        # ⭐ 跳过demo_only字段（如uuid）
        if column.get('demo_only', False):
            modified_inputs[key] = inputs.get(key, None)
            continue
        
        # ⭐ 跳过不存在的字段
        if key not in inputs:
            continue
        
        input_val = inputs[key]
        
        # ⭐ 跳过非tensor类型（安全检查）
        if not torch.is_tensor(input_val):
            modified_inputs[key] = input_val
            continue
        
        if column.get('is_sequence', False):
            # 检查loss_condition
            if 'loss_condition' in column:
                cond = column['loss_condition']
                # 某些类型的元素不需要这个特征
                cond_mask = torch.zeros_like(mask, dtype=torch.bool)
                
                # 获取条件字段的值
                if cond['key'] in inputs and torch.is_tensor(inputs[cond['key']]):
                    type_values = inputs[cond['key']]  # (B, S, 1)
                    if type_values.dim() == 3:
                        type_values = type_values.squeeze(-1)  # (B, S)
                    
                    # 根据loss_condition的mask设置
                    if 'mask' in cond:
                        # cond['mask']是一个列表，指示每个类别是否需要这个特征
                        loss_mask_tensor = torch.tensor(
                            cond['mask'], 
                            dtype=torch.bool, 
                            device=type_values.device
                        )
                        # 使用gather获取每个位置对应的mask值
                        # 确保type_values在有效范围内
                        type_values = torch.clamp(type_values, 0, len(cond['mask']) - 1)
                        cond_mask = ~loss_mask_tensor[type_values]
                
                mask_ = cond_mask | unused_mask
            else:
                mask_ = unused_mask
            
            # 应用UNUSED token
            modified_inputs[key] = apply_token(input_val, column, mask_, 'unused')
        else:
            modified_inputs[key] = input_val
    
    return modified_inputs



def random_masking(
    inputs: Dict[str, torch.Tensor],
    input_columns: Dict,
    mask: torch.Tensor
) -> Tuple[Dict[str, torch.Tensor], Dict[str, torch.Tensor]]:
    """
    随机masking（MLM风格）
    - 15%的token被选中
    - 选中的token中：80% MASK, 10% RANDOM, 10% UNCHANGED
    
    Args:
        inputs: 输入字典
        input_columns: 列配置  
        mask: (B, S) 有效位置mask
    
    Returns:
        (modified_inputs, mfp_masks)
    """
    modified_inputs = {}
    mfp_masks = {}
    
    for key, column in input_columns.items():
        # ⭐ 跳过demo_only字段
        if column.get('demo_only', False):
            modified_inputs[key] = inputs.get(key, None)
            mfp_masks[key] = torch.zeros(mask.size(0), dtype=torch.bool, device=mask.device)
            continue
        
        # ⭐ 跳过不存在的字段
        if key not in inputs:
            continue
        
        if not column.get('is_sequence', False):
            modified_inputs[key] = inputs[key]
            mfp_masks[key] = torch.ones(
                mask.size(0), dtype=torch.bool, device=mask.device
            )
            continue
        
        input_val = inputs[key]
        
        # ⭐ 跳过非tensor
        if not torch.is_tensor(input_val):
            modified_inputs[key] = input_val
            mfp_masks[key] = torch.zeros_like(mask, dtype=torch.bool)
            continue
        
        # 随机选择MASK_PROB比例的位置
        rand_arr = torch.rand(mask.shape, device=mask.device)
        mfp_mask = mask & (rand_arr < MASK_PROB)
        
        # 在选中的位置中，80% MASK, 10% RANDOM, 10% UNCHANGED
        chg_mask = mfp_mask & (torch.rand_like(rand_arr) < CHANGE_PROB)
        rand_arr2 = torch.rand_like(rand_arr)
        
        masked_input = apply_token(input_val, column, chg_mask & (rand_arr2 >= THRESH), 'masked')
        masked_input = apply_token(masked_input, column, chg_mask & (rand_arr2 < THRESH), 'random')
        
        modified_inputs[key] = masked_input
        mfp_masks[key] = mfp_mask
    
    return modified_inputs, mfp_masks

def elem_masking(
    inputs: Dict[str, torch.Tensor],
    input_columns: Dict,
    mask: torch.Tensor,
    is_autoreg: bool = False
) -> Tuple[Dict[str, torch.Tensor], Dict[str, torch.Tensor]]:
    """
    元素级masking（mask整个元素的所有特征）
    
    Args:
        inputs: 输入字典
        input_columns: 列配置
        mask: (B, S) 有效位置mask
        is_autoreg: 是否为自回归模型（选择最后一个元素）
    
    Returns:
        (modified_inputs, mfp_masks)
    """
    mfp_masks = get_initial_masks(input_columns, mask)
    
    # 选择单个元素
    selected_mask = select_single_element(mask, select_last=is_autoreg)
    
    modified_inputs = {}
    for key, column in input_columns.items():
        # ⭐ 跳过demo_only字段
        if column.get('demo_only', False):
            modified_inputs[key] = inputs.get(key, None)
            continue
        
        # ⭐ 跳过不存在的字段
        if key not in inputs:
            continue
        
        if not column.get('is_sequence', False):
            modified_inputs[key] = inputs[key]
        else:
            input_val = inputs[key]
            # ⭐ 跳过非tensor
            if not torch.is_tensor(input_val):
                modified_inputs[key] = input_val
                continue
            
            modified_inputs[key] = apply_token(input_val, column, selected_mask, 'masked')
            mfp_masks[key] = selected_mask
    
    return modified_inputs, mfp_masks


def feat_masking(
    inputs: Dict[str, torch.Tensor],
    input_columns: Dict,
    mask: torch.Tensor,
    feat_group: List[str]
) -> Tuple[Dict[str, torch.Tensor], Dict[str, torch.Tensor]]:
    """
    特征组masking（只mask特定的特征组）
    
    Args:
        inputs: 输入字典
        input_columns: 列配置
        mask: (B, S) 有效位置mask
        feat_group: 要mask的特征列表
    
    Returns:
        (modified_inputs, mfp_masks)
    """
    modified_inputs = {}
    for k, v in inputs.items():
        # ⭐ 只clone tensor类型
        if torch.is_tensor(v):
            modified_inputs[k] = v.clone()
        else:
            modified_inputs[k] = v
    
    mfp_masks = get_initial_masks(input_columns, mask)
    
    for key in feat_group:
        if key in input_columns and key in modified_inputs:
            column = input_columns[key]
            
            # ⭐ 跳过demo_only
            if column.get('demo_only', False):
                continue
            
            input_val = modified_inputs[key]
            # ⭐ 跳过非tensor
            if not torch.is_tensor(input_val):
                continue
            
            modified_inputs[key] = apply_token(input_val, column, mask, 'masked')
            mfp_masks[key] = mask
    
    return modified_inputs, mfp_masks


def select_single_element(mask: torch.Tensor, select_last: bool = False) -> torch.Tensor:
    """
    为每个样本选择单个元素
    
    Args:
        mask: (B, S) 有效位置mask
        select_last: 是否选择最后一个有效元素
    
    Returns:
        selected_mask: (B, S) 只有一个位置为True
    """
    batch_size, seq_len = mask.shape
    device = mask.device
    
    # 计算每个样本的有效长度
    length = mask.sum(dim=1).float()  # (B,)
    
    if select_last:
        # 选择最后一个有效位置
        indices = (length - 1).long()
    else:
        # 随机选择
        indices = (torch.rand(batch_size, device=device) * length).long()
    
    # 创建one-hot mask
    new_mask = F.one_hot(indices, num_classes=seq_len).bool()
    
    # 如果length=0，则全为False
    new_mask = new_mask & (length > 0).unsqueeze(1)
    
    return new_mask


def preprocess_for_train(
    inputs: Dict[str, torch.Tensor],
    input_columns: Dict,
    task_id: int,
    is_autoreg: bool = False,
) -> Tuple[Dict[str, torch.Tensor], Dict[str, torch.Tensor], Dict[str, torch.Tensor]]:
    """
    训练时的预处理
    
    Args:
        inputs: 原始输入
        input_columns: 列配置
        task_id: 任务ID (0=random, 1=elem, 2+=feat groups)
        is_autoreg: 是否为自回归模型
    
    Returns:
        (targets, modified_inputs, masks)
    """
    # 生成序列mask
    seq_mask = get_seq_mask(inputs['length'], max_len=inputs['left'].size(1))
    
    # 过滤padding
    filtered_inputs = filter_padding(inputs, input_columns, seq_mask)
    
    # 获取属性组
    attribute_groups = get_attribute_groups(input_columns.keys())
    
    # 根据task_id选择masking策略
    if task_id == 0:
        # Random masking
        modified_inputs, masks = random_masking(filtered_inputs, input_columns, seq_mask)
    elif task_id == 1:
        # Element masking
        modified_inputs, masks = elem_masking(filtered_inputs, input_columns, seq_mask, is_autoreg)
    else:
        # Feature group masking
        group_names = list(attribute_groups.keys())
        group_idx = task_id - 2
        if group_idx < len(group_names):
            feat_group = attribute_groups[group_names[group_idx]]
            modified_inputs, masks = feat_masking(filtered_inputs, input_columns, seq_mask, feat_group)
        else:
            # 默认使用random
            modified_inputs, masks = random_masking(filtered_inputs, input_columns, seq_mask)
    
    return inputs, modified_inputs, masks


def preprocess_for_test(
    inputs: Dict[str, torch.Tensor],
    input_columns: Dict,
    masks: Dict[str, torch.Tensor],
) -> Dict[str, torch.Tensor]:
    """
    测试时的预处理（用于demo）
    
    Args:
        inputs: 原始输入
        input_columns: 列配置
        masks: 预定义的mask
    
    Returns:
        modified_inputs: 处理后的输入
    """
    seq_mask = get_seq_mask(inputs['length'], max_len=inputs['left'].size(1))
    filtered_inputs = filter_padding(inputs, input_columns, seq_mask)
    
    modified_inputs = {}
    for key, column in input_columns.items():
        if not column.get('is_sequence', False):
            modified_inputs[key] = filtered_inputs[key]
        else:
            modified_inputs[key] = apply_token(
                filtered_inputs[key], 
                column, 
                masks[key], 
                'masked'
            )
    
    return modified_inputs


def merge_inputs_and_prediction(
    inputs: Dict[str, torch.Tensor],
    input_columns: Dict,
    masks: Dict[str, torch.Tensor],
    predictions: Dict[str, torch.Tensor]
) -> Dict[str, torch.Tensor]:
    """
    合并输入和预测（未mask的部分保持原值）
    
    Args:
        inputs: 原始输入
        input_columns: 列配置
        masks: mask字典（True表示被mask的位置）
        predictions: 模型预测
    
    Returns:
        merged: 合并后的结果
    """
    merged = {}
    
    for key, column in input_columns.items():
        if key not in predictions:
            merged[key] = inputs[key]
            continue
        
        if not column.get('is_sequence', False):
            # 非序列特征保持原值
            merged[key] = inputs[key]
        elif column['type'] == 'numerical':
            # 数值特征
            pred = predictions[key]
            mask = masks[key]
            while mask.dim() < pred.dim():
                mask = mask.unsqueeze(-1)
            merged[key] = torch.where(mask, pred, inputs[key])
        else:
            # 分类特征（需要转换为one-hot）
            pred = predictions[key]  # (B, S, ..., C)
            gt = F.one_hot(inputs[key].long(), num_classes=column['input_dim'])
            
            mask = masks[key]
            while mask.dim() < gt.dim():
                mask = mask.unsqueeze(-1)
            
            merged[key] = torch.where(mask, pred, gt.float())
    
    # 复制demo_only字段
    for key, column in input_columns.items():
        if column.get('demo_only', False):
            merged[key] = inputs[key]
    
    return merged

===== dataset.py =====
"""
修复版 Dataset - 确保所有值都在正确范围内
"""

import json
import torch
from torch.utils.data import Dataset, DataLoader
from pathlib import Path
import numpy as np
from typing import Dict, List, Optional


class DesignLayoutDataset(Dataset):
    """设计布局数据集 - 修复版"""
    
    def __init__(
        self,
        data_path: str,
        split: str = 'train',
        max_length: int = 20,
        bins: int = 64,
        min_font_freq: int = 500,
    ):
        self.data_path = Path(data_path)
        self.split = split
        self.max_length = max_length
        self.bins = bins
        self.min_font_freq = min_font_freq
        
        # 加载数据
        json_file = self.data_path / f"{split}.json"
        print(f"加载数据: {json_file}")
        with open(json_file, 'r', encoding='utf-8') as f:
            self.data = json.load(f)
        
        print(f"✓ 加载了 {len(self.data)} 个样本")
        
        # 加载词汇表
        vocab_file = self.data_path.parent / "vocabulary.json"
        with open(vocab_file, 'r', encoding='utf-8') as f:
            self.vocabulary = json.load(f)
        
        # 构建查找表
        self._build_lookups()
    
    def _build_lookups(self):
        """构建字符串到索引的映射"""
        print("\n构建查找表...")
        
        # === Type映射 - 关键修复：不包含特殊token ===
        # type_vocab = self.vocabulary['type']

        type_vocab = ['','svgElement', 'textElement', 'imageElement', 'coloredBackground', 'maskElement']


        # if isinstance(type_vocab, list):
        #     # 只映射实际的类型，索引从0开始
        #     self.type_to_idx = {v: i for i, v in enumerate(type_vocab)}
        # else:
        #     self.type_to_idx = {k: i for i, k in enumerate(type_vocab.keys())}
        
        self.type_to_idx={
            '':0,
            'svgElement': 1,
            'textElement': 2,
            'imageElement': 3,
            'coloredBackground': 4,
            'maskElement': 5
            }



        
        # 添加未知类型映射到0
        # self.type_to_idx['<UNKNOWN>'] = 0
        self.type_vocab_size = len(type_vocab)  # 不包含特殊token
        
        print(f"  Type词汇表: {self.type_vocab_size} 个类型")
        print(f"  Type映射: {self.type_to_idx}")
        
        # === Canvas Width映射 ===
        if 'canvas_width' in self.vocabulary:
            width_vocab = self.vocabulary['canvas_width']
            if isinstance(width_vocab, dict):
                widths = sorted([int(k) for k in width_vocab.keys()])
            elif isinstance(width_vocab, list):
                widths = sorted([int(v) for v in width_vocab])
            else:
                widths = list(range(200, 2001, 100))
            
            self.width_to_idx = {w: i for i, w in enumerate(widths)}
            self.idx_to_width = {i: w for i, w in enumerate(widths)}
            self.idx_to_width[-1] = widths[0] if widths else 800  # 默认值
            
            self.width_vocab_size = len(widths)
            print(f"  Canvas Width词汇表: {len(widths)} 个尺寸")
        else:
            self.width_to_idx = {}
            self.idx_to_width = {0: 800}
            self.width_vocab_size = 1
        
        # === Canvas Height映射 ===
        if 'canvas_height' in self.vocabulary:
            height_vocab = self.vocabulary['canvas_height']
            if isinstance(height_vocab, dict):
                heights = sorted([int(k) for k in height_vocab.keys()])
            elif isinstance(height_vocab, list):
                heights = sorted([int(v) for v in height_vocab])
            else:
                heights = list(range(200, 2001, 100))
            
            self.height_to_idx = {h: i for i, h in enumerate(heights)}
            self.idx_to_height = {i: h for i, h in enumerate(heights)}
            self.idx_to_height[-1] = heights[0] if heights else 600
            
            self.height_vocab_size = len(heights)
            print(f"  Canvas Height词汇表: {len(heights)} 个尺寸")
        else:
            self.height_to_idx = {}
            self.idx_to_height = {0: 600}
            self.height_vocab_size = 1
        
        # === Font映射 ===
        if 'font_family' in self.vocabulary:
            font_vocab = self.vocabulary['font_family']
            
            if isinstance(font_vocab, dict):
                filtered_fonts = [
                    font for font, count in font_vocab.items() 
                    if count >= self.min_font_freq
                ]
                filtered_fonts.sort()
                self.font_to_idx = {font: i for i, font in enumerate(filtered_fonts)}
            else:
                self.font_to_idx = {v: i for i, v in enumerate(font_vocab)}
            
            # 关键修复：OOV索引应该是0（未知），而不是超出范围的值
            self.font_vocab_size = len(self.font_to_idx)
            # OOV映射到0
            self.font_oov_idx = 0
            
            print(f"  Font词汇表: {self.font_vocab_size} 个字体 (OOV->0)")
        else:
            self.font_to_idx = {}
            self.font_oov_idx = 0
            self.font_vocab_size = 0
        
        # 反向映射
        self.idx_to_type = {v: k for k, v in self.type_to_idx.items()}
        self.idx_to_font = {v: k for k, v in self.font_to_idx.items()}
    
    def discretize(self, value: float, min_val: float = 0.0, max_val: float = 1.0) -> int:
        """将连续值离散化到bins，确保结果在 [0, bins-1] 范围内"""
        value = np.clip(value, min_val, max_val)
        discrete = int((value - min_val) / (max_val - min_val) * (self.bins - 1))
        return np.clip(discrete, 0, self.bins - 1)  # 确保不超出范围
    
    def __len__(self):
        return len(self.data)
    
    def __getitem__(self, idx) -> Dict[str, torch.Tensor]:
        """获取单个样本 - 修复版，确保所有值都在范围内"""
        item = self.data[idx]
        length = min(item['length'], self.max_length)
        
        # Canvas尺寸
        canvas_w = item['canvas_width']
        canvas_h = item['canvas_height']
        
        width_idx = self.width_to_idx.get(canvas_w, 0)
        height_idx = self.height_to_idx.get(canvas_h, 0)
        
        if width_idx == 0 and canvas_w not in self.width_to_idx:
            closest_w = min(self.width_to_idx.keys(), 
                          key=lambda x: abs(x - canvas_w)) if self.width_to_idx else 800
            width_idx = self.width_to_idx.get(closest_w, 0)
            
        if height_idx == 0 and canvas_h not in self.height_to_idx:
            closest_h = min(self.height_to_idx.keys(), 
                          key=lambda x: abs(x - canvas_h)) if self.height_to_idx else 600
            height_idx = self.height_to_idx.get(closest_h, 0)
        
        sample = {
            'id': item['id'],
            'length': torch.tensor([length], dtype=torch.long),
            'canvas_width': torch.tensor([width_idx], dtype=torch.long),
            'canvas_height': torch.tensor([height_idx], dtype=torch.long),
        }
        
        # 位置和尺寸 - 确保在 [0, bins-1] 范围内
        for key in ['left', 'top', 'width', 'height']:
            values = [self.discretize(item[key][i]) for i in range(length)]
            values += [0] * (self.max_length - length)
            sample[key] = torch.tensor(values, dtype=torch.long).unsqueeze(-1)
        
        # 类型编码 - 确保在 [0, type_vocab_size-1] 范围内
        type_ids = []
        for i in range(length):
            type_name = item['type'][i]
            type_id = self.type_to_idx.get(type_name, 0)  # 未知类型映射到0
            type_id = min(type_id, self.type_vocab_size - 1)  # 确保不超出范围
            type_ids.append(type_id)
        type_ids += [0] * (self.max_length - length)
        sample['type'] = torch.tensor(type_ids, dtype=torch.long).unsqueeze(-1)
        
        # 不透明度 - 确保在 [0, 7] 范围内
        if 'opacity' in item:
            opacity_values = []
            for i in range(length):
                # 离散化到8个bins: 0.0-1.0 -> 0-7
                opacity = np.clip(item['opacity'][i], 0.0, 1.0)
                discrete_val = int(opacity * 7)
                discrete_val = min(discrete_val, 7)  # 确保不超过7
                opacity_values.append(discrete_val)
            opacity_values += [0] * (self.max_length - length)
            sample['opacity'] = torch.tensor(opacity_values, dtype=torch.long).unsqueeze(-1)
        
        # 颜色 - 确保每个通道在 [0, 15] 范围内
        if 'color' in item:
            colors = []
            for i in range(length):
                rgb = item['color'][i]
                # 离散化每个通道：0-255 -> 0-15
                discrete_rgb = []
                for c in rgb:
                    c = np.clip(c, 0, 255)
                    discrete_c = int(c * 15 / 255)
                    discrete_c = min(discrete_c, 15)  # 确保不超过15
                    discrete_rgb.append(discrete_c)
                colors.append(discrete_rgb)
            for _ in range(self.max_length - length):
                colors.append([0, 0, 0])
            sample['color'] = torch.tensor(colors, dtype=torch.long)
        
        # 字体编码 - 确保在 [0, font_vocab_size-1] 范围内
        if 'font_family' in item and self.font_to_idx:
            font_ids = []
            for i in range(length):
                font_name = item['font_family'][i]
                font_id = self.font_to_idx.get(font_name, self.font_oov_idx)
                # 关键修复：确保不超出范围 [0, font_vocab_size-1]
                font_id = np.clip(font_id, 0, self.font_vocab_size - 1)
                font_ids.append(font_id)
            
            font_ids += [0] * (self.max_length - length)
            sample['font_family'] = torch.tensor(font_ids, dtype=torch.long).unsqueeze(-1)
        
        # UUID - 仅用于demo，不参与训练
        if 'uuid' in item:
            # 简单存储原始值，但标记为demo_only
            uuid_vals = item['uuid'][:length] + [''] * (self.max_length - length)
            sample['uuid'] = uuid_vals  # 保持为字符串列表，不转tensor
        
        # 图像嵌入
        if 'image_embedding' in item:
            image_embs = item['image_embedding'][:length]
            for _ in range(self.max_length - length):
                image_embs.append([0.0] * 512)
            sample['image_embedding'] = torch.tensor(image_embs, dtype=torch.float32)
        
        # 文本嵌入
        if 'text_embedding' in item:
            text_embs = item['text_embedding'][:length]
            for _ in range(self.max_length - length):
                text_embs.append([0.0] * 512)
            sample['text_embedding'] = torch.tensor(text_embs, dtype=torch.float32)
        
        return sample
    
    def get_input_columns(self) -> Dict:
        """
        生成input_columns配置
        关键：input_dim 是实际的类别数，不包含Encoder会添加的特殊token
        """
        input_columns = {
            'id': {
                'demo_only': True,
                'shape': [1],
                'is_sequence': False,
                'primary_label': None,
            },
            'length': {
                'type': 'categorical',
                'input_dim': 50,
                'shape': [1],
                'is_sequence': False,
                'primary_label': None,
            },
            'canvas_width': {
                'type': 'categorical',
                'input_dim': self.width_vocab_size,
                'shape': [1],
                'is_sequence': False,
                'primary_label': None,
            },
            'canvas_height': {
                'type': 'categorical',
                'input_dim': self.height_vocab_size,
                'shape': [1],
                'is_sequence': False,
                'primary_label': None,
            },
            'type': {
                'type': 'categorical',
                'input_dim': self.type_vocab_size,  # 实际类别数
                'shape': [1],
                'is_sequence': True,
                'primary_label': 0,
            },
            'left': {
                'type': 'categorical',
                'input_dim': self.bins,  # 64
                'shape': [1],
                'is_sequence': True,
                'primary_label': None,
            },
            'top': {
                'type': 'categorical',
                'input_dim': self.bins,  # 64
                'shape': [1],
                'is_sequence': True,
                'primary_label': None,
            },
            'width': {
                'type': 'categorical',
                'input_dim': self.bins,  # 64
                'shape': [1],
                'is_sequence': True,
                'primary_label': None,
            },
            'height': {
                'type': 'categorical',
                'input_dim': self.bins,  # 64
                'shape': [1],
                'is_sequence': True,
                'primary_label': None,
            },
            'opacity': {
                'type': 'categorical',
                'input_dim': 8,  # 0-7
                'shape': [1],
                'is_sequence': True,
                'primary_label': None,
            },
            'color': {
                'type': 'categorical',
                'input_dim': 16,  # 0-15 每个通道
                'shape': [3],
                'is_sequence': True,
                'primary_label': None,
            },
            'image_embedding': {
                'type': 'numerical',
                'shape': [512],
                'is_sequence': True,
                'primary_label': None,
            },
            'text_embedding': {
                'type': 'numerical',
                'shape': [512],
                'is_sequence': True,
                'primary_label': None,
            },
        }
        
        # 只有在有字体数据时才添加
        if self.font_vocab_size > 0:
            input_columns['font_family'] = {
                'type': 'categorical',
                'input_dim': self.font_vocab_size,
                'shape': [1],
                'is_sequence': True,
                'primary_label': None,
            }
        
        # UUID 仅用于演示，不参与训练
        input_columns['uuid'] = {
            'demo_only': True,
            'type': 'categorical',
            'input_dim': 1215,
            'shape': [1],
            'is_sequence': True,
            'primary_label': None,
        }
        
        return input_columns


def collate_fn(batch: List[Dict]) -> Dict[str, torch.Tensor]:
    """批处理函数"""
    keys = batch[0].keys()
    collated = {}
    
    for key in keys:
        if key in ['id', 'uuid']:  # id和uuid保持为列表
            collated[key] = [item[key] for item in batch]
        else:
            collated[key] = torch.stack([item[key] for item in batch])
    
    return collated


def create_dataloader(
    data_path: str,
    split: str = 'train',
    batch_size: int = 32,
    shuffle: bool = True,
    num_workers: int = 4,
    **dataset_kwargs
) -> DataLoader:
    """创建数据加载器"""
    dataset = DesignLayoutDataset(data_path, split=split, **dataset_kwargs)
    
    dataloader = DataLoader(
        dataset,
        batch_size=batch_size,
        shuffle=shuffle,
        num_workers=num_workers,
        collate_fn=collate_fn,
        pin_memory=True,
    )
    
    return dataloader

