{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDAå¯ç”¨: False\n",
      "è®¾å¤‡æ•°é‡: 0\n",
      "âœ“ å¯¼å…¥å®Œæˆï¼ˆCPUæ¨¡å¼ï¼‰\n",
      "\n",
      "âœ“ é…ç½®: device=cpu, batch_size=4\n",
      "\n",
      "================================================================================\n",
      "MFP PyTorch Demo - çº¯CPUç‰ˆæœ¬\n",
      "================================================================================\n",
      "\n",
      "1. åŠ è½½æ•°æ®é›†\n",
      "åŠ è½½æ•°æ®: /home/dell/Project-HCL/BaseLine/flexdm_pt/data/crello_json/test.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Building ImageRetriever index for test...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ åŠ è½½äº† 2248 ä¸ªæ ·æœ¬\n",
      "\n",
      "æ„å»ºæŸ¥æ‰¾è¡¨...\n",
      "  Typeè¯æ±‡è¡¨: 7 ä¸ªç±»å‹\n",
      "  Canvas Widthè¯æ±‡è¡¨: 41 ä¸ªå°ºå¯¸\n",
      "    èŒƒå›´: 160 - 3000\n",
      "  Canvas Heightè¯æ±‡è¡¨: 46 ä¸ªå°ºå¯¸\n",
      "    èŒƒå›´: 90 - 2560\n",
      "  Fontè¿‡æ»¤: 290 -> 34 (é¢‘ç‡>=500)\n",
      "  Fontè¯æ±‡è¡¨: 37 ä¸ªtoken (å«ç‰¹æ®Štoken)\n",
      "âœ“ æ•°æ®é›†å¤§å°: 2248\n",
      "\n",
      "2. åŠ è½½æ˜ å°„\n",
      "âœ“ å­—ä½“æ˜ å°„: 37 ä¸ªå­—ä½“\n",
      "âœ“ Widthæ˜ å°„: 42 ä¸ªå°ºå¯¸\n",
      "âœ“ Heightæ˜ å°„: 47 ä¸ªå°ºå¯¸\n",
      "\n",
      "3. åˆ›å»ºDataLoader\n",
      "âœ“ æ‰¹æ¬¡å½¢çŠ¶: torch.Size([4, 20, 1])\n",
      "\n",
      "4. åŠ è½½æ¨¡å‹é…ç½®\n",
      "âœ“ è¾“å…¥åˆ—æ•°: 17\n",
      "\n",
      "5. åŠ è½½æ¨¡å‹\n",
      "åŠ è½½æ¨¡å‹: /home/dell/Project-HCL/BaseLine/flexdm_pt/chechpoints/best_pytorch.pth\n",
      "\n",
      "============================================================\n",
      "åˆå§‹åŒ–MFPæ¨¡å‹\n",
      "============================================================\n",
      "åˆå§‹åŒ–Encoder:\n",
      "  type: Embedding(8, 256)\n",
      "  left: Embedding(66, 256)\n",
      "  top: Embedding(66, 256)\n",
      "  width: Embedding(66, 256)\n",
      "  height: Embedding(66, 256)\n",
      "  opacity: Embedding(10, 256)\n",
      "  color: Embedding(18, 256)\n",
      "  image_embedding: Linear(512, 256)\n",
      "  text_embedding: Linear(512, 256)\n",
      "  font_family: Embedding(37, 256)\n",
      "æ€»è®¡: 10 ä¸ªç‰¹å¾\n",
      "\n",
      "åˆå§‹åŒ–Transformer:\n",
      "  blocks=4, embed_dim=256, num_heads=8\n",
      "\n",
      "åˆå§‹åŒ–Decoder:\n",
      "  type: Linear(256, 6) -> (1, 6)\n",
      "  left: Linear(256, 64) -> (1, 64)\n",
      "  top: Linear(256, 64) -> (1, 64)\n",
      "  width: Linear(256, 64) -> (1, 64)\n",
      "  height: Linear(256, 64) -> (1, 64)\n",
      "  opacity: Linear(256, 8) -> (1, 8)\n",
      "  color: Linear(256, 48) -> (3, 16)\n",
      "  image_embedding: Linear(256, 512)\n",
      "  text_embedding: Linear(256, 512)\n",
      "  font_family: Linear(256, 35) -> (1, 35)\n",
      "æ€»è®¡: 10 ä¸ªè¾“å‡ºå¤´\n",
      "\n",
      "æ€»å‚æ•°æ•°: 2,824,289\n",
      "============================================================\n",
      "\n",
      "  è­¦å‘Š: ç¼ºå¤± 97 ä¸ªé”®\n",
      "  è­¦å‘Š: å¤šä½™ 84 ä¸ªé”®\n",
      "âœ“ æ¨¡å‹åŠ è½½å®Œæˆï¼ˆCPUï¼‰\n",
      "\n",
      "6. æ„å»ºæ£€ç´¢æ•°æ®åº“\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Embeddings shape: (11306, 512), dtype: float32, C-contiguous: True\n",
      "INFO: âœ“ Built index with 11306 items\n",
      "INFO: Building TextRetriever index for test...\n",
      "INFO: Embeddings shape: (6973, 512), dtype: float32, C-contiguous: True\n",
      "INFO: âœ“ Built index with 6973 items\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "7. åˆ›å»ºSVGæ„å»ºå™¨\n",
      "âœ“ æ„å»ºå™¨åˆ›å»ºå®Œæˆ\n",
      "\n",
      "================================================================================\n",
      "8. å¼€å§‹å¯è§†åŒ– - ä»»åŠ¡: pos\n",
      "================================================================================\n",
      "æ¸²æŸ“ 4 ä¸ªæ ·æœ¬...\n",
      "  - GT Layout\n",
      "  - GT Visual\n",
      "  - æ¨¡å‹æ¨ç†\n",
      "  - Pred Layout\n",
      "  - Pred Visual\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "int() argument must be a string, a bytes-like object or a real number, not 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 444\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m8. å¼€å§‹å¯è§†åŒ– - ä»»åŠ¡: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39mtarget_task\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    442\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m80\u001b[39m)\n\u001b[0;32m--> 444\u001b[0m svgs \u001b[38;5;241m=\u001b[39m \u001b[43mvisualize_reconstruction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuilders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_columns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    445\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mtype_mapping\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfont_mapping\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwidth_mapping\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    446\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mheight_mapping\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbins\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    448\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mâœ“ ç”Ÿæˆäº† \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(svgs)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m ä¸ªæ ·æœ¬çš„å¯è§†åŒ–ç»“æœ\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    449\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124måˆ—å: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39mcolumn_names[config\u001b[38;5;241m.\u001b[39mtarget_task]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[1], line 353\u001b[0m, in \u001b[0;36mvisualize_reconstruction\u001b[0;34m(model, example, builders, config, input_columns, type_mapping, font_mapping, width_mapping, height_mapping, bins)\u001b[0m\n\u001b[1;32m    350\u001b[0m     svgs\u001b[38;5;241m.\u001b[39mappend([builders[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlayout\u001b[39m\u001b[38;5;124m\"\u001b[39m](item) \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m pred_items])\n\u001b[1;32m    352\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  - Pred Visual\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 353\u001b[0m svgs\u001b[38;5;241m.\u001b[39mappend(\u001b[43m[\u001b[49m\u001b[43mbuilders\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvisual\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mitem\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpred_items\u001b[49m\u001b[43m]\u001b[49m)\n\u001b[1;32m    355\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mâœ“ æ¸²æŸ“å®Œæˆ\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    356\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39msvgs))\n",
      "Cell \u001b[0;32mIn[1], line 353\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    350\u001b[0m     svgs\u001b[38;5;241m.\u001b[39mappend([builders[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlayout\u001b[39m\u001b[38;5;124m\"\u001b[39m](item) \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m pred_items])\n\u001b[1;32m    352\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  - Pred Visual\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 353\u001b[0m svgs\u001b[38;5;241m.\u001b[39mappend([\u001b[43mbuilders\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvisual\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m pred_items])\n\u001b[1;32m    355\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mâœ“ æ¸²æŸ“å®Œæˆ\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    356\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39msvgs))\n",
      "File \u001b[0;32m/home/dell/Project-HCL/BaseLine/flexdm_pt/scripts/svg_builder_pytorch.py:108\u001b[0m, in \u001b[0;36mSVGBuilder.__call__\u001b[0;34m(self, document)\u001b[0m\n\u001b[1;32m    106\u001b[0m elements \u001b[38;5;241m=\u001b[39m document\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124melements\u001b[39m\u001b[38;5;124m'\u001b[39m, [])\n\u001b[1;32m    107\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, element \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(elements):\n\u001b[0;32m--> 108\u001b[0m     svg_parts\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_element_to_svg\u001b[49m\u001b[43m(\u001b[49m\u001b[43melement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    110\u001b[0m \u001b[38;5;66;03m# SVGå°¾éƒ¨\u001b[39;00m\n\u001b[1;32m    111\u001b[0m svg_parts\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m</svg>\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/home/dell/Project-HCL/BaseLine/flexdm_pt/scripts/svg_builder_pytorch.py:121\u001b[0m, in \u001b[0;36mSVGBuilder._element_to_svg\u001b[0;34m(self, element, index)\u001b[0m\n\u001b[1;32m    119\u001b[0m color \u001b[38;5;241m=\u001b[39m element\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcolor\u001b[39m\u001b[38;5;124m'\u001b[39m, [\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(color, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m, np\u001b[38;5;241m.\u001b[39mndarray)):\n\u001b[0;32m--> 121\u001b[0m     fill \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrgb(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcolor\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m,\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mint\u001b[39m(color[\u001b[38;5;241m1\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m,\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mint\u001b[39m(color[\u001b[38;5;241m2\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    123\u001b[0m     fill \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrgb(0,0,0)\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "\u001b[0;31mTypeError\u001b[0m: int() argument must be a string, a bytes-like object or a real number, not 'list'"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "MFP PyTorch Demo - çº¯CPUç‰ˆæœ¬\n",
    "å®Œå…¨ç¦ç”¨CUDAï¼Œå¼ºåˆ¶ä½¿ç”¨CPU\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "# ğŸ”§ åœ¨å¯¼å…¥torchä¹‹å‰ç¦ç”¨CUDA\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = ''  # å¯¹torchéšè—æ‰€æœ‰GPU\n",
    "\n",
    "import json\n",
    "import logging\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Optional\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# ç¡®è®¤CUDAå·²ç¦ç”¨\n",
    "print(f\"CUDAå¯ç”¨: {torch.cuda.is_available()}\")  # åº”è¯¥æ˜¯False\n",
    "print(f\"è®¾å¤‡æ•°é‡: {torch.cuda.device_count()}\")  # åº”è¯¥æ˜¯0\n",
    "\n",
    "from models_pytorch import MFP\n",
    "from dataset import DesignLayoutDataset\n",
    "from svg_builder_pytorch import SVGBuilder\n",
    "from retriever_pytorch import ImageRetriever, TextRetriever\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "print(\"âœ“ å¯¼å…¥å®Œæˆï¼ˆCPUæ¨¡å¼ï¼‰\\n\")\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# é…ç½®\n",
    "# ============================================================\n",
    "class DemoConfig:\n",
    "    def __init__(self):\n",
    "        self.ckpt_dir = \"/home/dell/Project-HCL/BaseLine/flexdm_pt/chechpoints\"\n",
    "        self.dataset_name = \"crello_json\"\n",
    "        self.db_root = \"/home/dell/Project-HCL/BaseLine/flexdm_pt/data/crello_json\"\n",
    "        self.batch_size = 4\n",
    "        self.device = 'cpu'  # å¼ºåˆ¶CPU\n",
    "        self.target_task = \"pos\"\n",
    "        \n",
    "        self.column_names = {\n",
    "            \"txt\": [\"gt-layout\", \"gt-visual\", \"input\", \"pred\"],\n",
    "            \"img\": [\"gt-layout\", \"gt-visual\", \"input\", \"pred\"],\n",
    "            \"attr\": [\"gt-layout\", \"gt-visual\", \"input\", \"pred\"],\n",
    "            \"pos\": [\"gt-layout\", \"gt-visual\", \"pred-layout\", \"pred-visual\"],\n",
    "            \"elem\": [\"gt-layout\", \"gt-visual\", \"input-layout\", \"input-visual\", \n",
    "                     \"pred-layout\", \"pred-visual\"],\n",
    "        }\n",
    "        \n",
    "        self.attribute_groups = {\n",
    "            \"type\": [\"type\"],\n",
    "            \"pos\": [\"left\", \"top\", \"width\", \"height\"],\n",
    "            \"attr\": [\"opacity\", \"color\", \"font_family\"],\n",
    "            \"img\": [\"image_embedding\"],\n",
    "            \"txt\": [\"text_embedding\"],\n",
    "        }\n",
    "\n",
    "config = DemoConfig()\n",
    "print(f\"âœ“ é…ç½®: device={config.device}, batch_size={config.batch_size}\\n\")\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# ç±»å‹æ˜ å°„\n",
    "# ============================================================\n",
    "DEFAULT_TYPE_MAPPING = {\n",
    "    0: '', 1: 'svgElement', 2: 'textElement', 3: 'imageElement',\n",
    "    4: 'coloredBackground', 5: 'maskElement', 6: 'humanElement',\n",
    "}\n",
    "\n",
    "def load_type_mapping_from_vocab(vocab_file: str):\n",
    "    return DEFAULT_TYPE_MAPPING\n",
    "\n",
    "def load_font_mapping_from_dataset(dataset):\n",
    "    return dataset.idx_to_font if hasattr(dataset, 'idx_to_font') else {}\n",
    "\n",
    "def load_canvas_mappings_from_dataset(dataset):\n",
    "    width_mapping = dataset.idx_to_width if hasattr(dataset, 'idx_to_width') else {}\n",
    "    height_mapping = dataset.idx_to_height if hasattr(dataset, 'idx_to_height') else {}\n",
    "    return width_mapping, height_mapping\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# æ•°æ®å¤„ç†å·¥å…·\n",
    "# ============================================================\n",
    "def _extract_scalar(tensor):\n",
    "    if tensor.dim() == 0:\n",
    "        return tensor.item()\n",
    "    elif tensor.dim() == 1:\n",
    "        return tensor[0].item() if tensor.size(0) == 1 else tensor.argmax().item()\n",
    "    else:\n",
    "        return tensor.argmax(dim=-1)[0].item() if tensor.size(0) > 0 else 0\n",
    "\n",
    "\n",
    "def tensor_to_list(data, type_mapping, font_mapping=None, \n",
    "                   width_mapping=None, height_mapping=None, bins=64):\n",
    "    batch_size = data['length'].size(0)\n",
    "    items = []\n",
    "    scale = 1.0 / (bins - 1.0)\n",
    "    \n",
    "    for i in range(batch_size):\n",
    "        # Canvaså°ºå¯¸\n",
    "        canvas_w = 800\n",
    "        canvas_h = 600\n",
    "        \n",
    "        if 'canvas_width' in data:\n",
    "            width_idx = data['canvas_width'][i].item()\n",
    "            if width_mapping and width_idx in width_mapping:\n",
    "                canvas_w = width_mapping[width_idx]\n",
    "        \n",
    "        if 'canvas_height' in data:\n",
    "            height_idx = data['canvas_height'][i].item()\n",
    "            if height_mapping and height_idx in height_mapping:\n",
    "                canvas_h = height_mapping[height_idx]\n",
    "        \n",
    "        item = {\n",
    "            'id': data['id'][i] if 'id' in data else f'sample_{i}',\n",
    "            'canvas_width': canvas_w,\n",
    "            'canvas_height': canvas_h,\n",
    "            'length': data['length'][i].item(),\n",
    "            'elements': []\n",
    "        }\n",
    "        \n",
    "        for j in range(item['length']):\n",
    "            element = {}\n",
    "            \n",
    "            for key, value in data.items():\n",
    "                if key in ['id', 'length', 'canvas_width', 'canvas_height']:\n",
    "                    continue\n",
    "                if not torch.is_tensor(value):\n",
    "                    continue\n",
    "                if value.dim() < 2 or value.size(1) <= j:\n",
    "                    continue\n",
    "                \n",
    "                elem_value = value[i, j]\n",
    "                \n",
    "                if key == 'type':\n",
    "                    element[key] = type_mapping.get(int(_extract_scalar(elem_value)), '')\n",
    "                elif key == 'font_family' and font_mapping:\n",
    "                    element[key] = font_mapping.get(int(_extract_scalar(elem_value)), 'Arial')\n",
    "                elif key in ['left', 'top', 'width', 'height']:\n",
    "                    discrete_idx = _extract_scalar(elem_value)\n",
    "                    element[key] = float(np.clip(scale * discrete_idx, 0.0, 1.0))\n",
    "                elif key == 'color':\n",
    "                    # å¤„ç†colorï¼šéœ€è¦åç¦»æ•£åŒ–\n",
    "                    # æ¨¡å‹è¾“å‡ºshape: (B, S, 3, 16) -> logits\n",
    "                    if elem_value.dim() == 2 and elem_value.size(0) == 3:\n",
    "                        # å–argmaxå¾—åˆ°ç¦»æ•£ç´¢å¼• (3,) æ¯ä¸ªå€¼åœ¨0-15\n",
    "                        discrete_indices = elem_value.argmax(dim=-1).cpu().numpy()\n",
    "                        # åç¦»æ•£åŒ–åˆ°0-255\n",
    "                        rgb = [int(idx * 255 / 15) for idx in discrete_indices]\n",
    "                        element[key] = rgb\n",
    "                    elif elem_value.dim() == 1 and elem_value.size(0) == 3:\n",
    "                        # å·²ç»æ˜¯ç¦»æ•£ç´¢å¼•\n",
    "                        rgb = [int(idx * 255 / 15) for idx in elem_value.cpu().numpy()]\n",
    "                        element[key] = rgb\n",
    "                    else:\n",
    "                        element[key] = [128, 128, 128]\n",
    "                elif key == 'opacity':\n",
    "                    # åç¦»æ•£åŒ–ï¼š0-7 -> 0.0-1.0\n",
    "                    discrete_idx = _extract_scalar(elem_value)\n",
    "                    element[key] = float(discrete_idx / 7.0)\n",
    "                elif 'embedding' in key:\n",
    "                    element[key] = elem_value.cpu().numpy()\n",
    "                elif key == 'uuid':\n",
    "                    element[key] = str(_extract_scalar(elem_value))\n",
    "                else:\n",
    "                    element[key] = _extract_scalar(elem_value)\n",
    "            \n",
    "            item['elements'].append(element)\n",
    "        \n",
    "        items.append(item)\n",
    "    \n",
    "    return items\n",
    "\n",
    "\n",
    "def get_seq_mask(lengths, max_len=None):\n",
    "    if lengths.dim() == 2:\n",
    "        lengths = lengths.squeeze(-1)\n",
    "    if max_len is None:\n",
    "        max_len = lengths.max().item()\n",
    "    mask = torch.arange(max_len, device=lengths.device).unsqueeze(0) < lengths.unsqueeze(1)\n",
    "    return mask\n",
    "\n",
    "\n",
    "def get_initial_masks(input_columns, seq_mask):\n",
    "    masks = {}\n",
    "    batch_size, seq_len = seq_mask.shape\n",
    "    for key, column in input_columns.items():\n",
    "        if column.get('is_sequence', False):\n",
    "            masks[key] = torch.zeros_like(seq_mask, dtype=torch.bool)\n",
    "        else:\n",
    "            masks[key] = torch.ones(batch_size, dtype=torch.bool)\n",
    "    return masks\n",
    "\n",
    "\n",
    "def set_visual_default(item):\n",
    "    item = item.copy()\n",
    "    for elem in item.get('elements', []):\n",
    "        elem.setdefault('color', [128, 128, 128])\n",
    "        elem.setdefault('opacity', 1.0)\n",
    "        elem.setdefault('font_family', 'Arial')\n",
    "    return item\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# æ¨¡å‹ç›¸å…³ï¼ˆçº¯CPUç‰ˆæœ¬ï¼‰\n",
    "# ============================================================\n",
    "def load_model(checkpoint_path, input_columns):\n",
    "    \"\"\"åŠ è½½æ¨¡å‹ - å¼ºåˆ¶CPU\"\"\"\n",
    "    print(f\"åŠ è½½æ¨¡å‹: {checkpoint_path}\")\n",
    "    \n",
    "    model = MFP(\n",
    "        input_columns=input_columns,\n",
    "        embed_dim=256,\n",
    "        num_blocks=4,\n",
    "        num_heads=8,\n",
    "        dropout=0.1,\n",
    "    )\n",
    "    \n",
    "    # å¼ºåˆ¶åŠ è½½åˆ°CPU\n",
    "    checkpoint = torch.load(checkpoint_path, map_location='cpu')\n",
    "    state_dict = checkpoint.get('state_dict', checkpoint)\n",
    "    \n",
    "    missing, unexpected = model.load_state_dict(state_dict, strict=False)\n",
    "    \n",
    "    if missing:\n",
    "        print(f\"  è­¦å‘Š: ç¼ºå¤± {len(missing)} ä¸ªé”®\")\n",
    "    if unexpected:\n",
    "        print(f\"  è­¦å‘Š: å¤šä½™ {len(unexpected)} ä¸ªé”®\")\n",
    "    \n",
    "    model.eval()\n",
    "    print(\"âœ“ æ¨¡å‹åŠ è½½å®Œæˆï¼ˆCPUï¼‰\\n\")\n",
    "    return model\n",
    "\n",
    "\n",
    "def apply_task_masks(example, input_columns, target_task, attribute_groups):\n",
    "    seq_mask = get_seq_mask(example['length'], example['left'].size(1))\n",
    "    mfp_masks = get_initial_masks(input_columns, seq_mask)\n",
    "    \n",
    "    for key in mfp_masks.keys():\n",
    "        if not input_columns[key].get('is_sequence', False):\n",
    "            continue\n",
    "        \n",
    "        mask = mfp_masks[key].clone()\n",
    "        \n",
    "        if target_task == \"elem\":\n",
    "            mask[:, 0] = True\n",
    "        else:\n",
    "            if key != \"type\" and target_task in attribute_groups:\n",
    "                if key in attribute_groups[target_task]:\n",
    "                    mask = seq_mask.clone()\n",
    "        \n",
    "        mfp_masks[key] = mask\n",
    "    \n",
    "    return mfp_masks\n",
    "\n",
    "\n",
    "def model_inference_with_masks(model, inputs, masks):\n",
    "    \"\"\"æ¨¡å‹æ¨ç† - çº¯CPU\"\"\"\n",
    "    masked_inputs = {}\n",
    "    \n",
    "    for key, value in inputs.items():\n",
    "        if key in masks and torch.is_tensor(value):\n",
    "            mask = masks[key]\n",
    "            if mask.any():\n",
    "                masked_value = value.clone()\n",
    "                if value.dim() == 3:\n",
    "                    masked_value[mask] = 0\n",
    "                masked_inputs[key] = masked_value\n",
    "            else:\n",
    "                masked_inputs[key] = value\n",
    "        else:\n",
    "            masked_inputs[key] = value\n",
    "    \n",
    "    # ç¡®ä¿æ‰€æœ‰æ•°æ®åœ¨CPUä¸Š\n",
    "    for key in masked_inputs:\n",
    "        if torch.is_tensor(masked_inputs[key]):\n",
    "            masked_inputs[key] = masked_inputs[key].cpu()\n",
    "    \n",
    "    outputs = model(masked_inputs)\n",
    "    return outputs\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# å¯è§†åŒ–ä¸»å‡½æ•°\n",
    "# ============================================================\n",
    "def visualize_reconstruction(model, example, builders, config, input_columns,\n",
    "                            type_mapping, font_mapping=None, width_mapping=None, \n",
    "                            height_mapping=None, bins=64):\n",
    "    svgs = []\n",
    "    target_task = config.target_task\n",
    "    \n",
    "    # ç¡®ä¿æ•°æ®åœ¨CPU\n",
    "    for key in example:\n",
    "        if torch.is_tensor(example[key]):\n",
    "            example[key] = example[key].cpu()\n",
    "    \n",
    "    items = tensor_to_list(example, type_mapping, font_mapping, \n",
    "                          width_mapping, height_mapping, bins)\n",
    "    \n",
    "    print(f\"æ¸²æŸ“ {len(items)} ä¸ªæ ·æœ¬...\")\n",
    "    \n",
    "    # GT\n",
    "    print(\"  - GT Layout\")\n",
    "    svgs.append([builders[\"layout\"](item) for item in items])\n",
    "    print(\"  - GT Visual\")\n",
    "    svgs.append([builders[\"visual\"](item) for item in items])\n",
    "    \n",
    "    # è¾“å…¥è§†å›¾\n",
    "    if target_task == \"txt\":\n",
    "        print(\"  - Input (æ— æ–‡æœ¬)\")\n",
    "        svgs.append([builders[\"visual_wo_text\"](item) for item in items])\n",
    "    elif target_task == \"img\":\n",
    "        print(\"  - Input (æ— å›¾åƒ)\")\n",
    "        svgs.append([builders[\"visual_wo_image\"](item) for item in items])\n",
    "    elif target_task == \"attr\":\n",
    "        print(\"  - Input (é»˜è®¤å±æ€§)\")\n",
    "        svgs.append([builders[\"visual\"](set_visual_default(item)) for item in items])\n",
    "    \n",
    "    # æ©ç \n",
    "    mfp_masks = apply_task_masks(example, input_columns, target_task, \n",
    "                                 config.attribute_groups)\n",
    "    \n",
    "    # å…ƒç´ çº§ä»»åŠ¡\n",
    "    if target_task == \"elem\":\n",
    "        example_copy = {}\n",
    "        for key, value in example.items():\n",
    "            if isinstance(value, torch.Tensor) and value.dim() >= 2 and value.size(1) > 1:\n",
    "                indices = torch.where(~mfp_masks[key][0, :])[0]\n",
    "                example_copy[key] = torch.index_select(value, 1, indices)\n",
    "            else:\n",
    "                example_copy[key] = value\n",
    "        \n",
    "        example_copy['length'] = example['length'] - 1\n",
    "        items_copy = tensor_to_list(example_copy, type_mapping, font_mapping,\n",
    "                                    width_mapping, height_mapping, bins)\n",
    "        svgs.append([builders[\"layout\"](item) for item in items_copy])\n",
    "        svgs.append([builders[\"visual\"](item) for item in items_copy])\n",
    "    \n",
    "    # é¢„æµ‹\n",
    "    print(\"  - æ¨¡å‹æ¨ç†\")\n",
    "    with torch.no_grad():\n",
    "        pred = model_inference_with_masks(model, example, mfp_masks)\n",
    "    \n",
    "    for key in example:\n",
    "        if key not in pred:\n",
    "            pred[key] = example[key]\n",
    "    \n",
    "    pred_items = tensor_to_list(pred, type_mapping, font_mapping,\n",
    "                                width_mapping, height_mapping, bins)\n",
    "    \n",
    "    if target_task in [\"pos\", \"elem\"]:\n",
    "        print(\"  - Pred Layout\")\n",
    "        svgs.append([builders[\"layout\"](item) for item in pred_items])\n",
    "    \n",
    "    print(\"  - Pred Visual\")\n",
    "    svgs.append([builders[\"visual\"](item) for item in pred_items])\n",
    "    \n",
    "    print(\"âœ“ æ¸²æŸ“å®Œæˆ\\n\")\n",
    "    return list(zip(*svgs))\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# ä¸»æµç¨‹\n",
    "# ============================================================\n",
    "print(\"=\"*80)\n",
    "print(\"MFP PyTorch Demo - çº¯CPUç‰ˆæœ¬\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# 1. åŠ è½½æ•°æ®é›†\n",
    "print(\"\\n1. åŠ è½½æ•°æ®é›†\")\n",
    "dataset = DesignLayoutDataset(config.db_root, split='test', max_length=20)\n",
    "print(f\"âœ“ æ•°æ®é›†å¤§å°: {len(dataset)}\\n\")\n",
    "\n",
    "# 2. åŠ è½½æ˜ å°„\n",
    "print(\"2. åŠ è½½æ˜ å°„\")\n",
    "vocab_file = Path(config.db_root).parent / \"vocabulary.json\"\n",
    "type_mapping = load_type_mapping_from_vocab(str(vocab_file))\n",
    "font_mapping = load_font_mapping_from_dataset(dataset)\n",
    "width_mapping, height_mapping = load_canvas_mappings_from_dataset(dataset)\n",
    "\n",
    "if font_mapping:\n",
    "    print(f\"âœ“ å­—ä½“æ˜ å°„: {len(font_mapping)} ä¸ªå­—ä½“\")\n",
    "if width_mapping:\n",
    "    print(f\"âœ“ Widthæ˜ å°„: {len(width_mapping)} ä¸ªå°ºå¯¸\")\n",
    "if height_mapping:\n",
    "    print(f\"âœ“ Heightæ˜ å°„: {len(height_mapping)} ä¸ªå°ºå¯¸\")\n",
    "print()\n",
    "\n",
    "# 3. åˆ›å»ºDataLoader\n",
    "print(\"3. åˆ›å»ºDataLoader\")\n",
    "from torch.utils.data import DataLoader\n",
    "from dataset import collate_fn\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=config.batch_size, \n",
    "                       shuffle=False, collate_fn=collate_fn)\n",
    "example = next(iter(dataloader))\n",
    "\n",
    "# å¼ºåˆ¶è½¬CPU\n",
    "for key in example:\n",
    "    if torch.is_tensor(example[key]):\n",
    "        example[key] = example[key].cpu()\n",
    "\n",
    "print(f\"âœ“ æ‰¹æ¬¡å½¢çŠ¶: {example['left'].shape}\\n\")\n",
    "\n",
    "# 4. åŠ è½½é…ç½®\n",
    "print(\"4. åŠ è½½æ¨¡å‹é…ç½®\")\n",
    "input_columns_file = './input_columns_generated.json'\n",
    "with open(input_columns_file, 'r') as f:\n",
    "    input_columns = json.load(f)\n",
    "print(f\"âœ“ è¾“å…¥åˆ—æ•°: {len(input_columns)}\\n\")\n",
    "\n",
    "# 5. åŠ è½½æ¨¡å‹\n",
    "print(\"5. åŠ è½½æ¨¡å‹\")\n",
    "checkpoint_path = Path(config.ckpt_dir) / \"best_pytorch.pth\"\n",
    "model = load_model(str(checkpoint_path), input_columns)\n",
    "\n",
    "# 6. æ„å»ºæ£€ç´¢æ•°æ®åº“\n",
    "print(\"6. æ„å»ºæ£€ç´¢æ•°æ®åº“\")\n",
    "db_root = Path(config.db_root).parent / config.dataset_name\n",
    "image_db = ImageRetriever(db_root, image_path=db_root / \"images\")\n",
    "image_db.build(\"test\")\n",
    "text_db = TextRetriever(db_root, text_path=db_root / \"texts\")\n",
    "text_db.build(\"test\")\n",
    "print()\n",
    "\n",
    "# 7. åˆ›å»ºSVGæ„å»ºå™¨\n",
    "print(\"7. åˆ›å»ºSVGæ„å»ºå™¨\")\n",
    "builders = {\n",
    "    \"layout\": SVGBuilder(key='type', max_width=128, max_height=192, opacity=0.8),\n",
    "    \"visual\": SVGBuilder(key='color', max_width=128, max_height=192, \n",
    "                        image_db=image_db, text_db=text_db, \n",
    "                        render_text=True, opacity=1.0),\n",
    "    \"visual_wo_text\": SVGBuilder(key='color', max_width=128, max_height=192,\n",
    "                                 image_db=image_db, text_db=None, \n",
    "                                 render_text=False, opacity=1.0),\n",
    "    \"visual_wo_image\": SVGBuilder(key='color', max_width=128, max_height=192,\n",
    "                                  image_db=None, text_db=text_db, \n",
    "                                  render_text=True, opacity=1.0),\n",
    "}\n",
    "print(\"âœ“ æ„å»ºå™¨åˆ›å»ºå®Œæˆ\\n\")\n",
    "\n",
    "# 8. è¿è¡Œå¯è§†åŒ–\n",
    "print(\"=\"*80)\n",
    "print(f\"8. å¼€å§‹å¯è§†åŒ– - ä»»åŠ¡: {config.target_task}\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "svgs = visualize_reconstruction(model, example, builders, config, input_columns,\n",
    "                                type_mapping, font_mapping, width_mapping, \n",
    "                                height_mapping, bins=64)\n",
    "\n",
    "print(f\"âœ“ ç”Ÿæˆäº† {len(svgs)} ä¸ªæ ·æœ¬çš„å¯è§†åŒ–ç»“æœ\")\n",
    "print(f\"åˆ—å: {config.column_names[config.target_task]}\\n\")\n",
    "\n",
    "# 9. æ˜¾ç¤ºç»“æœ\n",
    "print(\"=\"*80)\n",
    "print(\"å¯è§†åŒ–ç»“æœ:\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for i, row in enumerate(svgs[:3]):\n",
    "    print(f\"\\nSample {i}:\")\n",
    "    display(HTML(\"<div style='margin: 10px 0;'>%s</div>\" % \" \".join(row)))\n",
    "\n",
    "print(\"\\nâœ“ Demoå®Œæˆ!\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
