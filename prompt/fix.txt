demo_pytorch.py
"""
PyTorch版本的MFP模型演示和可视化
用于测试和可视化布局生成结果
"""
import json
import itertools
import logging
from pathlib import Path
from typing import Dict, List
import json

import torch
import numpy as np
from IPython.display import display, HTML

# 导入PyTorch模型和工具
from models_pytorch import MFP
from dataset import DesignLayoutDataset
from svg_builder_pytorch import SVGBuilder
from retriever_pytorch import ImageRetriever, TextRetriever

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# 设置随机种子
torch.manual_seed(0)
np.random.seed(0)


class DemoConfig:
    """演示配置"""
    def __init__(self):
        self.ckpt_dir = "/home/dell/Project-HCL/BaseLine/flexdm_pt/chechpoints"
        self.dataset_name = "crello_json"
        self.db_root = "/home/dell/Project-HCL/BaseLine/flexdm_pt/data/crello_json"
        self.batch_size = 20
        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'
        
        # 任务类型: elem, pos, attr, txt, img
        self.target_task = "pos"
        
        # 列名配置
        self.column_names = {
            "txt": ["gt-layout", "gt-visual", "input", "pred"],
            "img": ["gt-layout", "gt-visual", "input", "pred"],
            "attr": ["gt-layout", "gt-visual", "input", "pred"],
            "pos": ["gt-layout", "gt-visual", "pred-layout", "pred-visual"],
            "elem": ["gt-layout", "gt-visual", "input-layout", "input-visual", "pred-layout", "pred-visual"],
        }
        
        # 属性分组
        self.attribute_groups = {
            "type": ["type"],
            "pos": ["left", "top", "width", "height"],
            "attr": ["opacity", "color", "font_family"],
            "img": ["image_embedding"],
            "txt": ["text_embedding"],
        }


def load_model(checkpoint_path: str, input_columns: Dict, device: str = 'cuda'):
    """
    加载PyTorch模型
    
    Args:
        checkpoint_path: checkpoint路径
        input_columns: 输入列配置
        device: 设备
    
    Returns:
        加载好的模型
    """
    # 创建模型
    model = MFP(
        input_columns=input_columns,
        embed_dim=256,
        num_blocks=4,
        num_heads=8,
        dropout=0.1,
    )
    
    # 加载权重
    checkpoint = torch.load(checkpoint_path, map_location=device)
    if 'state_dict' in checkpoint:
        state_dict = checkpoint['state_dict']
    else:
        state_dict = checkpoint
    
    # 加载权重（允许部分匹配）
    missing, unexpected = model.load_state_dict(state_dict, strict=False)
    
    if missing:
        logger.warning(f"Missing keys: {len(missing)}")
    if unexpected:
        logger.warning(f"Unexpected keys: {len(unexpected)}")
    
    model.to(device)
    model.eval()
    
    logger.info(f"✓ Model loaded from {checkpoint_path}")
    return model


def get_seq_mask(lengths: torch.Tensor, max_len: int = None) -> torch.Tensor:
    """
    生成序列掩码
    
    Args:
        lengths: (B,) 长度张量
        max_len: 最大长度
    
    Returns:
        mask: (B, S) 布尔掩码
    """
    if lengths.dim() == 2:
        lengths = lengths.squeeze(-1)
    
    batch_size = lengths.size(0)
    if max_len is None:
        max_len = lengths.max().item()
    
    # 创建掩码
    mask = torch.arange(max_len, device=lengths.device).unsqueeze(0) < lengths.unsqueeze(1)
    return mask


def get_initial_masks(input_columns: Dict, seq_mask: torch.Tensor) -> Dict[str, torch.Tensor]:
    """
    初始化掩码字典（所有为False）
    
    Args:
        input_columns: 输入列配置
        seq_mask: 序列掩码
    
    Returns:
        masks: 掩码字典
    """
    masks = {}
    batch_size, seq_len = seq_mask.shape
    
    for key, column in input_columns.items():
        if column.get('is_sequence', False):
            masks[key] = torch.zeros_like(seq_mask, dtype=torch.bool)
        else:
            masks[key] = torch.ones(batch_size, dtype=torch.bool)
    
    return masks


def set_visual_default(item: Dict) -> Dict:
    """设置可视化默认值"""
    item = item.copy()
    for elem in item.get('elements', []):
        if 'color' not in elem or elem['color'] is None:
            elem['color'] = [0, 0, 0]
        if 'opacity' not in elem or elem['opacity'] is None:
            elem['opacity'] = 1.0
        if 'font_family' not in elem or elem['font_family'] is None:
            elem['font_family'] = 'DummyFont'
    return item


def tensor_to_list(data: Dict) -> List[Dict]:
    """
    将批次张量转换为样本列表
    
    Args:
        data: 批次数据字典
    
    Returns:
        样本列表
    """
    batch_size = data['length'].size(0)
    items = []
    
    for i in range(batch_size):
        item = {
            'id': data['id'][i] if 'id' in data else f'sample_{i}',
            'canvas_width': data['canvas_width'][i].item() if 'canvas_width' in data else 800,
            'canvas_height': data['canvas_height'][i].item() if 'canvas_height' in data else 600,
            'length': data['length'][i].item(),
            'elements': []
        }
        
        # 获取有效长度
        length = item['length'] + 1  # 基于0的索引
        
        # 构建元素列表
        for j in range(length):
            element = {}
            
            for key, value in data.items():
                if key in ['id', 'length', 'canvas_width', 'canvas_height']:
                    continue
                
                if not torch.is_tensor(value):
                    continue
                    
                if value.dim() >= 2 and value.size(1) > j:
                    elem_value = value[i, j]
                    
                    # 转换为Python原生类型
                    if elem_value.dim() == 0:
                        # 标量
                        element[key] = elem_value.item()
                    elif elem_value.dim() == 1:
                        # 一维向量
                        if elem_value.size(0) == 1:
                            # 单个值，展开
                            element[key] = elem_value[0].item()
                        else:
                            # 多个值（如RGB或embedding）
                            element[key] = elem_value.cpu().numpy().tolist()
                    else:
                        # 多维（对于分类变量，取argmax）
                        if elem_value.dim() == 2:
                            # (num_features, vocab_size) -> 取argmax
                            indices = elem_value.argmax(dim=-1)
                            if indices.size(0) == 1:
                                element[key] = indices[0].item()
                            else:
                                element[key] = indices.cpu().numpy().tolist()
                        else:
                            element[key] = elem_value.cpu().numpy().tolist()
            
            item['elements'].append(element)
        
        items.append(item)
    
    return items


def apply_task_masks(
    example: Dict,
    input_columns: Dict,
    target_task: str,
    attribute_groups: Dict,
    device: str
) -> Dict[str, torch.Tensor]:
    """
    应用任务特定的掩码
    
    Args:
        example: 输入样本
        input_columns: 输入列配置
        target_task: 目标任务
        attribute_groups: 属性分组
        device: 设备
    
    Returns:
        masks: 掩码字典
    """
    seq_mask = get_seq_mask(example['length'], example['left'].size(1))
    mfp_masks = get_initial_masks(input_columns, seq_mask)
    
    for key in mfp_masks.keys():
        if not input_columns[key].get('is_sequence', False):
            continue
        
        mask = mfp_masks[key].clone()
        
        if target_task == "elem":
            # 元素级掩码：隐藏第一个元素
            mask[:, 0] = True
        else:
            # 特征级掩码
            if key == "type":
                continue
            
            if target_task in attribute_groups:
                attr_keys = attribute_groups[target_task]
                if key in attr_keys:
                    mask = seq_mask.clone()
        
        mfp_masks[key] = mask.to(device)
    
    return mfp_masks


def visualize_reconstruction(
    model: torch.nn.Module,
    example: Dict,
    builders: Dict,
    config: DemoConfig,
    input_columns: Dict,
):
    """
    可视化重建结果
    
    Args:
        model: PyTorch模型
        example: 输入样本
        builders: SVG构建器字典
        config: 配置
        input_columns: 输入列配置
    
    Returns:
        SVG列表
    """
    svgs = []
    target_task = config.target_task
    
    # 转换为样本列表
    items = tensor_to_list(example)
    
    # GT布局和视觉
    svgs.append(list(map(builders["layout"], items)))
    svgs.append(list(map(builders["visual"], items)))
    
    # 输入可视化（根据任务类型）
    if target_task == "txt":
        svgs.append(list(map(builders["visual_wo_text"], items)))
    elif target_task == "img":
        svgs.append(list(map(builders["visual_wo_image"], items)))
    elif target_task == "attr":
        svgs.append(list(map(builders["visual"], [set_visual_default(x) for x in items])))
    
    # 应用掩码
    mfp_masks = apply_task_masks(
        example, input_columns, target_task, 
        config.attribute_groups, config.device
    )
    
    # 元素级任务的特殊处理
    if target_task == "elem":
        # 创建移除第一个元素后的样本
        example_copy = {}
        for key, value in example.items():
            if isinstance(value, torch.Tensor) and value.dim() >= 2 and value.size(1) > 1:
                # 移除第一个元素
                indices = torch.where(~mfp_masks[key][0, :])[0]
                example_copy[key] = torch.index_select(value, 1, indices)
            else:
                example_copy[key] = value
        
        example_copy['length'] = example['length'] - 1
        
        items_copy = tensor_to_list(example_copy)
        svgs.append(list(map(builders["layout"], items_copy)))
        svgs.append(list(map(builders["visual"], items_copy)))
    
    # 模型预测
    with torch.no_grad():
        # 将掩码信息添加到输入
        pred = model_inference_with_masks(model, example, mfp_masks)
    
    # 合并预测和原始输入
    for key in example:
        if key not in pred:
            pred[key] = example[key]
    
    # 预测可视化
    pred_items = tensor_to_list(pred)
    
    if target_task in ["pos", "elem"]:
        svgs.append(list(map(builders["layout"], pred_items)))
    svgs.append(list(map(builders["visual"], pred_items)))
    
    return [list(grouper(row, len(config.column_names[target_task]))) for row in zip(*svgs)]


def model_inference_with_masks(model, inputs, masks):
    """
    使用掩码进行模型推理
    
    Args:
        model: 模型
        inputs: 输入数据
        masks: 掩码字典
    
    Returns:
        预测结果
    """
    # 应用掩码到输入
    masked_inputs = {}
    for key, value in inputs.items():
        if key in masks and torch.is_tensor(value):
            mask = masks[key]
            if mask.any():
                # 应用掩码（使用特殊token）
                masked_value = value.clone()
                if value.dim() == 3:  # (B, S, F)
                    masked_value[mask] = 0  # 或使用特殊值
                masked_inputs[key] = masked_value
            else:
                masked_inputs[key] = value
        else:
            masked_inputs[key] = value
    
    # 模型推理
    outputs = model(masked_inputs)
    
    return outputs


def grouper(iterable, n):
    """将可迭代对象分组"""
    args = [iter(iterable)] * n
    return itertools.zip_longest(*args, fillvalue=None)


def main():
    """主函数"""
    # 配置
    config = DemoConfig()
    
    logger.info("="*80)
    logger.info("MFP PyTorch Demo")
    logger.info("="*80)
    
    # 加载数据
    logger.info(f"Loading dataset from {config.db_root}")
    dataset = DesignLayoutDataset(
        config.db_root, 
        split='test',
        max_length=50
    )
    
    # 创建DataLoader
    from torch.utils.data import DataLoader
    from dataset import collate_fn
    
    dataloader = DataLoader(
        dataset,
        batch_size=config.batch_size,
        shuffle=False,
        collate_fn=collate_fn
    )
    
    # 获取一个批次
    example = next(iter(dataloader))
    
    # 移动到设备
    for key in example:
        if torch.is_tensor(example[key]):
            example[key] = example[key].to(config.device)
    
    # # 获取输入列配置
    # input_columns = {
    #     'type': {'is_sequence': True, 'type': 'categorical', 'input_dim': 7, 'shape': [1]},
    #     'left': {'is_sequence': True, 'type': 'categorical', 'input_dim': 64, 'shape': [1]},
    #     'top': {'is_sequence': True, 'type': 'categorical', 'input_dim': 64, 'shape': [1]},
    #     'width': {'is_sequence': True, 'type': 'categorical', 'input_dim': 64, 'shape': [1]},
    #     'height': {'is_sequence': True, 'type': 'categorical', 'input_dim': 64, 'shape': [1]},
    #     'image_embedding': {'is_sequence': True, 'type': 'numerical', 'shape': [512]},
    # }

    with open('/home/dell/Project-HCL/BaseLine/flexdm_pt/scripts/input_columns_generated.json', 'r') as f:
        input_columns = json.load(f)    
    
    # 加载模型
    logger.info(f"Loading model from {config.ckpt_dir}")
    checkpoint_path = Path(config.ckpt_dir) / "best_pytorch.pth"
    model = load_model(str(checkpoint_path), input_columns, config.device)
    
    # 构建检索数据库
    logger.info("Building retrieval databases...")
    db_root = Path(config.db_root).parent / config.dataset_name
    
    image_db = ImageRetriever(db_root, image_path=db_root / "images")
    image_db.build("test")
    
    text_db = TextRetriever(db_root, text_path=db_root / "texts")
    text_db.build("test")
    
    # 创建SVG构建器
    logger.info("Creating SVG builders...")
    builders = {}
    
    # 布局构建器
    builders["layout"] = SVGBuilder(
        max_width=128,
        max_height=192,
        key="type",
    )
    
    # 视觉构建器
    patterns = [
        ("visual", image_db, text_db),
        ("visual_wo_text", image_db, None),
        ("visual_wo_image", None, text_db),
    ]
    
    for (name, idb, tdb) in patterns:
        builders[name] = SVGBuilder(
            max_width=128,
            max_height=192,
            key="color",
            image_db=idb,
            text_db=tdb,
            render_text=True,
        )
    
    # 可视化重建
    logger.info(f"Visualizing reconstruction for task: {config.target_task}")
    logger.info(f"Columns: {', '.join(config.column_names[config.target_task])}")
    
    svgs = visualize_reconstruction(
        model, example, builders, config, input_columns
    )
    
    # 显示结果
    for i, row in enumerate(svgs):
        print(f"Sample {i}:")
        display(HTML("<div>%s</div>" % " ".join(itertools.chain.from_iterable(row))))
    
    logger.info("✓ Demo completed!")


if __name__ == "__main__":
    main()

models_pytorch.py
"""
PyTorch模型架构 - 完全修复版本
使用ModuleList替代ModuleDict，避免键冲突
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
from typing import Dict, Optional
import math


# ==================== Transformer Components ====================

class MultiHeadSelfAttention(nn.Module):
    """多头自注意力机制"""
    
    def __init__(
        self,
        embed_dim: int,
        num_heads: int = 8,
        dropout: float = 0.1,
        lookahead: bool = True,
    ):
        super().__init__()
        assert embed_dim % num_heads == 0
        
        self.embed_dim = embed_dim
        self.num_heads = num_heads
        self.head_dim = embed_dim // num_heads
        self.lookahead = lookahead
        
        self.q_proj = nn.Linear(embed_dim, embed_dim)
        self.k_proj = nn.Linear(embed_dim, embed_dim)
        self.v_proj = nn.Linear(embed_dim, embed_dim)
        self.out_proj = nn.Linear(embed_dim, embed_dim)
        
        self.dropout = nn.Dropout(dropout)
        
    def forward(self, x: torch.Tensor, mask: Optional[torch.Tensor] = None):
        B, S, D = x.shape
        
        q = self.q_proj(x).view(B, S, self.num_heads, self.head_dim).transpose(1, 2)
        k = self.k_proj(x).view(B, S, self.num_heads, self.head_dim).transpose(1, 2)
        v = self.v_proj(x).view(B, S, self.num_heads, self.head_dim).transpose(1, 2)
        
        scores = torch.matmul(q, k.transpose(-2, -1)) / math.sqrt(self.head_dim)
        
        if mask is not None:
            mask = mask.unsqueeze(1).unsqueeze(2)
            scores = scores.masked_fill(~mask, float('-inf'))
            
            if not self.lookahead:
                causal_mask = torch.triu(
                    torch.ones(S, S, device=x.device, dtype=torch.bool),
                    diagonal=1
                )
                scores = scores.masked_fill(causal_mask, float('-inf'))
        
        attn_weights = F.softmax(scores, dim=-1)
        attn_weights = self.dropout(attn_weights)
        
        out = torch.matmul(attn_weights, v)
        out = out.transpose(1, 2).contiguous().view(B, S, D)
        out = self.out_proj(out)
        return out


class TransformerBlock(nn.Module):
    """Transformer块（DeepSVG风格）"""
    
    def __init__(
        self,
        embed_dim: int = 128,
        num_heads: int = 8,
        ff_dim: Optional[int] = None,
        dropout: float = 0.1,
        lookahead: bool = True,
    ):
        super().__init__()
        ff_dim = ff_dim or (2 * embed_dim)
        
        self.norm1 = nn.LayerNorm(embed_dim)
        self.attn = MultiHeadSelfAttention(
            embed_dim, num_heads, dropout, lookahead
        )
        self.dropout1 = nn.Dropout(dropout)
        
        self.norm2 = nn.LayerNorm(embed_dim)
        self.ffn = nn.Sequential(
            nn.Linear(embed_dim, ff_dim),
            nn.ReLU(),
            nn.Linear(ff_dim, embed_dim),
        )
        self.dropout2 = nn.Dropout(dropout)
    
    def forward(self, x: torch.Tensor, mask: Optional[torch.Tensor] = None):
        residual = x
        x = self.norm1(x)
        x = self.attn(x, mask)
        x = self.dropout1(x)
        x = residual + x
        
        residual = x
        x = self.norm2(x)
        x = self.ffn(x)
        x = self.dropout2(x)
        x = residual + x
        
        return x


class TransformerBlocks(nn.Module):
    """堆叠的Transformer块"""
    
    def __init__(
        self,
        num_blocks: int = 4,
        embed_dim: int = 128,
        num_heads: int = 8,
        dropout: float = 0.1,
        lookahead: bool = True,
    ):
        super().__init__()
        self.blocks = nn.ModuleList([
            TransformerBlock(embed_dim, num_heads, dropout=dropout, lookahead=lookahead)
            for _ in range(num_blocks)
        ])
    
    def forward(self, x: torch.Tensor, mask: Optional[torch.Tensor] = None):
        for block in self.blocks:
            x = block(x, mask)
        return x


# ==================== Encoder（修复版本）====================

class Encoder(nn.Module):
    """编码器 - 使用ModuleList避免键冲突"""
    
    def __init__(
        self,
        input_columns: Dict,
        embed_dim: int = 128,
        dropout: float = 0.1,
        max_length: int = 50,
    ):
        super().__init__()
        self.input_columns = input_columns
        self.embed_dim = embed_dim
        
        # 使用列表而不是字典存储层
        self.emb_layers = nn.ModuleList()
        self.emb_keys = []
        self.emb_types = []
        self.emb_configs = []
        
        print("初始化Encoder:")
        for key, column in input_columns.items():
            if not column.get('is_sequence', False):
                continue
            
            self.emb_keys.append(key)
            self.emb_types.append(column['type'])
            self.emb_configs.append(column)
            
            if column['type'] == 'categorical':
                vocab_size = column['input_dim'] + 2
                self.emb_layers.append(nn.Embedding(vocab_size, embed_dim))
                print(f"  {key}: Embedding({vocab_size}, {embed_dim})")
            elif column['type'] == 'numerical':
                input_size = column['shape'][-1] if 'shape' in column else 1
                self.emb_layers.append(nn.Linear(input_size, embed_dim))
                print(f"  {key}: Linear({input_size}, {embed_dim})")
        
        print(f"总计: {len(self.emb_keys)} 个特征")
        
        self.pos_embedding = nn.Embedding(max_length + 1, embed_dim)
        self.dropout = nn.Dropout(dropout)
    
    def forward(self, inputs: Dict[str, torch.Tensor]) -> tuple:
        batch_size = inputs['length'].size(0)
        
        # 找到序列长度
        seq_len = None
        for key in self.emb_keys:
            if key in inputs:
                seq_len = inputs[key].size(1)
                break
        
        if seq_len is None:
            raise ValueError("未找到序列特征")
        
        # 编码每个特征
        seq_embs = []
        for idx, key in enumerate(self.emb_keys):
            if key not in inputs:
                continue
            
            x = inputs[key]
            emb = self.emb_layers[idx](x)
            
            # 处理多维特征（如RGB）
            if len(emb.shape) == 4:
                emb = emb.sum(dim=2)
            
            seq_embs.append(emb)
        
        # 融合特征
        seq = torch.stack(seq_embs).sum(dim=0)
        
        # 位置编码
        positions = torch.arange(seq_len, device=seq.device).unsqueeze(0).expand(batch_size, -1)
        seq = seq + self.pos_embedding(positions)
        seq = self.dropout(seq)
        
        # 生成掩码
        lengths = inputs['length'].squeeze(-1)
        mask = torch.arange(seq_len, device=seq.device).unsqueeze(0) < lengths.unsqueeze(1)
        
        return seq, mask


# ==================== Decoder（修复版本）====================

class Decoder(nn.Module):
    """解码器 - 使用ModuleList避免键冲突"""
    
    def __init__(self, input_columns: Dict, embed_dim: int = 128):
        super().__init__()
        self.input_columns = input_columns
        
        # 使用列表而不是字典存储层
        self.head_layers = nn.ModuleList()
        self.head_keys = []
        self.head_configs = []
        
        print("初始化Decoder:")
        for key, column in input_columns.items():
            if not column.get('is_sequence', False):
                continue
            
            self.head_keys.append(key)
            self.head_configs.append(column)
            
            if column['type'] == 'categorical':
                shape = column.get('shape', [1])
                output_dim = shape[-1] * column['input_dim']
                self.head_layers.append(nn.Linear(embed_dim, output_dim))
                print(f"  {key}: Linear({embed_dim}, {output_dim}) -> ({shape[-1]}, {column['input_dim']})")
            else:
                shape = column.get('shape', [1])
                output_dim = shape[-1]
                self.head_layers.append(nn.Linear(embed_dim, output_dim))
                print(f"  {key}: Linear({embed_dim}, {output_dim})")
        
        print(f"总计: {len(self.head_keys)} 个输出头")
    
    def forward(self, x: torch.Tensor) -> Dict[str, torch.Tensor]:
        outputs = {}
        batch_size, seq_len, _ = x.shape
        
        for idx, key in enumerate(self.head_keys):
            column = self.head_configs[idx]
            pred = self.head_layers[idx](x)
            
            if column['type'] == 'categorical':
                shape = column.get('shape', [1])
                num_features = shape[-1]
                vocab_size = column['input_dim']
                pred = pred.view(batch_size, seq_len, num_features, vocab_size)
            
            outputs[key] = pred
        
        return outputs


# ==================== MFP Model ====================

class MFP(nn.Module):
    """Masked Field Prediction模型"""
    
    def __init__(
        self,
        input_columns: Dict,
        embed_dim: int = 128,
        num_blocks: int = 4,
        num_heads: int = 8,
        dropout: float = 0.1,
        max_length: int = 50,
    ):
        super().__init__()
        self.input_columns = input_columns
        
        print("\n" + "="*60)
        print("初始化MFP模型")
        print("="*60)
        
        self.encoder = Encoder(
            input_columns, embed_dim, dropout, max_length
        )
        
        print("\n初始化Transformer:")
        print(f"  blocks={num_blocks}, embed_dim={embed_dim}, num_heads={num_heads}")
        self.transformer = TransformerBlocks(
            num_blocks, embed_dim, num_heads, dropout, lookahead=True
        )
        
        print("")
        self.decoder = Decoder(input_columns, embed_dim)
        
        total_params = sum(p.numel() for p in self.parameters())
        print(f"\n总参数数: {total_params:,}")
        print("="*60 + "\n")
    
    def forward(self, inputs: Dict[str, torch.Tensor]) -> Dict[str, torch.Tensor]:
        x, mask = self.encoder(inputs)
        x = self.transformer(x, mask)
        outputs = self.decoder(x)
        return outputs
    
    def load_converted_weights(self, checkpoint_path: str):
        """加载转换后的权重"""
        checkpoint = torch.load(checkpoint_path, map_location='cpu')
        state_dict = checkpoint['state_dict']
        
        missing_keys, unexpected_keys = self.load_state_dict(state_dict, strict=False)
        
        if missing_keys:
            print(f"警告: 缺失 {len(missing_keys)} 个键")
        if unexpected_keys:
            print(f"警告: 多余 {len(unexpected_keys)} 个键")
        
        print("✓ 权重加载完成")


# ==================== 测试代码 ====================

if __name__ == "__main__":
    print("测试MFP模型（修复版本）\n")
    
    input_columns = {
        'type': {'is_sequence': True, 'type': 'categorical', 'input_dim': 7, 'shape': [1]},
        'left': {'is_sequence': True, 'type': 'categorical', 'input_dim': 64, 'shape': [1]},
        'top': {'is_sequence': True, 'type': 'categorical', 'input_dim': 64, 'shape': [1]},
        'width': {'is_sequence': True, 'type': 'categorical', 'input_dim': 64, 'shape': [1]},
        'height': {'is_sequence': True, 'type': 'categorical', 'input_dim': 64, 'shape': [1]},
        'image_embedding': {'is_sequence': True, 'type': 'numerical', 'shape': [512]},
    }
    
    model = MFP(input_columns, embed_dim=256, num_blocks=4)
    
    # 测试前向传播
    batch_size = 2
    seq_len = 10
    
    test_input = {
        'length': torch.tensor([[5], [7]], dtype=torch.long),
        'type': torch.randint(0, 7, (batch_size, seq_len, 1)),
        'left': torch.randint(0, 64, (batch_size, seq_len, 1)),
        'top': torch.randint(0, 64, (batch_size, seq_len, 1)),
        'width': torch.randint(0, 64, (batch_size, seq_len, 1)),
        'height': torch.randint(0, 64, (batch_size, seq_len, 1)),
        'image_embedding': torch.randn(batch_size, seq_len, 512),
    }
    
    print("测试前向传播...")
    with torch.no_grad():
        outputs = model(test_input)
    
    print("\n✓ 前向传播成功!")
    print("\n输出形状:")
    for key, value in outputs.items():
        print(f"  {key:20s}: {list(value.shape)}")

svg_builder_pytorch.py
"""
PyTorch版本的SVG构建器
用于将布局数据转换为SVG可视化
"""

import xml.etree.ElementTree as ET
from typing import Dict, Optional
import numpy as np


class SVGBuilder:
    """SVG构建器"""
    
    def __init__(
        self,
        key: str = 'type',
        colormap: Optional[Dict] = None,
        canvas_width: int = 256,
        canvas_height: int = 256,
        max_width: Optional[int] = None,
        max_height: Optional[int] = None,
        opacity: float = 0.5,
        image_db = None,
        text_db = None,
        render_text: bool = False,
        **kwargs
    ):
        """
        Args:
            key: 用于着色的键 ('type' 或 'color')
            colormap: 颜色映射字典
            canvas_width: 画布宽度
            canvas_height: 画布高度
            max_width: 最大显示宽度
            max_height: 最大显示高度
            opacity: 不透明度
            image_db: 图像检索数据库
            text_db: 文本检索数据库
            render_text: 是否渲染文本
        """
        self.key = key
        self.canvas_width = canvas_width
        self.canvas_height = canvas_height
        self.max_width = max_width
        self.max_height = max_height
        self.opacity = opacity
        self.image_db = image_db
        self.text_db = text_db
        self.render_text = render_text
        
        # 颜色映射
        if colormap is None and key != 'color':
            self.colormap = self._make_default_colormap()
        else:
            self.colormap = colormap or {}
    
    def _make_default_colormap(self) -> Dict:
        """创建默认颜色映射"""
        # 常见元素类型的颜色
        return {
            'imageElement': 'rgb(66, 166, 246)',
            'textElement': 'rgb(241, 98, 147)',
            'svgElement': 'rgb(175, 214, 130)',
            'maskElement': 'rgb(79, 196, 248)',
            'coloredBackground': 'rgb(226, 191, 232)',
            'humanElement': 'rgb(255, 139, 101)',
            '': 'none',
        }
    
    def compute_canvas_size(self, document: Dict):
        """计算画布大小"""
        canvas_width = document.get('canvas_width', self.canvas_width)
        canvas_height = document.get('canvas_height', self.canvas_height)
        
        scale = 1.0
        if self.max_width is not None:
            scale = min(self.max_width / canvas_width, scale)
        if self.max_height is not None:
            scale = min(self.max_height / canvas_height, scale)
        
        return canvas_width * scale, canvas_height * scale
    
    def __call__(self, document: Dict) -> str:
        """
        将文档转换为SVG字符串
        
        Args:
            document: 文档字典
        
        Returns:
            SVG字符串
        """
        canvas_width, canvas_height = self.compute_canvas_size(document)
        
        # 创建SVG根元素
        root = ET.Element(
            'svg',
            {
                'width': str(int(canvas_width)),
                'height': str(int(canvas_height)),
                'viewBox': '0 0 1 1',
                'style': 'background-color: #FFF',
                'preserveAspectRatio': 'none',
                'xmlns': 'http://www.w3.org/2000/svg',
            }
        )
        
        # 添加元素
        for element in document.get('elements', []):
            self._add_element(root, element, document)
        
        # 转换为字符串
        return ET.tostring(root, encoding='unicode')
    
    def _add_element(self, parent, element: Dict, document: Dict):
        """添加单个元素到SVG"""
        # 获取颜色
        if self.key == 'color':
            color = element.get('color', [0, 0, 0])
            if isinstance(color, list):
                fill = f'rgb({int(color[0])},{int(color[1])},{int(color[2])})'
            else:
                fill = 'rgb(0,0,0)'
        else:
            element_type = element.get(self.key, '')
            # 处理可能是列表的情况
            if isinstance(element_type, list):
                element_type = element_type[0] if element_type else ''
            # 处理可能是数字的情况
            if isinstance(element_type, (int, float)):
                element_type = str(int(element_type))
            fill = self.colormap.get(element_type, 'rgb(128,128,128)')
        
        # 获取位置和尺寸
        left = float(element.get('left', 0))
        top = float(element.get('top', 0))
        width = float(element.get('width', 0.1))
        height = float(element.get('height', 0.1))
        opacity = float(element.get('opacity', 1.0))
        
        # 检查是否需要渲染图像或文本
        image_url = None
        if self.image_db and element.get('type') in ['imageElement', 'svgElement', 'maskElement']:
            if 'image_embedding' in element:
                image_url = self.image_db.search(element['image_embedding'])
        
        text_content = None
        if self.text_db and element.get('type') == 'textElement':
            if 'text_embedding' in element:
                text_content = self.text_db.search(element['text_embedding'])
        
        # 创建元素
        if image_url and image_url != '':
            # 图像元素
            elem = ET.SubElement(
                parent,
                'image',
                {
                    'x': str(left),
                    'y': str(top),
                    'width': str(width),
                    'height': str(height),
                    'href': image_url,
                    'opacity': str(opacity * self.opacity),
                    'preserveAspectRatio': 'none',
                }
            )
        elif self.render_text and text_content:
            # 文本元素
            container = ET.SubElement(
                parent,
                'svg',
                {
                    'x': str(left),
                    'y': str(top),
                    'width': str(width),
                    'height': str(height),
                    'overflow': 'visible',
                }
            )
            
            text_elem = ET.SubElement(
                container,
                'text',
                {
                    'x': '50%',
                    'y': '50%',
                    'text-anchor': 'middle',
                    'dominant-baseline': 'middle',
                    'fill': fill,
                    'font-size': str(height * 0.8),
                    'font-family': element.get('font_family', 'Arial'),
                }
            )
            text_elem.text = str(text_content)[:50]  # 限制长度
        else:
            # 矩形元素
            elem = ET.SubElement(
                parent,
                'rect',
                {
                    'x': str(left),
                    'y': str(top),
                    'width': str(width),
                    'height': str(height),
                    'fill': fill,
                    'opacity': str(opacity * self.opacity),
                }
            )
        
        # 添加标题（用于hover显示）
        title = ET.SubElement(elem if not (self.render_text and text_content) else container, 'title')
        title.text = str({k: v for k, v in element.items() if not isinstance(v, (list, np.ndarray))})


# 测试代码
if __name__ == "__main__":
    # 创建测试文档
    test_doc = {
        'id': 'test_001',
        'canvas_width': 800,
        'canvas_height': 600,
        'length': 3,
        'elements': [
            {
                'type': 'imageElement',
                'left': 0.1,
                'top': 0.1,
                'width': 0.3,
                'height': 0.3,
                'color': [255, 0, 0],
                'opacity': 1.0,
            },
            {
                'type': 'textElement',
                'left': 0.5,
                'top': 0.5,
                'width': 0.3,
                'height': 0.1,
                'color': [0, 0, 255],
                'opacity': 1.0,
                'font_family': 'Arial',
            },
            {
                'type': 'coloredBackground',
                'left': 0.0,
                'top': 0.0,
                'width': 1.0,
                'height': 1.0,
                'color': [240, 240, 240],
                'opacity': 0.5,
            },
        ]
    }
    
    # 测试布局构建器
    builder = SVGBuilder(key='type', max_width=400)
    svg = builder(test_doc)
    print("SVG生成成功!")
    print(f"SVG长度: {len(svg)} 字符")
    
    # 保存到文件
    with open('test_layout.svg', 'w') as f:
        f.write(svg)
    print("✓ 已保存到 test_layout.svg")

retriever_pytorch.py
"""
PyTorch版本的检索器
用于图像和文本的最近邻检索
"""

import json
import logging
from pathlib import Path
from typing import Any, Dict, List
from base64 import b64encode

import torch
import numpy as np

# 使用faiss进行快速检索
try:
    import faiss
    FAISS_AVAILABLE = True
except ImportError:
    FAISS_AVAILABLE = False
    logging.warning("Faiss not available, using brute force search")

logger = logging.getLogger(__name__)


class BaseRetriever:
    """基础检索器"""
    
    def __init__(
        self,
        data_path: Path,
        key: str,
        value: str,
        condition: Dict[str, Any] = None,
        dim: int = 512,
    ):
        """
        Args:
            data_path: 数据路径
            key: 查询键
            value: 检索值
            condition: 条件过滤
            dim: 嵌入维度
        """
        self.data_path = Path(data_path)
        self.key = key
        self.value = value
        self.condition = condition
        self.dim = dim
        
        self.labels = None
        self.db = None
    
    def build(self, split: str = 'train'):
        """
        构建检索索引
        
        Args:
            split: 数据集划分
        """
        logger.info(f"Building {self.__class__.__name__} index for {split}...")
        
        # 加载数据
        json_file = self.data_path / f"{split}.json"
        if not json_file.exists():
            logger.warning(f"Data file not found: {json_file}")
            return
        
        with open(json_file, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        # 提取嵌入和标签
        embeddings = []
        labels = []
        
        for item in data:
            length = item['length']
            
            for i in range(length):
                # 检查条件
                if self.condition:
                    cond_key = self.condition['key']
                    cond_values = self.condition['values']
                    if item[cond_key][i] not in cond_values:
                        continue
                
                # 提取嵌入和标签
                if self.key in item and self.value in item:
                    key_val = item[self.key][i]
                    value_val = item[self.value][i]
                    
                    if isinstance(value_val, list) and len(value_val) == self.dim:
                        embeddings.append(value_val)
                        labels.append(key_val)
        
        if not embeddings:
            logger.warning(f"No embeddings found for {split}")
            return
        
        # 去重
        unique_data = {}
        for label, emb in zip(labels, embeddings):
            if label not in unique_data:
                unique_data[label] = emb
        
        self.labels = np.array(list(unique_data.keys()))
        embeddings = np.array(list(unique_data.values()), dtype=np.float32)
        
        # 构建索引
        if FAISS_AVAILABLE:
            self.db = faiss.IndexFlatL2(self.dim)
            self.db.add(embeddings)
        else:
            # 使用PyTorch进行暴力搜索
            self.db = torch.from_numpy(embeddings)
        
        logger.info(f"✓ Built index with {len(self.labels)} items")
    
    def search(self, query, k: int = 1):
        """
        搜索最近邻
        
        Args:
            query: 查询向量
            k: 返回的最近邻数量
        
        Returns:
            检索结果
        """
        if self.labels is None or self.db is None:
            return self.get_default_result()
        
        # 转换查询为numpy
        if torch.is_tensor(query):
            query = query.cpu().numpy()
        if not isinstance(query, np.ndarray):
            query = np.array(query, dtype=np.float32)
        
        if query.ndim == 1:
            query = query.reshape(1, -1)
        
        # 搜索
        if FAISS_AVAILABLE:
            _, indices = self.db.search(query, k)
        else:
            # PyTorch暴力搜索
            query_torch = torch.from_numpy(query)
            distances = torch.cdist(query_torch, self.db)
            _, indices = distances.topk(k, largest=False)
            indices = indices.cpu().numpy()
        
        # 获取结果
        results = [self.get_url(idx) for idx in indices[0]]
        
        return results[0] if k == 1 else results
    
    def get_url(self, index: int) -> str:
        """获取URL（子类实现）"""
        raise NotImplementedError
    
    def get_default_result(self):
        """获取默认结果"""
        return ""


class ImageRetriever(BaseRetriever):
    """图像检索器"""
    
    def __init__(
        self,
        data_path: Path,
        key: str = 'image_hash',
        value: str = 'image_embedding',
        condition: Dict[str, Any] = None,
        image_path: Path = None,
        dim: int = 512,
    ):
        """
        Args:
            data_path: 数据路径
            key: 图像哈希键
            value: 图像嵌入键
            condition: 条件过滤
            image_path: 图像文件路径
            dim: 嵌入维度
        """
        super().__init__(data_path, key, value, condition, dim)
        
        if condition is None:
            self.condition = {
                'key': 'type',
                'values': ['imageElement', 'maskElement', 'svgElement', 'humanElement'],
            }
        
        self.image_path = image_path or self.data_path / 'images'
    
    def get_url(self, index: int) -> str:
        """获取图像URL"""
        label = self.labels[index]
        
        if isinstance(label, bytes):
            label = label.decode('utf-8')
        
        if label:
            image_file = self.image_path / f"{label}.png"
            if image_file.exists():
                return self._make_data_uri(image_file)
        
        return ""
    
    def _make_data_uri(self, file_path: Path, mime_type: str = 'image/png') -> str:
        """创建data URI"""
        try:
            with open(file_path, 'rb') as f:
                image_bytes = f.read()
            data = b64encode(image_bytes).decode('ascii')
            return f"data:{mime_type};base64,{data}"
        except Exception as e:
            logger.warning(f"Failed to read image {file_path}: {e}")
            return ""


class TextRetriever(BaseRetriever):
    """文本检索器"""
    
    def __init__(
        self,
        data_path: Path,
        key: str = 'text_hash',
        value: str = 'text_embedding',
        condition: Dict[str, Any] = None,
        text_path: Path = None,
        dim: int = 512,
    ):
        """
        Args:
            data_path: 数据路径
            key: 文本哈希键
            value: 文本嵌入键
            condition: 条件过滤
            text_path: 文本文件路径
            dim: 嵌入维度
        """
        super().__init__(data_path, key, value, condition, dim)
        
        if condition is None:
            self.condition = {
                'key': 'type',
                'values': ['textElement'],
            }
        
        self.text_path = text_path or self.data_path / 'texts'
    
    def get_url(self, index: int) -> str:
        """获取文本内容"""
        label = self.labels[index]
        
        if isinstance(label, bytes):
            label = label.decode('utf-8')
        
        if label:
            text_file = self.text_path / f"{label}.txt"
            if text_file.exists():
                try:
                    with open(text_file, 'r', encoding='utf-8') as f:
                        return f.read()
                except Exception as e:
                    logger.warning(f"Failed to read text {text_file}: {e}")
        
        return "TEXT"


# 测试代码
if __name__ == "__main__":
    logging.basicConfig(level=logging.INFO)
    
    # 测试路径
    data_path = Path("./data/crello_json")
    
    if data_path.exists():
        # 测试图像检索
        print("测试图像检索器...")
        image_retriever = ImageRetriever(
            data_path,
            image_path=data_path.parent / "crello" / "images"
        )
        image_retriever.build("test")
        
        # 测试查询
        if image_retriever.labels is not None:
            test_query = np.random.randn(512).astype(np.float32)
            result = image_retriever.search(test_query)
            print(f"图像检索结果长度: {len(result)}")
        
        # 测试文本检索
        print("\n测试文本检索器...")
        text_retriever = TextRetriever(
            data_path,
            text_path=data_path.parent / "crello" / "texts"
        )
        text_retriever.build("test")
        
        # 测试查询
        if text_retriever.labels is not None:
            test_query = np.random.randn(512).astype(np.float32)
            result = text_retriever.search(test_query)
            print(f"文本检索结果: {result[:50]}...")
        
        print("\n✓ 测试完成!")
    else:
        print(f"数据路径不存在: {data_path}")


    Exception has occurred: RuntimeError
mat1 and mat2 must have the same dtype, but got Long and Float
  File "/home/dell/Project-HCL/BaseLine/flexdm_pt/scripts/models_pytorch.py", line 201, in forward
    emb = self.emb_layers[idx](x)
          ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/dell/Project-HCL/BaseLine/flexdm_pt/scripts/models_pytorch.py", line 317, in forward
    x, mask = self.encoder(inputs)
              ^^^^^^^^^^^^^^^^^^^^
  File "/home/dell/Project-HCL/BaseLine/flexdm_pt/scripts/demo_pytorch.py", line 391, in model_inference_with_masks
    outputs = model(masked_inputs)
              ^^^^^^^^^^^^^^^^^^^^
  File "/home/dell/Project-HCL/BaseLine/flexdm_pt/scripts/demo_pytorch.py", line 345, in visualize_reconstruction
    pred = model_inference_with_masks(model, example, mfp_masks)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/dell/Project-HCL/BaseLine/flexdm_pt/scripts/demo_pytorch.py", line 498, in main
    model, example, builders, config, input_columns

    )
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/dell/Project-HCL/BaseLine/flexdm_pt/scripts/demo_pytorch.py", line 511, in <module>
    main()
RuntimeError: mat1 and mat2 must have the same dtype, but got Long and Float

(base) hzj@29541d69cb02:/home/dell/Project-HCL/BaseLine/flexdm_pt/scripts$  cd /home/dell/Project-HCL/BaseLine/flexdm_pt/scripts ; /usr/bin/env /bin/python3 /home/hzj/.vscode-server/extensions/ms-python.debugpy-2025.13.2025091201-linux-x64/bundled/libs/debugpy/adapter/../../debugpy/launcher 40861 -- demo_pytorch.py 
WARNING:root:Faiss not available, using brute force search
加载数据: /home/dell/Project-HCL/BaseLine/flexdm_pt/data/crello_json/test.json
✓ 加载了 2248 个样本

============================================================
初始化MFP模型
============================================================
初始化Encoder:
  color: Linear(3, 256)
  font_family: Embedding(83, 256)
  height: Embedding(66, 256)
  image_embedding: Linear(512, 256)
  left: Embedding(66, 256)
  opacity: Embedding(66, 256)
  text_embedding: Linear(512, 256)
  top: Embedding(66, 256)
  type: Embedding(17, 256)
  uuid: Embedding(1217, 256)
  width: Embedding(66, 256)
总计: 11 个特征

初始化Transformer:
  blocks=4, embed_dim=256, num_heads=8

初始化Decoder:
  color: Linear(256, 3)
  font_family: Linear(256, 81) -> (1, 81)
  height: Linear(256, 64) -> (1, 64)
  image_embedding: Linear(256, 512)
  left: Linear(256, 64) -> (1, 64)
  opacity: Linear(256, 64) -> (1, 64)
  text_embedding: Linear(256, 512)
  top: Linear(256, 64) -> (1, 64)
  type: Linear(256, 15) -> (1, 15)
  uuid: Linear(256, 1215) -> (1, 1215)
  width: Linear(256, 64) -> (1, 64)
总计: 11 个输出头

总参数数: 3,489,890
============================================================

WARNING:__main__:Missing keys: 101
WARNING:__main__:Unexpected keys: 84
WARNING:retriever_pytorch:No embeddings found for test
WARNING:retriever_pytorch:No embeddings found for test

